{"./":{"url":"./","title":"README","keywords":"","body":"pp4fpga-cn 中文版 Parallel Programming for FPGAs 电子书阅读地址: https://xupsh.github.io/pp4fpgas-cn 电子书下载地址: 暂无 写在前面 国内鲜有介绍HLS的书，我们希望通过翻译Parallel Programming for FPGAs这本书，让更多的人来了解HLS和FPGA开发。 翻译之前 Parallel Programming for FPGAs这本书的原作采用的是latex进行内容的编写和排版。为了提高翻译写作的速度和协作的效率，本次翻译任务选择了在GitHub这个平台上进行协作，采用了Markdown使得译者可以专注文字内容而不是排版样式，安心写作。 这也给参与翻译任务的诸位带来了一点小挑战，需要诸位事先熟悉一下GitHub平台的使用、git的使用以及Markdown语言的规范，下面是相关的参考链接给诸位快速上手。 排版约定 排版约定 编辑器 一个界面美观、交互UI设计良好的编辑器可以帮我们节省很多力气，这里我们比较推荐使用以下几款编辑器来进行翻译工作 Atom VS Code Markdown语言 事实上这篇README就是用Markdown写成的 :) 认识与入门Markdown Markdown 语法说明 (简体中文版) git git可以说是现在最为流行的版本管理工具了。 廖雪峰的git教程 猴子都能懂的GIT入门 其实最常用的命令无非下面几条 下载git库到本地 git clone https://github.com/xupsh/pp4fpgas-cn.git 保存本地的修改并上传到云端服务器(GitHub) git add -A git commit -m \"最近的修改里都做了什么\" git pull git push GitHub的Pull Request操作 在GitHub上进行协作，通常采用的方式是先各自fork一份到自己的个人帐户，经过一段时间的工作之后，通过pull request的方式，将自己的工作内容提交到公共项目帐户中，而pull request之后往往还需要进行review才能正式进入公共项目。 github的pull request官方文档 Pull Request 的流程 第一步，你需要把别人的代码，克隆到你自己的仓库，Github 的术语叫做 fork。 第二步，在你仓库的修改后的分支上，按下\"New pull request\"按钮。 这时，会进入一个新页面，有Base 和 Head 两个选项。Base 是你希望提交变更的目标，Head 是目前包含你的变更的那个分支或仓库。 第三步，填写说明，帮助别人理解你的提交，然后按下\"create pull request\"按钮即可。 PR 创建后，管理者就要决定是否接受该 PR。对于非代码变更（比如文档），单单使用 Web 界面就足够了。但是，对于代码变更，Web 界面可能不够用，需要命令行验证是否可以运行。 任务分工 见Wiki页面 Citation https://github.com/KastnerRG/pp4fpgas @ARTICLE{ 2018arXiv180503648K, author = {{Kastner}, R. and {Matai}, J. and {Neuendorffer}, S.}, title = \"{Parallel Programming for FPGAs}\", journal = {ArXiv e-prints}, archivePrefix = \"arXiv\", eprint = {1805.03648}, keywords = {Computer Science - Hardware Architecture}, year = 2018, month = may } Copyright © xupsh.github.io 2018 all right reserved，powered by Gitbook 该文件修订时间： 2018-07-10 15:20:35 "},"00-Preface.html":{"url":"00-Preface.html","title":"前言","keywords":"","body":"前言 \"当有人说‘我想要一个编程语言，这个语言我只需要直接写我要干什么’的时候，你还是给他一个棒棒糖吧。\" -Alan Perlis 本书将着重介绍高层次综合（HLS） 算法的使用并以此完成一些比较具体、细分的FPGA应用。我们的目的是让读者认识到用HLS创造并优化硬件设计的好处。当然，FPGA的并行编程肯定是有别于在多核处理器、GPU上实行的并行编程，但是一些最关键的概念是相似的，例如，设计者必须充分理解内存层级和带宽、空间局部性与时间局部性、并行结构和计算与存储之间的取舍与平衡。 本书将更多的作为一个实际应用的向导，为那些对于研发FPGA系统有兴趣的读者提供帮助。对于大学教育来说，这本书将更适用于高阶的本科课程或研究生课程，同时也对应用系统设计师和嵌入式程序员有所帮助。我们不会对C/C++方面的知识做过多的阐述，而会以提供很多的代码的方式作为示范。另外，读者需要对基本的计算机架构有所熟悉，例如流水线（pipeline），加速，阿姆达尔定律（Amdahl's Law）。以寄存器传输级（RTL)为基础FPGA设计知识并不是必需的，但会对理解本书有所帮助。 本书囊括了很多对教学很有帮助的内容。每个章节均有一些小问题留给读者，这些问题将有助于加深对于材料的理解。在加州大学圣地亚哥分校（UCSD）的CSE 237C这门课里也有很多用HLS开发的项目，如果有出于教育目的的需要，我们可以对提出申请的读者分享这些课程项目的文件。这些HLS项目主要是与数字信号分析相关，重点于无线交流系统的开发。每个单独的项目都或多或少与书中的某一章节有所关联。这些项目以赛灵思大学计划（Xilinx University Program）使用的FPGA开发板为基础而开发，设计基础参考 http://www.xilinx.com/support/university.html 。赛灵思也同时提供这些开发板的商业订单。同时我们鼓励读者在 http://xilinx.com 申请Vivado HLS的试用许可。 本书并不着重于HLS算法本身。HLS处理方面的具体内容已经有很多的资源供读者参考，包括计划，资源分配，捆绑[51, 29, 18, 26]的算法。 本书更多的将会是引导学生掌握各类算法怎样分明的协同工作，提供具体的HLS语言开发程序的使用案例，因此，其他的一些更注重于算法与概念本身的材料会对理解本书很有帮助。本书也不着重于FPGA的细分结构和RTL设计方法，但是同样这方面的材料可以作为很好的辅助材料。 本书将主要使用赛灵思的Vivado HLS来完成类C代码到RTL的转换，C语言下的示例是针对Vivado HLS语法而完成的。本书不仅将介绍Vivado HLS的具体使用，而且会介绍那些最基本的HLS概念，这些概念应当适用于所有开发工具。我们同时鼓励读者尝试其他工具以真正理解这些概念，而不仅仅是在我们使用的工具里“学会”如何一步步操作。 希望你能享受这本书，并祝一切好运。 Copyright © xupsh.github.io 2018 all right reserved，powered by Gitbook 该文件修订时间： 2018-07-10 15:20:35 "},"01-Introduction.html":{"url":"01-Introduction.html","title":"第一章","keywords":"","body":"第一章 介绍 1.1 高层次综合(HLS) 硬件设计与处理近几年来发展迅速。 过去我们的电路相对简单，硬件设计师们可以很方便的画出每一个晶体管，规划他们的连接方式，甚至他们的板上位置。可以说所有工作都是人工完成的。但随着越来越多晶体管的设计需要，硬件工程师也越来越需要依赖自动化设计工具来帮助他们完成设计，而这些设计工具也相对应的变得越来越精密。工程师在这些设计工具的协助下也更具效率。他们不再具体操作每一个晶体管，而只需要设计数字电路，电子设计自动化工具（EDA）把这些抽象而概括的电路自动转换成实际的部件构造版图。 米德和康威（Mead&Conway）的方法[50]，也就是使用一种硬件语言描述语言（Verilog, VHDL），并把其编译成片上设计的方法在上世纪80年代开始广为使用。但这之后硬件的复杂度还在以指数函数的增长速度发展，硬件工程师们只好寻求更加概括而高层的编程语言，RTL应运而生。在RTL里，设计师不需要考虑怎么构造一个寄存器或怎样安置这些寄存器，而只需要考虑这些寄存器在设计中起到怎样的作用。EDA工具可以先把RTL转化成数电模型，再由模型转换成一个设备上的具体电路实施方案。所谓“方案”其实就是编译出的文件，这些文件可以用于规定某个自定义设备，也可以用于编程一些现有的设备，比如FPGA。如我们现在所见，新的设计方法确实帮助工程师们的设计思路变得更加清晰。更多关于这方面的探讨参考注释[42]. HLS则是在这基础上更高层的一种方法，设计师们在HLS下需要更多的考虑大的架构而非某个单独部件或逐周期运行。设计师在HLS下需要注重的是系统的运行模式，HLS工具会负责产生具体的RTL微结构。最早大多数HLS工具是基于Verilog的，用户需要使用Verilog语言进行描述，工具也通过Verilog产生RTL。现如今很多HLS工具开始使用C/C++作为设计师端的语言。当然，选择HLS工具最重要的还是看它能否综合我们需要的程序，而不是它使用什么语言。 总体来说，HLS可以自动完成以下曾经需要手动完成的工作： HLS自动分析并利用一个算法中潜在的并发性 HLS自动在需要的路径上插入寄存器，并自动选择最理想的时钟 HLS自动产生控制数据在一个路径上出入方向的逻辑 HLS自动完成设计的部分与系统中其他部分的接口 HLS自动映射数据到储存单位以平衡资源使用与带宽 HLS自动将程序中计算的部分对应到逻辑单位，在实现等效计算的前提下自动选取最有效的实施方式 HLS的目标是根据用户提供的输入和限制自动替用户做出很多决定。每个HLS工具在实际施行的效率上相差甚远，这其中我们有一些非常不错的选择，例如赛灵思Vivado HLS, LegUp, Mentor Catapult HLS。他们出众的特性在于可以支持更多更广泛的程序转换。我们在本书中将使用Vivado HLS作为演示软件，但是设计的思路与技巧在各个软件中应当是通用的，读者只需要在各自的软件中对语法进行稍微的调整。 大多数HLS工具需要用户提供功能的规范，交互的描述，一个对接的计算设备，和目标优化方向。而对于Vivado HLS来说，用户需要： 一个用C/C++/System C编写的函数 一个测试平台用于验证结果 一个FPGA开发版 期望的时钟周期 一个简单的实施指导 HLS工具没有强大到可以处理任何代码。很多我们平时在软件编程中常用的概念在硬件实施中很难实现，所以硬件描述语言对于具体实施会更加灵活。通常这些HLS工具需要用户提供一些附加信息（通过suggestion或#pagma）来帮助完善程序，因此我们说HLS工具会同时“限制”又“加强”了一门语言。举例而言，HLS工具一般无法处理动态内存分配，大部分工具对标准库的支持也非常有限。用户也应当避免系统调用和递归以尽量降低复杂程度。除去这些设计限制之外，HLS工具的处理范围非常的广（包括直接内存访问，流，片上内存），优化效率也很高。 根据Vivado HLS的使用指南，我们将对我们的输入程序作出以下规范： 不使用动态内存分配（不使用malloc(),free(),new和delete()） 减少使用指针对指针的操作 不使用系统调用（例如abort(),exit(),printf()），我们可以在其他代码例如测试平台上使用这些指令，但是综合的时候这些指令会被无视（或直接删掉） 减少使用其他标准库里的内容（支持math.h里常用的内容，但还是有一些不兼容） 减少使用C++中的函数指针和虚拟函数 不使用递归方程 精准的表达我们的交互接口 当RTL级的设计可用时，大多数HLS工具会进行标准RTL设计流。而在赛灵思Xilinx Vivado设计套装里进行的是逻辑综合，将RTL级设计转换成一个FPGA逻辑部件的连线表，这份连线表不仅包含需要的逻辑部件还包含他们的连接方式。Vivado之后将连线表和目标设备中的可用资源相关联，这个过程被称作布局及布线（PAR）。产出的FPGA配置被附在比特流（bitstream）上，用户可以将比特流上传到FPGA以实现想要的功能。比特流实质上是用二进制表示FPGA上每一个可用资源的配置，包括逻辑部件的使用，连线的方式，和片上的内存。大型FPGA例如赛灵思UltraScale FPGA拥有超过十亿个可配置比特，较小的FPGA上也至少有几亿个可配置比特。 1.2 FPGA构造 了解HLS的第一步是熟悉FPGA的构造，因为很多HLS的优化都是和这些构造特点息息相关的。过去几十年来，FPGA变得越发大而复杂，也加入了片上内存、自定义数据路径，高速I/O，和多核处理器等等精密结构。在这一节，我们只讨论FPGA中与HLS相关的结构特点，其他无关内容不会被详细描述。了解FPGA的现代结构后再学习HLS会有助于读者对于其理解。 FPGA由一个可编程逻辑模块的矩阵和与之相连的内存组成，通常这些模块是以查找表（LUT）的形式存在，也就是说把地址信号输入进去，对应内存位置的内容会直接被输出出来。一个N位查找表可以以一个N位输入真值表的方式来表示。 上图中的a部分是一个2位输入查找表，共有22{2}^{2}22个配置比特。使用者通过编写程序来控制这些比特以实现某种功能。b部分是一个2位输入AND门的真值表，通过对应4个可能的结果产出（out一列），我们可以把a中的2位查找表编写成b中的AND门，即四个查找表输入依次对应b中的00，01，10，11。按照这个模式编写查找表，我们可以轻松的改变它的功能，让它充当我们需要的部件。对于小的布尔逻辑（Boolean），这样的编写方式更加的灵活高效。实际中的FPGA大多使用4-6位输入的查找表作为运算基础，一些大型FPGA内甚至有几百万个这一级别的查找表。 怎样将图片1.1中的查找表编写成一个XOR门呢？一个OR门？我们需要一个几位输入的查找表？ 一个2位输入的查找表最多可以被编写出多少种形态？一个n位输入的查找表呢？ 触发器（FF）是FPGA最基本的内存单位，通常触发器是配有查找表的，这样是为方便查找表之间的复制与组合。在这基础上再加入一个规定它们的函数（例如全加器），就可以创建一个更为复杂的逻辑单位，称为可配置逻辑块（CLB）或逻辑矩阵块（LAB）。有些设计工具中还会把它称作片（Slice）。为避免歧义，我们将在下文中用slice作描述，这样读者可以对在Vivado设计工具中出现的Slice更加熟悉。一个slice是几个查找表，触发器，和多路复用器（MUX）组合到一起而形成的更强大的可编程逻辑单位。每个slice需要的小部件数视FPGA的架构而变，但总体来说每个slice真的只包含不多的几个部件。图片1.1中的c部分就是由1个三位输入查找表和1个触发器组成的slice。slice可以变得更加复杂一点，比如常见的全加器。FPGA内部通常有一些定义好的全加器slice，这看起来有点违背FPGA的“可编写性”。但实际上使用全加器在硬件设计中太过于常见，把所有的全加器每次重新编写成一个slice会降低效率。灵活性和高效综合考虑，一些被配置好的slice是一个对整个系统有益的设计。 可编写的互联是FPGA最关键的特性之一，它能提供一个slice之间更灵活的连线网络。slice的输入与输出全都与连线通道相连，连线通道也是通过配置比特来决定每个slice的输入输出通向哪里，而通道本身则与开关盒相连。开关盒由很多传输晶体管充当的开关所组成，它的工作便是连接通道与通道。 图片1.2展示了一个slice，连线通道和开关盒之间的连接方式。slice的每个输入输出都应与通道中的一条路线相连。所谓路线，我们可以简单的把它想成一跟比特层级的跳线，在物理层级上这条线路是由传输晶体管构成的，同样具有可编写性。 开关盒像是一个连接矩阵，沟通不同连接通道中的各个路线。FPGA一般有一个2D的形式，能给使用者一个大概的2D计算模型，我们称之为岛状结构。在岛状结构里，每个slice都是一个逻辑岛，岛与岛之间通过连线通道和开关盒相连。在这里每个开关盒在上下左右四个方向连接了四个连线通道。 连线通道和开关盒中的所有开关都通过使用者的编写控制着逻辑部件之间的联系。现如今业界对于电路层级的FPGA架构已经了解的很深了，连线通道的数量，开关盒的连接方式，slice的结构等等都有很详尽的资料。我们在注释中附上了一些书籍[12, 10, 30]，有兴趣的读者可以参考一下。当然使用HLS工具不需要了解那么多细节的资料，这方面更多的知识是作为理解HLS优化工作的辅助。 图片1.3提供的是一个更概括性的结构互联，可以比较清楚的看到各部分之间的物理连接方式。FPGA的逻辑部分通过一些IO模块与外部设备相联系，像微控制器（通过AXI接口连接片上ARM处理器 ），传感器（通过A/D接口连接天线），作动器（通过D/A接口连接电机）都是可以实现的。近来发展的FPGA又集成了自定义片上I/O处理器，像内存控制，无线收发，模拟与数字转换器这类的装置。 我们说到FPGA上要承载的晶体管变得越来越多，这也是FPGA上多了很多预配好的资源的原因。这部分硬件用于完成特定工作。很多设计都需要大量的加法和乘法，因此FPGA厂商把这部分的内容预配好以直接使用。像DSP48数据路径已经被用一种高效的方法预配好，添加了乘法、加法、乘积、逻辑操作等一系列算数。对于DSP48这样的模块来说，它们依旧保留了一定的可编写性，但不想其他可编程逻辑那样完全灵活。这样综合而言，用户在DSP48这样的模块上进行乘法这样的操作会比重新编写高效的多。所以我们说灵活性和效率有时候是此消彼长的。现代FPGA会含有成百上千个DSP48模块，如图1.4所示。 比较自搭乘积和DSP48基础上乘积的性能，两种情况下可获得的最高频率分别是多少？FPGA资源利用上有什么变化吗？ 块RAM（BRAM）是另一个预配好的模块。BRAM是一个支持多种内存形式和接口的可配置随机储存器，可以储存字节，对字，全字，双字等等等。BRAM还可以把这些数据传给本地片上总线（与可编程逻辑交流）或处理器总线（与片上处理器交流）等等接口。总体来说它有两个功能，一是芯片上各部分的数据转移，二是储存大一些的数据集。slice经过编写也可以储存数据（通过触发器），但这样做会增加额外消耗。 外部内存 BRAM 触发器 数量 1-4 几千 几百万 单个大小 GB级 KB级 比特级 总量 GB级 MB级 几百KB 宽度 8-64 1-16 1 总带宽 GB每秒 TB每秒 几百TB每秒 表格1.5:三种形式内存存储比较。外部内存存储密度最高但带宽有限，触发器拥有最好的带宽但储存容量太小，BRAM则像是两者之间的中间值。 一块BRAM通常有大约32000比特的储存容量，可以以32000 x 1比特，16000 x 2比特，8000 x 4比特等等形式存在。串联在一起可以拥有更大的容量，Vivado工具可以完成这方面的配置，而Vivado HLS的优势也在于这里，设计者不再需要考虑这一层级的细节。通常BRAM和DSP48放置在一起，对于HLS设计来说，我们可以直接把BRAM想成一个寄存器堆，它可以直接输出到一个自定义的数据路径（DSP48），可以与处理器交流，也可以像可编程逻辑上的数据路径传输数据。 思考怎样把一个很大的数组存在BRAM和可编程逻辑里。它的性能如何变化？资源使用呢？ 表格1.5是一个不同内存形式比较的表格。如表格所示，所有触发器最后可以形成一个几百KB的储存，它们每个周期都可以被读写所以总带宽非常的大，但很显然他们的储存容量不尽如人意。BRAM在不牺牲很大带宽的前提下，提供了更大的储存密度。带宽的牺牲主要在于每个周期BRAM只有1-2个入口可以被接通。外部内存对于带宽的牺牲更大，但提供了最大的容量。把应用数据放在哪里是非常关键的一个设计决定，我们会在整本书里经常提到。Vivado HLS工具也允许设计者清楚指明到底要将这段数据放在哪里。 片上晶管的繁多也丰富了我们的预配资源，片上的处理器其实就是一个很好的代表。现如今的高端FPGA会含有4个甚至更多的微处理器（比如ARM核心），小型的FPGA上附有一个处理器也变得很常见。处理器使芯片有了运行操作系统（比如Linux）的能力，它可以通过驱动和外部设备交流，可以运行更大的软件包比如OpenCV，可以运行更高级的语言（比如python）并以更快的速度运行。处理器经常成为了整个系统的控制者，协调了各方之间的数据转移，也协调了各个IP核心（包括用HLS自定义的IP核和第三方IP核）和板上资源的关系。 1.3 FPGA设计与处理 由于FPGA大小和复杂度的不断提升，设计师更倾向于从高层建造自己的设计。这样一来，FPGA设计更多是由一个个大组件，或IP核组建而成，如图1.6。在整个设计的外围临近I/O引脚的地方通常是一些少量的逻辑，它们一般用来完成关键时序和协议，比如内存控制模块，视频接口核心或模拟数字转换器。这部分逻辑我们称之为I/O接口核，通常以RTL的形式构架并需要加上其他的时序限制。时序限制的目的是阐明信号本身与信号变化规则之间的时序关系。设置限制的时候必须要考虑信号蔓延到电路板和连接装置的影响。使用I/O引脚附近逻辑的考虑是为了高速接口的实施需要，这些逻辑更适合在“高速”前提下实现数据的序列化和反序列化，时钟的恢复与分布，和精准延迟某些信号以不断从寄存器获取数据。I/O接口核心在不同的FPGA架构上差别比较大，FPGA供应商一般会有设计参考或成品部件，因此我们不会展开太多细节。 除了I/O引脚，FPGA一般会有标准核，处理器核心，片上内存核连接开关都属于标准核。标准核另外还包括原生的函数处理部件比如滤波器，FFT，编解码器等等。这些核心的参数和接入方式在不同的设计中相差很大，但它们并不是在设计中真正造成差异的部件，相反他们是相对“水平的”技术部分，可以被插入到各类不同的应用领域。FPGA厂商同样也提供这些模块，但设计师其实很少情况下接触到它们。不像IO接口核心，标准核心主要是同步电路，它除了时钟时序限制之外不大有限制。这些特点让标准核更容易在不同FPGA中兼容，当然，被转移到另一种FPGA结构中时还是需要一定优化的。 最后一种核心是针对应用的加速器核，同标准核一样，加速核通常是由时钟限制而规定的同步电路，但这些核却是系统设计师们在具体应用中不可避免要接触的部分。如果把一个设计的系统比做一道菜，那加速器核就像是秘制配方，它是让每个人的菜肴各有风味的关键。最理想的情况是设计师又快又轻松地设计出了这样的高性能核然后把它们以很快的速度集成到整个系统里，这也是我们这本书的主要目标，用HLS设计出快而高效的核。 图片1.6中的系统通过两种方法可以实现。第一种方法是把HLS产生的加速器核当作一个普通的核。用HLS创造出这种核之后把他们与IO接口核和标准核组合到一起（可以通过Vivado IP Inegrator这样的软件），这样我们就得到了完整的设计。这个方法叫做以核为基础的设计方法，与使用HLS之前的FPGA设计方法十分相似。第二种方法则着重于设计样板或平台，称为平台为基础的设计方法，这种方法下设计师先用IO接口核和标准核组合出一个样板，然后再用HLS通过壳（shell）的接口将各式算法或对象组合进去。只要壳支持双边的接口，加速器核在平台与平台之间的移动也非常容易。 1.4 设计优化 1.4.1 性能特点 在开始讨论怎么去优化之前，我们先要讨论一下判断一个设计特点的标准。计算时间就是一个衡量设计好坏的重要标准。很多人把时钟周期数作为一个同步电路性能的指标，但实际上对于两个使用不同时针的电路这是不得当的，而时针不同又是HLS下的绝大多数情况。比如说，我们现在已经规定好了Vivado HLS的输入时钟限制，那么工具根据时钟的不同会从同一段代码中产生不同的结构，所以这不是一个很恰当的比较方式。秒数是一个更好的对应比较指标。Vivado HLS工具会提供一个周期数和周期频率的报告，用户可以用此得出某段代码的操作时间。 改变时钟频率有时候可以优化设计。Vivado HLS工具把时钟频率作为一个输入，所以改变一个输入可以导致产出的结构完全不同。我们会在后文继续讨论。书中章节2.4描述了根据时钟周期决定限制。书中章节2.5讨论了改变时钟周期如何通过操作链提升产力。 我们用任务（task）这个术语来表示一个行为的基本单位，用户可以在Vivado HLS中发现与之对应的是调用函数。任务延迟就是任务开始到任务完成中间的这段时间。任务间隔则是任务开始到下一个任务开始之间的这段时间。所有的任务输入，输出和计算的时间都被算在任务延迟里，但是任务的开始并不等同于读取输入，同样任务的结束也不等同于写出输出。在很多设计中，数据率是一个很重要的东西，它同时取决于任务间隔和函数参数的多少。 图片1.7表示的是两种设计的实施设想，横向轴是时间轴（从左到右增大），纵向是设计中不同的函数单位。红色表示的是输入有关的操作，橙色表示的是输出有关的操作，正在活跃的运算符用深蓝表示，不活跃的则用浅蓝表示。每一个进入的箭头表示的是一个任务的开始，而出去的箭头表示任务的完成。左侧的图表示的是一个每个周期都执行新任务的结构设计。与之对应的是完全流水（fully-pipelined）结构。右侧表示的则是一个完全不一样的结构，系统每次读取四段输入，处理数据，然后再合成一个4段数据的输出。这种结构的任务延迟和任务间隔是一样的（13个周期），并且每一周期内只有一个任务在执行。这个结构和左边的流水形成了鲜明对比，左边的结构在同一周期内显然有多个任务在执行。HLS中的流水和处理器中的流水概念相似，但是不再使用处理器中操作分5个阶段并把结果写入寄存器堆的方法，Vivado HLS工具构造的是一个只适用于特定板子，可以完成特定程序的电路，所以它能更好的调整流水的阶段数量，初始间隔（连续两组数据提供给流水之间的间隔），函数单位的数量和种类，还有所有部件之间的互联。 Vivado HLS工具通过计算一个任务输出到输入之间这个过程需要的寄存器数来决定周期。因此，0周期的任务延迟是可以实现的，也就是组合逻辑下路径上没有任何寄存器。另一个常用的工作是计算输入输出并把结果存到寄存器里，通过这些数据找到路径上的寄存器数。这样的计算有花费很多的周期。 很多工具把任务间隔称为生产力（throughput）。这个词语听起来和间隔没什么关系。一个任务间隔的变长不可避免的会减少一段固定时间内能完成的任务数，也就是“生产的力度”。还有一些工具用延迟来描述读输入和写输出的关系。非常不幸的是，在一些复杂的设计中，任务的特点很难仅仅用输入输出来分析，比如有时候一个任务需要读很多次数据。 1.4.2 面积和产力的取舍 为了更深入的讨论使用HLS工具过程中的问题，我们需要分析一个简单但很常见的硬件函数——有限脉冲响应（FIR）滤波器。FIR会对输入做固定系数下的卷积，它可以被用作充当各式滤波器（高通，低通，带通），最简单的FIR可能就是一个移动平均滤波器。有关FIR的具体内容会在第二章展开，在这里我们从高层简要的谈一下。 #include \"stdio.h\" #define NUM_TAPS 4 void fir(int input, int *output, int taps[NUM_TAPS]); const int SIZE = 256; int main() { int taps[] = {1, 2, 0, -3, 0, 4, -5, 0, 1, -2, 0, -3, 0, 4, -5, 0}; int out = 0; for (int i = 0; i （代码样例）图片1.8:四抽头FIR滤波器的代码. 图片1.8中的C代码可以作为一个HLS的任务描述。这段代码可以直接作为Vivado HLS工具的输入，工具会自动分析并产生一个等效的RTL电路。这个过程具体细节比较复杂，我们暂时不做深究，只需要把它当作一个编译器去理解，像是gcc，只不过这个编译器输出的是RTL硬件描述。编译器的复杂性是它非常关键的原因之一，因为它不需要用户理解每一个细节。但理解编译器如何工作其实有助于设计师写出更高效的代码，这点对于HLS尤其重要，因为综合电路的构建方式有很多种，只理解它软件流是不够的。比如HLS设计师需要考虑流水，内存排布，I/O接口这些软件设计师不需要考虑的内容。 回到编译器，理解它的关键问题在于：这段代码中产生的是什么电路？这个问题的答案分多钟，还和你所用的HLS工具有关。那么通常工具有以下几种合成方式： 第一种可能的产出电路是按照顺序执行每行代码产出的电路，这时候工具就像一个简单的RISC处理器。下面的图片1.9中的代码是图片1.8中的代码在赛灵思Microblaze处理器下的汇编代码版本。虽然已经经过了优化，但还是有很多指令用来执行计算数组索引（array index）和控制循环。这样的指令我们假设它每个循环都要执行一次，那么我们在49个循环之后才能得到滤波器得出的结果。我们可以很明了的得到一个结果，那就是一个周期内执行的指令数是影响性能的一个重要的壁垒。有时候对于一个架构的提升就是让它处理的指令变得更复杂，让同一个指令能做的事情变得更多。HLS的一个特点就是在决定结构上的一些此消彼长的设计时，不再需要考虑让它适用于指令集的结构限制。在HLS设计中，设计出一个在同周期内执行成百上千个RISC级指令外加几百个周期程度流水的系统是非常常见的。 fir: .frame r1,0,r15 # vars= 0, regs= 0, args= 0 .mask 0x00000000 addik r3,r0,delay_line.1450 lwi r4,r3,8 # Unrolled loop to shift the delay line swi r4,r3,12 lwi r4,r3,4 swi r4,r3,8 lwi r4,r3,0 swi r4,r3,4 swi r5,r3,0 # Store the new input sample into the delay line addik r5,r0,4 # Initialize the loop counter addk r8,r0,r0 # Initialize accumulator to zero addk r4,r8,r0 # Initialize index expression to zero {% math_inline %}L2: muli r3,r4,4 # Compute a byte offset into the delay_line array addik r9,r3,delay_line.1450 lw r3,r3,r7 # Load filter tap lwi r9,r9,0 # Load value from delay line mul r3,r3,r9 # Filter Multiply addk r8,r8,r3 # Filter Accumulate addik r5,r5,-1 # update the loop counter bneid r5,{% endmath_inline %}L2 addik r4,r4,1 # branch delay slot, update index expression rtsd r15, 8 swi r8,r6,0 # branch delay slot, store the output .end fir 这是Vivado HLS默认下产出的是非常顺序化的结构。所谓顺序化的结构，是指循环和分支都被写作控制逻辑以控制寄存器、功能单元等部件。这其实和RISC处理器的概念相同，除了我们提到过产出的结果是RTL结构下的状态机。这种结构更倾向于限制那些使用资源去并行的功能单元。顺序化结构可以从大多数程序中生成，无需对原代码做太多的修改和优化，所以对HLS初学者非常的简单。但它同样存在一些缺陷。顺序化的结构很难解析码流，主要出于控制逻辑的复杂度。另外，控制逻辑负责规定任务延迟和任务间隔。顺序化结构的性能有时取决于处理的数据。 Vivado HLS可以产出更加流水，平行，性能上也更好的结构。其中之一叫做函数流水。函数流水结构是把函数内所有的代码都当作计算数据路径的一部分，再加上少量的控制逻辑。循环和分支被转换成无限制的结构。这种结构特点分明，容易分析，一般用于处理连续而简单的高码率数据。函数流水结构可以在更大的设计中充当组件，因为它的行为比较简单，方便共享资源，但这种结构的缺点在于适用范围相对较小，不是所有代码都可以被设计成平行结构。 用户可以通过在代码中添加#pagma HLS pipeline来指导Vivado HLS工具产生函数流水结构。这段指令需要一个参数来规划流水的起始间隔，也就是一个函数流水的任务间隔。图片1.10展示了一个可行的设计——每周期一抽头的架构。任务用到了一个乘法器和一个加法器完成滤波器。这种设计的任务间隔和任务延迟都是4个周期。图片1.11展示的是一个每周期一样本的结构，它使用了4个乘法器和3个加法器。这种设计的任务延迟和任务间隔都是1个周期，所以它每个周期都接受一个新的输入。当然这两种之外还有很多可行的设计，比如每周期两抽头设计，或每周期两样本设计，在一些特定应用中各自有各自的优势，我们将在第二章中讨论更多优化。 实际应用中，复杂的设计在顺序化和并行化的结构之间会有很多取舍的考虑。这些取舍在Vivado HLS中很大程度上取决于设计者的决定和代码内容。 1.4.3 处理速率的限制 我们看到了很多改变架构会改变任务间隔的例子，这样做通常来讲可以提升处理速率。但是读者需要意识到任何结构的任务间隔都是有一定的限度的。最关键的限制来自于递归和反馈循环，还有一些其他的例如资源限制也很重要。 递归（recurrence），这里是指某个部件的计算需要这个部件之前一轮计算的结果， 递归是限制产力的重要因素，即使在流水结构中也是如此[56，43]。分析算法中的递归并产出正确的硬件设计是非常关键的一步，同样，选择一个尽量避免很多递归的算法也是设计中非常关键的一步。 递归在很多代码结构中都会出现，比如静态变量（图片1.8），顺序的循环（图片1.10）。它存在于很多顺序化结构中，也有很多会随着改编成流水结构而消失。对于顺序化结构递归有时候不影响处理速率，但是在流水结构中是一个很不理想的状况。 另一个影响速率的关键因素就是资源限制，其中一种形式是设计边缘的跳线，因为一个同步电路中的每根跳线在每周期只能传送抓取1个比特的数据。因此，如果 int32_t f(int32_t x)这样形式的函数作为一个单独模块在100MHZ的频率和1的任务间隔下运行，它最大的数据处理量就是3.2G比特。另一种资源限制来自于内存，因为大多数内存每周期只支持一定次数的访问。还有一种资源限制来自于用户所给的限制，如果用户规定了在综合中可用的操作数，这其实是给处理率添加了限制条件。 #define NUM_TAPS 4 void block_fir(int input[256], int output[256], int taps[NUM_TAPS], int delay_line[NUM_TAPS]) { int i, j; for (j = 0; j 0; i--) { #pragma HLS unroll delay_line[i] = delay_line[i - 1]; } delay_line[0] = input; for (i = 0; i （代码样例）图片1.12：另一种FIR滤波器代码 1.4.4 代码风格 每个工程师在设计时都该问自己：我写的这段代码有最好的利用算法吗？在很多情况下，我们追求的不是结果质量达到极致，而是代码更易于更改更灵活。虽然这其实是个因人而异的风格问题，但有些代码风格确实会限制HLS工具产出的结构的质量。 举例而言，在不同的工具中输入图片1.8的代码，图片1.10和图片1.11都是可能的产出结果。但是加入了图片1.12中的那些指令之后就会一定产出特定的一种结果。这个情况下延迟线被展开，乘积的for循环都被用流水的方式实施，产出的结构会于图片1.11中的结构相似。 本章介绍了很多不同处理率的方法，其中最快的甚至到了每周期一样本的结构。但是，还有很多的应用需要更高的处理率，比如每周期多个样本。这样的设计需要怎样的代码呢？以设计一个每周期四样本的FIR滤波器为例，这样的设计需要多少资源（加法器和乘法器的数量）？与每周期一样本相比哪个资源使用更多？ 我们将会在第二章具体讨论每种优化怎样影响性能和资源使用。 1.5 重建代码 写出一个非常优化的HLS代码不是一两步就可以完成的工作，设计者必须对程序的应用有很深的理解，才能让HLS工具利用指令产生最高效的结构。 在这本书接下来内容里，我们会以应用为主题，讨论几个常见应用的综合的过程，包括数字信号处理，排序，矩阵操作，视频处理。理解算法是非常重要的一步，因为对代码的调整经常不止于加几句指令，有时候还需要重写整段。 重建代码，对于工具链来说经常变成很难读懂的行为，需要与硬件对应好关系，所以它不仅要求对算法的理解还要求对硬件微结构有比较深的理解。一般来说现成的算法原代码产出的结构比普通的CPU程序还低效，即使使用流水，展开等方法也没起到太大的作用。所以最好的方法还是自己写出一个等效但适合高层次综合的算法。 重建代码与它原来的软件版本通常区别很大。一些研究指明重建是提升效率的非常重要的一步[46,47,15,14,39]。用户在写重建代码时一定要时刻分析潜在的硬件设计。 在本书接下来的内容里，我们会展示之前提到的几个应用程序用于产出硬件结构的代码，具体包括FIR，离散傅里叶变换（DFT），快速傅里叶变换（FFT），稀疏矩阵乘矢量（SpMV)，矩阵相乘，排序，哈夫曼编码。我们会讨论重建代码对最终硬件结构的影响，具体来说，针对每一章我们计划： 强调重建代码对于高质量设计的重要性，比如在高性能和低使用面积上。 对常见的内容提供重建的代码 讨论重建对于硬件的影响 使用必要的HLS指令以实现最好的设计 整本书来说，我们的示例会引导读者从最基础的设计到更有效的设计，因为我们相信理解来自于对示例的研究。每一章会采用不一样的优化策略，包括流水，数据流，循环优化，数组分离，带宽优化等等。另外，我们也会提供对于重建代码必要的洞察训练和知识。 1.6 本书结构 就像我们之前所说的，这本书的宗旨是以示例教学。每章将展示一个应用，逐步构建HLS，并一层层的优化。每章都只会用到一小部分优化策略，每章内容的难度也是逐步增加的。第二章我们会分析相对简单的FIR滤波器，而到了第九章我们会分析复杂的视频处理系统。 我们这样的教学方法当然也是会有弊有利，我们认为好处主要体现在 ： 1）读者可以清晰的看到优化是如何具体实施的 2）每一章都会展示怎么具体的写HLS代码 3） 有些应用解释起来比较简单，但实际实施却是另外一回事，简单不完整的示例经常不够读者学习。 相对的，缺点主要在于：1）大多数应用还是要求读者对计算和背景有一定的理解，而真正理解计算部分又有时需要比较深的数学背景。例如，FFT的最好结构需要读者深入理解DFT和FFT的数学背景。出于这个原因，有一些章节（比如第四章DFT第五章FFT）以一些数学介绍为开头。有些读者认为这些数学知识对于具体实施HLS没什么帮助，但我们认为这部分内容对于代码重建是非常必需的。 2）有时候一件没那么具体的示例其实能更好的概括代码，具体示例中细枝末节反而会让读者很疑惑。 每章的结构大致相同，一般会以一些必要的背景介绍开始。对于大多数章节程序的背景介绍没有程序本身听上去那么复杂，比如第七章矩阵相乘，但是还是有例如第四章DFT这样的章节我们会介绍大量的数学知识。介绍之后我们会提供一个基准方法——一个不经过任何优化但是结果正确的HLS构建方法。然后我们就会开始介绍不同的优化。每章内容包含的优化内容也有多有少，像第三章只比较强调带宽，第二章就描述了很多优化方法。一些非常关键的优化策略会贯穿全书被多次提到。 我们建议读者按顺序阅读本书。像我们在第二章会介绍后面出现的大多数优化策略，然后在后续的章节才会对其中的一些策略深入讲解。还有应用的难度也是逐渐增长的。但其实从各应用本身的内容上来说，各章交叉不大，所以如果读者已经是一个比较有经验的HLS设计师，那么完全可以根据需要只读某几章某一章。比如说第十章排序，读者如果已经有一定的HLS基础就不需要从头开始读这本书。 下面的表格1.1提供了一个各优化的总览表，读者可以看到每章使用了哪些优化，其中第二章除了各种对于FIR滤波器的优化之外，还简单的介绍了一下HLS的设计过程。总体来说后面的章节会更注重某几个优化并详细介绍。 章节 FIR CORDIC DFT FFT SpMV 矩阵 直方图 视频 排序 哈夫曼 展开循环 x x x x x x 循环流水 x x x x x x x x 带宽优化 x x x 函数内嵌 x x 分层 x x x x x x 数组优化 x x x x x x x x 任务流水 x x x x x 测试平台 x x x x 一同仿真 x 实时计算 x x x 接口交互 x 表格1.1:一个优化策略和章节的对照表 第三章到第五章可以算作一个系列，这个系列着重于建造数字信号处理模块（CORDIC，DFT，FFT）。这些章节都侧重于某一个优化策略，比如第三章的带宽优化，第四章的数组优化，第五章的数组优化和任务流水。以第四章DFT为例，第四章介绍了数组优化，特别介绍了怎样利用数组分离来提升片上内存带宽。这一章也提到了展开循环和循环流水，并且讲述了让这些优化共存的方法。 第五章描述了快速傅立叶变换的优化，它其实本身就是DFT的一个重构代码。FFT本身就是一个阶段化很明显的算法，所以非常适合任务流水。最终版优化代码需要一些其他优化包括循环流水，展开，数组优化等。每一章其实都在附录中的项目有所关联，他们最终的集成到一起可以组成一个无线交流系统。 第六章到第十一章对更多的应用做出了讲解。第六章讲述了如何使用测试平台和RTL同仿真，还讨论了一下数组和循环的优化。这些基本的优化策略很常见，在大多数程序中都有使用。第七章介绍了数据流的实时计算这个策略。第八章展示了两种应用（前缀和，直方图），这两个应用本身相对简单，但重建他们的代码需要很小心的实行优化。第九章会用很大篇幅讲述不同接口与交互的使用，比如视频直播需要某种特定的总线与内存接口。除此之外还需要一些数组和循环的优化。第十章介绍了几种排序算法，所以自然需要很大量的优化。最后一章则是建立了一个复杂的数据压缩结构，会包含大量复杂的模块。 Copyright © xupsh.github.io 2018 all right reserved，powered by Gitbook 该文件修订时间： 2018-07-10 15:20:35 "},"02-Finite-Impulse-Response-Filters.html":{"url":"02-Finite-Impulse-Response-Filters.html","title":"第二章","keywords":"","body":"第二章 Copyright © xupsh.github.io 2018 all right reserved，powered by Gitbook 该文件修订时间： 2018-07-10 15:20:35 "},"03-CORDIC.html":{"url":"03-CORDIC.html","title":"第三章","keywords":"","body":"第三章 Copyright © xupsh.github.io 2018 all right reserved，powered by Gitbook 该文件修订时间： 2018-07-10 15:20:35 "},"04-Discrete-Fourier-Transform.html":{"url":"04-Discrete-Fourier-Transform.html","title":"第四章","keywords":"","body":"第四章 离散傅里叶变换 本章介绍了DFT，并将重点放在了介绍了DPT在FPGA实现中的算法优化。DFT运算的核心是以一组固定系数执行矩阵向量乘法。在4.6章节中，我们首先将DFT运算初始优化集中在将其简化为矩阵 - 向量乘法，随后介绍了DFT使用Vivado HLS代码的完整实现方式。 另外，我们也描述了如何最佳地优化DFT计算以增加吞吐量。第4.5章中，我们将的优化工作集中在阵列分区优化上。 本章的前两小节有大量的数据计算和推导，这可能看起来有些多余，但是它对于我们充分理解代码重构优化以下一章快速傅里叶变换的对称性计算有着很大作用。但是如果你对HLS 优化内容更感兴趣，可以直接跳至第4.6章开始阅读。 4.1 傅里叶级数 为了解释离散傅里叶变换，我们首先要了解傅里叶级数。傅立叶级数提供了一种可选方法来观察信号从-π到π的一个周期内的连续实值周期信号。Jean Baptiste Joseph Fourier的开创性成果表明，在2π周期内任何连续的周期性信号都可以用周期为2π的余弦和正弦和表示。最终，傅里叶级数的表现形式如下： f(t)∼a02+a1cos(t)+a2cos(2t)+a3cos(3t)+⋯b1sin(t)+b2sin(2t)+b3sin(3t)+⋯∼a02+∑n=1∞(ancos(nt)+bnsin(nt)(4.1) \\begin{aligned} f(t)\\sim\\frac{a_{0}}{2}+a_{1}cos(t)+a_{2}cos(2t)+a_{3}cos(3t)+\\cdots \\\\ b_{1}sin(t)+b_{2}sin(2t)+b_{3}sin(3t)+\\cdots \\\\ \\sim\\frac{a_{0}}{2}+{\\sum_{n=1}^{\\infty}}(a_{n}cos(nt)+b_{n}sin(nt) \\end{aligned} \\quad(4.1) f(t)∼2a0​​+a1​cos(t)+a2​cos(2t)+a3​cos(3t)+⋯b1​sin(t)+b2​sin(2t)+b3​sin(3t)+⋯∼2a0​​+n=1∑∞​(an​cos(nt)+bn​sin(nt)​(4.1) 其中参数a0,a1,⋯a_{0},a_{1},\\cdotsa0​,a1​,⋯和b0,b1,⋯b_{0},b_{1},\\cdotsb0​,b1​,⋯的计算公式如下： a0=1π∫−ππf(t)dta_{0}=\\frac{1}{\\pi}\\int_{-\\pi}^{\\pi}f(t)dta0​=π1​∫−ππ​f(t)dt an=1π∫−ππf(t)cos(nt)dt(4.2)a_{n}=\\frac{1}{\\pi}\\int_{-\\pi}^{\\pi}f(t)cos(nt)dt\\quad\\quad(4.2)an​=π1​∫−ππ​f(t)cos(nt)dt(4.2) bn=1π∫−ππf(t)sin(nt)dtb_{n}=\\frac{1}{\\pi}\\int_{-\\pi}^{\\pi}f(t)sin(nt)dtbn​=π1​∫−ππ​f(t)sin(nt)dt 有几个需要注意的点是：首先式4.2中的参数a0,a1,⋯a_{0},a_{1},\\cdotsa0​,a1​,⋯,b0,b1,⋯b_{0},b_{1},\\cdotsb0​,b1​,⋯被称作傅里叶参数。其中参数 a0a_{0}a0​ 被称作直流分量（来自于对早期电流分析的参考），其中n=1频率分量称为基波，而其他频率（n≥2）分量统称为高次谐波。基波和高次谐波的概念来自声学和音乐。其次，函数f以及cos()和sin()函数都有2π个周期; 我们很快就会展现如何将这个周期改变为其他值。 直流分量a0a_{0}a0​等同于cos(0·t)=1时的系数，因此使用符号a。因为sin(0·t)=0，所以不需要 b0b_{0}b0​ 的值。最后，在某些情况下，函数f和它的傅里叶级数之间是近似相等的关系，这种不连续的现象我们称之为吉布斯现象。而这是只是一个仅与傅里叶级数有关的小问题，与其他傅立叶变换无关。 因此，今后我们将忽略式[4.1]中的“近似”（〜），直接视为“相等”（=）。 表示除π以外的周期性函数需要对变量进行简单的更改。 假设一个函数的周期范围在[-L,L]而不是[-π,π],则设： t≡πt′L(4.3)t\\equiv\\frac{\\pi t^{'}}{L}\\quad(4.3)t≡Lπt′​(4.3) 以及 dt≡πdt′L(4.4)dt\\equiv\\frac{\\pi{d} t^{'}}{L}\\quad(4.4)dt≡Lπdt′​(4.4) 这是一个简单地将周期区间从[-π,π]变换到期望的[-L,L]的一个线性方程，将t′=Ltπt^{'}=\\frac{Lt}{\\pi}t′=πLt​ 代入到式4.1得： f(t′)=a02+∑n=1∞(ancos(nπt′L)+bnsin(nπt′L))(4.5) f(t^{'})=\\frac{a_{0}}{2}+{\\sum_{n=1}^{\\infty}}(a_{n}cos(\\frac{n\\pi{t^{'}}}{L})+b_{n}sin(\\frac{n\\pi{t^{'}}}{L}))\\quad(4.5) f(t′)=2a0​​+n=1∑∞​(an​cos(Lnπt′​)+bn​sin(Lnπt′​))(4.5) 用同样的方法解得a和b的各项参数可解得： a0=1L∫−LLf(t′)dt′a_{0}=\\frac{1}{L}\\int_{-L}^{L}f(t^{'})dt^{'}\\quada0​=L1​∫−LL​f(t′)dt′ an=1L∫−LLf(t′)cos(nπt′L)dt′(4.6)a_{n}=\\frac{1}{L}\\int_{-L}^{L}f(t^{'})cos(\\frac{n\\pi{t^{'}}}{L})dt^{'}\\quad(4.6)an​=L1​∫−LL​f(t′)cos(Lnπt′​)dt′(4.6) bn=1L∫−LLf(t′)sin(nπt′L)dt′b_{n}=\\frac{1}{L}\\int_{-L}^{L}f(t^{'})sin(\\frac{n\\pi{t^{'}}}{L})dt^{'}\\quad\\quadbn​=L1​∫−LL​f(t′)sin(Lnπt′​)dt′ 我们也可以利用欧拉公式 ejnt=cos(nt)+jsin(nt)e^{jnt}=cos(nt)+jsin(nt)ejnt=cos(nt)+jsin(nt) 来得出一个更简洁的公式。 f(t)=∑n=−∞∞cnejnt(4.7)f(t)=\\sum_{n={-\\infty}}^{\\infty}c_{n}e^{jnt}\\quad(4.7)f(t)=n=−∞∑∞​cn​ejnt(4.7) 其中，傅里叶参数cnc_{n}cn​ 是一个较为复杂的指数表达式： cn=12π∫−ππf(t)e−jntdt(4.8)c_{n}=\\frac{1}{2\\pi}\\int^{\\pi}_{-\\pi}f\\left(t\\right)e^{-jnt}dt\\quad(4.8)cn​=2π1​∫−ππ​f(t)e−jntdt(4.8) 假设f(t)是一个具有2π个周期的周期函数，将这个公式与式4.1等效，傅里叶参数an,bn,andcna_{n},b_{n}, and\\,c_{n}an​,bn​,andcn​ 之间的数值关系为: an=cn+c−nforn=0,1,2,⋯a_{n}=c_{n}+c_{-n}forn=0,1,2,\\cdots\\quad\\quadan​=cn​+c−n​forn=0,1,2,⋯ bn=j(cn−c−n)forn=0,1,2,⋯b_{n}=j(c_{n}-c_{-n})forn=0,1,2,\\cdots\\quad\\quadbn​=j(cn​−c−n​)forn=0,1,2,⋯ Cn={12(an−jbn)n>012a012(a−n+jb−n)n0(4.9) C_{n}=\\begin{cases}\\frac {1}{2}\\left( a_{n}-jb_{n}\\right) n >0\\\\ \\frac {1}{2}a_{0}\\\\ \\frac {1}{2}\\left( a_{-n}+jb_{-n}\\right) n Cn​=⎩⎪⎨⎪⎧​21​(an​−jbn​)n>021​a0​21​(a−n​+jb−n​)n0​(4.9) 我们需要注意的是参数an,bn,cna_{n},b_{n},c_{n}an​,bn​,cn​ 的公式中引入了“负”频率的概念。虽然从物理的角度上看它没有实际意义，但在数学上我们可以将其视为复平面上的“负”旋转。正频率表示复数在复平面上以逆时针方向旋转，负频率表示我们在复平面上以顺时针方向旋转。 余弦，正弦和复指数之间的关系更加证明了上面这个理论，余弦既可以看作复指数的实数部分，也可以推导为一个正频率和一个负频率两个复指数的和，如式4.10所示。 cos(x)=Re(ejx)=eix+e−jx2cos(x)=Re\\left(e^{jx}\\right) =\\dfrac{e^{ix}+e^{-jx}}{2}cos(x)=Re(ejx)=2eix+e−jx​ 正弦和复指数之间的关系如式4.11所示，与余弦的不同点在于这里我们减去负频率并除以2j。 sin(x)=Im(ejx)=eix−e−jx2jsin(x)=Im\\left(e^{jx}\\right) =\\dfrac{e^{ix}-e^{-jx}}{2j}sin(x)=Im(ejx)=2jeix−e−jx​ 这两种正余弦和复指数之间的关系都可以用复平面矢量图的形式来理解，如下图4.1所示。图4.1中a)部分显示了余弦的推导过程，这里我们添加两个复平面向量ejxe^{jx}ejx and e−jxe^{-jx}e−jx，图中可以看出这两个向量和是一个在实轴上的向量，大小为2cos(x)。所以，当我们将这两个向量的和除以2就到了式4.10中的cos(x)的值。图4.1中b)部分显示了类似的正弦的推导过程，这里我们添加两个复平面向量ejxe^{jx}ejx and e−jxe^{-jx}e−jx，图中可以看出这两个向量差是一个在虚轴上的向量，大小为2sin(x)。所以，当我们将这两个向量的差除以2j就到了式4.11中的sin(x)的值。 4.2 DFT背景介绍 上一节我们探究了傅里叶级数的分析数学基础，证明了它对于周期连续性信号的作用，而离散傅里叶变换是针对于离散的周期信号的。DFT可以将有限数量的等间隔样本转换为有限数量的复数正弦曲线。换句话说，它将一个采样函数从一个域（通常是时域）转换到频域。复数正弦曲线的频率取为与输入函数的采样周期相关的频率的基频的整数倍。离散信号和周期信号最重要的关联在于它可以用一组有限的数字表示。因此，可以使用数字系统来实现DFT。 ejxe^{jx}ejx and e−jxe^{-jx}e−jx 的和。 这个求和的结果恰好落在实值轴上，其值为2cos(x)。b）部分显示了一个类似的总和，只是这次对矢量ejxe^{jx}ejx and −e−jx-e^{-jx}−e−jx 求和。 这个总和落在虚轴上，其值为2sin(x).\"> DFT适用于同时包含实数和复数的输入函数。直观上，为了轻松入门，我们暂时忽略复数部分，从实数信号开始了解实际DFT的工作原理。 关于术语的简要说明：我们使用小写函数变量来表示时域中的信号，大写函数变量来表示频域中的信号。我们使用（）表示连续函数，用[ ]表示离散函数。例如，f（）是连续的时域函数，F（）是其连续的频域表示。类似地，g[]是时域中的离散函数，G[]是将该函数转换到频域。 让我们从图4.2开始分析，左图是一个具有N个样本或从0到N-1运行的点的实值时域信号g[]。当我们用DFT分析时域信号时，会得出对应于各个频率的余弦和正弦幅度的频域信号。这些可以看作是余弦幅值对应复数的实数值，而正弦幅值对应复数的虚数的复数，其中包含有有N/2+1个余弦（实数）和N/2+1个正弦（虚数）值。我们称之为复频域函数G []。注意，频域中样本的数量为（N/2+1）是由于我们正在分析一个只包含实数的时域信号，复数时域信号经过DFT后将变为具有N个样本的频域信号。 一个具有N个样本点的DFT可以通过一个N×N矩阵乘以一个大小为N的矢量来确定。G = S·g其中 [111…11ss2…sN−11s2s4…s2(N−1)1s3s6…s3(N−1)⋮⋮⋮⋱⋮1sN−1s2N−1…s(N−1)(N−1)](4.12) \\begin{bmatrix} 1 & 1 & 1 &\\ldots &1\\\\ 1 & s &s^{2} &\\ldots &s^{N-1}\\\\ 1 & s^{2} &s^{4} &\\ldots &s^{2(N-1)}\\\\ 1 & s^{3} &s^{6} &\\ldots &s^{3(N-1)}\\\\ \\vdots& \\vdots &\\vdots &\\ddots &\\vdots\\\\ 1 & s^{N-1} &s^2{N-1} &\\ldots &s^{(N-1)(N-1)} \\end{bmatrix}\\quad(4.12) ⎣⎢⎢⎢⎢⎢⎢⎡​1111⋮1​1ss2s3⋮sN−1​1s2s4s6⋮s2N−1​…………⋱…​1sN−1s2(N−1)s3(N−1)⋮s(N−1)(N−1)​⎦⎥⎥⎥⎥⎥⎥⎤​(4.12) 和s=e−i2πNs=e^{\\frac{-i2\\pi}{N}}s=eN−i2π​。 因此，频域中的样本被推导为 G[t]=∑n=0N−1g[n]sknfork=0,…,N−1(4.13)G[t]=\\sum_{n={0}}^{N-1}g[n]s^{kn}\\quad for \\; k=0,\\ldots,N-1\\quad(4.13)G[t]=n=0∑N−1​g[n]sknfork=0,…,N−1(4.13) 图4.3提供了8个样本点的DFT操作的系数的可视化分析图。八点频域采样是通过将8个时域采样与S矩阵的对应行相乘而得到的。S矩阵的行0对应于与时域采样的平均值成比例的DC分量。将S矩阵的第1行与g相乘，得出围绕单位圆圈旋转一圈时的余弦和正弦振幅值。由于这是一个8点DFT，这意味着每个相位偏移45°。执行8个45°旋转将围绕单位圆完整旋转一圈。第2行是相似的，唯一不同点是围绕单位圆执行两次旋转，即每次旋转90°。这是一个更高的频率。第3排做三次旋转; 第4排四轮旋转等等。每一个这样的行时间列乘法中都给出了适当的频域样本。 我们可以注意到S矩阵是对角对称矩阵，即S[i][j]=S[j][i]S[i][j]=S[j][i]S[i][j]=S[j][i]。另外，S[i][j]=sisj=si+jS[i][j]=s^{i}s^{j}=s^{i+j}S[i][j]=sisj=si+j。在第四行周围也会出现有趣的对称性现象。行3和行5中的相量是彼此的共轭复数，即S[3][j]=S[5][j]∗S[3][j]=S[5][j]^{\\ast}S[3][j]=S[5][j]∗。 类似地，行2和6 (S[2][j]=S[6][j]∗)(S[2][j]=S[6][j]^{\\ast})(S[2][j]=S[6][j]∗) 以及行1和7 (S[1][j]=S[7][j]∗)(S[1][j]=S[7][j]^{\\ast})(S[1][j]=S[7][j]∗) 都是彼此的共轭复数。 正是由于这个原因，具有N个采样点的实值输入信号的DFT在频域中仅具有N/2+1个余弦和正弦值。剩余的N/2个频域值提供了冗余信息，因此不需要它们。然而，当输入信号复杂时，情况并非如此。在这种情况下，频域将有N+1个余弦和正弦值。 #define SIZE 8 typedef int BaseType; void matrix_vector(BaseType M[SIZE][SIZE], BaseType V_In[SIZE], BaseType V_Out[SIZE]) { BaseType i, j; data_loop: for (i = 0; i 图4.4 实现矩阵向量乘法的简单代码 4.3 矩阵向量乘法的优化 矩阵向量乘法是DFT计算的核心，输入的时域向量将乘以一个固定特殊值的矩阵，输出的结果是与输入时域信号表示相对应的频域矢量。 在本节中，我们讨论如何在硬件中实现矩阵向量乘法。我们把这个问题分解成最基本的形式（见图4.4）。这让我们能够更好地将讨论集中在算法优化上，而不是集中在使用功能正确的DFT代码的所有难点上。在下一节中我们将构建一个DFT内核。 图4.4中的代码提供了将该算法实现到硬件中的原始形式，代码中使用当前被映射为浮点型的BaseType的自定义数据类型。虽然这在刚开始看起来可能是多余的，但是可以方便我们在将来轻松地将变量（例如，具有不同精度的有符号或无符号的定点）进行不同的数字表示。 matrix_vector 功能共有三个参数，我们对前两个参数进行乘法计算，输入矩阵和向量分别是 BaseType M[SIZE][SIZE] 和 BaseType V In[SIZE]。第三个参数 BaseType V_Out[SIZE] 是合成向量。我们将M=S和V_in设为采样时域信号，则Vout将包含DFT。SIZE是决定输入信号中样本数量的常数，相应地也决定了DFT的大小。 这个算法本身只是一个嵌套的for循环。内部循环（ dot_product_loop）从0至SIZE-1计算DFT的系数。但是，这个相对简单的代码在映射到硬件执行时，就有许多种设计方案可选择。 无论何时执行HLS，你都应该考虑希望合成怎样的结构体系。内存结构的组织在这个过程中显得尤为重要。这个问题可以归结为你将代码中的数据存储到哪里？因为将变量映射到硬件时有许多选项。该变量可能只是一组信号（如果它的值永远不需要在一个周期内保存）、寄存器、RAM或FIFO。但所有这些选项都需要你在速度和面积之间作出折衷的选择。 另一个我们需要考虑的重要因素是代码并行度的可用性。纯粹的顺序代码到硬件上实现相当困难。换句话说，一个具有足够并行可行性的代码，从纯粹顺序执行到完全并行实现有一个可以选择的实现自由度。这样的选择显然会带来不同的面积和速度。我们将研究内存配置和并行性如何影响DFT矩阵向量的硬件实现。 图4.5显示了包含一个乘法和一个加法运算符的矩阵向量乘法的顺序结构。我们创建逻辑以访问存储在BRAM中的V_In和矩阵M。计算V_Out的每个元素并存储到BRAM中。这种体系结构本质上是将图4.4中的代码合成为无指令的结果。它不占用大量面积，但任务延迟和任务间隔相对较大。 4.4 流水线和并行运行 在矩阵乘法的例子中，我们可以很大程度地利用并行思想来解决问题。首先关注每次迭代循环执行的内部循环表达式 sum+=Vin[j]∗M[i][j]sum+= V_in [j] * M [i] [j]sum+=Vi​n[j]∗M[i][j]。乘法运行时，计数变量SUM在每次迭代中都被重复利用并赋予新的值。如图4.6所示，这个内部循环可以重新表述，此时变量 SUM 已被完全消除，并在较大表达式中替换为多个中间值。 #define SIZE 8 typedef int BaseType; void matrix_vector(BaseType M[SIZE][SIZE], BaseType V_In[SIZE], BaseType V_Out[SIZE]) { BaseType i, j; data_loop: for (i = 0; i 图4.6: 手动展开矩阵向量乘法内部循环实例 循环的展开可以由Vivado HLS在流水线上下文中自动执行,也可以通过使用#pragma HLS展开或者流水线上下文外的等价指令来实现。 我们应该已经发现替换内部循环的新表达式应具有大量的并行性。如此而来每个乘法可以同时执行，并且可以使用加法器树来执行求和。这个计算的数据流图如图4.7所示。 如果我们希望展开内循环的表达式的任务延迟最小，那么所有的八个乘法运算都应该并行执行。假设乘法有3个周期的延迟且加法有1个周期的延迟，则所有V_In[j]∗M[i][j]V\\_In[j] * M [i][j]V_In[j]∗M[i][j] 操作在第三周期结束时完成。使用加法器树对这八个中间结果进行求和需要log8=3log8 = 3log8=3个周期。因此，对于每次迭代，数据循环主题将共有6个周期的延迟，并且需要8个乘法器和7个加法器，如图4.8左侧所示。需要注意的是，如果在循环4-6中重复使用加法器，这会将加法器的数量减少到4个。但是，在FPGA上加法器通常是无法共享的，因为加法器和多路复用器需要相同数量的FPGA资源（对于2输入运算，大约1个LUT每比特）。 如果我们不愿意使用8个乘法器，则可以增加执行该功能的周期数量来减少资源使用量。例如，使用4个乘法器会使得8个V_In[j]∗M[i][j]V\\_In [j] * M [i] [j]V_In[j]∗M[i][j] 乘法操作带来6个周期的延迟，那么完成整个数据循环体将会有9个周期的总延迟，如图4.8的右侧所示。为了使用更少的乘法器，我们需要牺牲更多的时间周期来完成内部循环。 从图4.8中我们可以明显看出有很多重要的时间段并没有执行有效的工作，因而降低了设计的总体效率。我们应该尽量缩短这些时间来提高效率。在这种情况下，可以发现data_loop的每次迭代实际上是完全独立的，这意味着它们可以同时执行。正如我们展开dot_product_loop一样，也可以展开数据循环并同时执行所有的乘法运算。但是，这需要大量的FPGA资源。我们还有更好的选择是尽快地启动循环的每次迭代，意味着前一次循环仍在执行。这个过程被称为循环流水线化，我们通过#pragma HLS pipeline在Vivado HLS中实现。 在大多数情况下，循环流水线会减少循环的间隔时间，但不会影响延迟时间。循环流水线的实现如图4.9所示。 截至目前，我们的关注点集中在操作运行的延迟上。功能单元通常也是流水线式的，Vivado HLS中的大多数功能单元都是间隔为1的流水线式的。尽管单次乘法操作可能需要3个周期才能完成，但新的乘法操作可以从流水线乘法器的每个时钟周期开始。通过这种方式，单个功能单元可以同时执行多个乘法操作。例如，有3个周期延迟且间隔为1的乘数可以同时执行三次乘法运算。 充分利用流水线乘法器的优势就在于我们就可以在不添加额外运算符的前提下减少内部循环的延迟。图4.10中左边展示了使用三个流水线乘法器一种可能的实现方式。在这种情况下，乘法操作可以并发执行（因为它们没有数据依赖性），而加法操作只有在第一次乘法完成之后才能开始。在右图中，显示了该设计间隔为3的流水线版本，如果将#pragma HLS pipeline II=3应用于data_loop，则与Vivado R HLS的结果类似。这样不仅个别操作在同一个操作符上并发执行，而且这些操作可能来自于不同data_loop的迭代。 现在你可能已经观察到，我们可以在不同的层次级别上进行流水线操作，包括算法级别，循环级别和功能级别。此外，不同级别的流水线在很大程度上也是独立的！我们可以在顺序循环中使用流水线操作符，或者我们可以使用顺序操作符来构建流水线循环，也可以构建大型功能的流水线实现。这些功能可以像原始运算单元一样在Vivado HLS 中共享。我们实例化了多少运算单元，它们的个体成本以及使用频率如何才是最重要的。 4.5 存储权衡和数据分区 到了本小节，我们已经假定数组中的数据 V_In[],M[][]和V_Out[]可以随时访问，但是实际上，数据的放置的位置对整个处理器的性能和资源使用情况有重要影响。在大多数处理器系统中，内存架构是固定的，我们只能调整程序以尝试最大程度地利用可用的内存层次结构，例如注意尽可能减少寄存器溢出和缓存丢失。在HLS设计中，我们还可以利用不同的存储器结构，并尝试找到最适合特定算法的存储器结构。通常，大量数据存储在片外存储器如DRAM、闪存或网络连接的存储器中，但是数据访问时间通常很长，大约为几十到几百（或更多）个周期。由于大量的电流必须流过长电线已访问片外存储器，所以使用片外存储消耗的能量也比较大。相反，片上存储器可以快速访问并且功耗要低得多，只是它可以存储的数据量有限。有一种常见的操作模式类似于通用CPU的内存层次结构中的缓存效果，它是将数据重复地加载到块中的片上存储器上。 当我们选择片上存储器的时候，需要在嵌入式存储器（例如Block RAM）或触发器（FF）之间权衡。基于触发器的存储器允许在一个时钟内对不同地址的数据进行多次读取，也可以在一个时钟周期内读取、修改和写入基于触发器的存储器。然而，即使在资源配置最好的设备中，FF的数量通常也限制在大约10万字节左右。实际上，以便有效地使用其他FPGA资源，大多数基于FF的存储器应该小得多。Block RAM（BRAM）提供更高的容量，拥有Mbytes的存储量，其代价是有限的可访问性。例如，单个BRAM可以存储大于1到4千字节的数据，但是在每个时钟周期只可以对该数据的两个不同的地址进行访问。此外，BRAM需要尽可能减少流水线操作（比如，读操作必须具有至少一个周期的延迟）。因此，我们的基本的权衡点在于工程所需的带宽与容量。 如果说数据的吞吐量我们需要考虑的头号问题，则所有数据都将存储在FF中。这将允许任何元素在每个时钟周期内被访问尽可能多的次数。但是，随着矩阵阵列变大，这种方案也将变得不可行。在矩阵向量乘法的情况下，存储1024位乘以1024位矩阵的32位整数将需要大约4兆字节的存储器。即使使用BRAM来存储，由于每个BRAM存储大约4KBytes，也需要大约1024个BRAM块。另一方面，使用单个大型基于BRAM的内存意味着我们一次只能访问两个元素。这明显降低了性能，如图4.7所示，它需要在每个时钟周期访问多个数组元素（V_In[]的所有8个元素以及M[][]的8个元素）。在实际工程中，大多数设计需要更大的阵列分布存放在更小的BRAM存储器中，这种方法称为阵列分区。较小的数组（通常用于索引较大的数组）可以完全划分为单独的标准变量并映射到FF。匹配流水线选择和数组分区以最大限度地提高运算符使用率和内存使用率是HLS设计探索的一个重要方面。 Vivado HLS 将自动执行一些阵列分区，但由于阵列分区倾向于某些特定设计，因此通常需要我们利用好工具以获得最佳结果。阵列分区的全局配置可在config_array_partiton选项中找到。单个数组可以使用array_patition指令来显示分区，并将指令数组分区完成将数组的每个元素分解到它自己的寄存器中，最终形成基于FF内存。与许多其他基于指令的优化一样，通过手动重写代码也可以实现相同的效果。一般情况下，最好使用工具指令，因为它避免了引入错误并易于代码维护。 回到图4.4中的矩阵向量乘法代码，我们可以通过添加几个指令来实现高度并行，如图4.11所示，最终的体系结构如图4.12所示。请注意，内部j循环由Vivado HLS 自动展开，因此j在每次使用的时候都被替换为常量。此设计演示了阵列分区的最常见用法，其中分区的数组维度（在本例中为V_In[]和第二维的M[][]）都被索引为常量（在本例中为循环索引j来展开循环）。这使得多路复用器可以无需访问分区阵列架构。 我们还可以用更少的乘法器降低性能以实现其他设计。例如，在图4.10中，这些设计只使用三个乘法器，因此我们只需要在每个时钟周期读取三个矩阵M[][]和矢量V_in[]的元素。完全分割这些数组会导致额外的多路复用，如图4.13所示。实际上，阵列只需要分成三个物理存储器。同样，这种分区可以通过重写代码手动实现，也可以使用array_patition循环指令在Vivado HLS中实现。 让我们从包含数据的矩阵X来分析： #define SIZE 8 typedef int BaseType; void matrix_vector(BaseType M[SIZE][SIZE], BaseType V_In[SIZE], BaseType V_Out[SIZE]) { #pragma HLS array_partition variable=M dim=2 complete #pragma HLS array_partition variable=V_In complete BaseType i, j; data_loop: for (i = 0; i 图4.11 选用阵列分割和流水线操作的矩阵向量乘法 相似地，如果我们使用 array_patition variable=x factor=2 block 指令可以将它分为两个矩阵向量： 让我们来研究一下变化的流水线II和阵列分区对性能和面积的影响，比较根据每秒的矩阵向量乘法运算（吞吐量）和根据展开阵列分区因子的数量的性能高低，并绘制相同的区域趋势图（如显示LUT，FF，DSP模块，BRAM）。再思考这两种情况的总趋势是什么？你会选择哪种设计？为什么？ 通过流水线操作并将部分循环展开应用于 dot_product_loop，我们也可以得到类似的结果。图4.14显示了将矩阵向量乘法代码的内部循环展开2倍的结果。你可以发现，循环的边界现在增加到2；每个循环迭代需要2个矩阵M[][]和向量Vin[]每次迭代并执行两次乘法而不是一次。使用这种方式循环展开后，对应于原始循环的两次迭代，Vivado HLS可以并行地在两个表达式中实现这些操作。请注意，如果没有适当的数组分区，展开内部循环可能不会提高性能，因为并发读取操作的数量受到内存端口数量的限制。在这种情况下，我们可以将来自偶数列的数据存储在一个BRAM中，将来自奇数列的数据存储在另一个BRAM中。这是因为展开的循环总是执行一次偶数迭代和一次奇数迭代。 #define SIZE 8 typedef int BaseType; void matrix_vector(BaseType M[SIZE][SIZE], BaseType V_In[SIZE], BaseType V_Out[SIZE]) { #pragma HLS array_partition variable=M dim=2 cyclic factor=2 #pragma HLS array_partition variable=V_In cyclic factor=2 BaseType i, j; data_loop: for (i = 0; i 图4.14 内部循环展开2倍的矩阵向量乘法代码。 HLS工具可以使用 unroll 指令自动展开循环。该指令采用一个因子作为参数，它是一个正整数，表示循环体应该展开的次数。 使用 array_partition cyclic factor = 2 指令和将 M[][]和向量 V_in[]手动划分为单独的数组有着相同的效果。考虑一下应该如何修改代码才能更改访问模式呢？ 现在我们手动将循环展开为两倍。原始代码（没有数组分区和不展开），只执行数组分区的代码，同时执行数组分区和循环展开代码之间的性能结果有哪些不同呢？ 最后，使用指令执行数组分割和循环展开的结果与手动执行的结果相比有哪些不同呢？ 在这段代码中，我们看到数组分区通常与流水线操作并行执行。通过2倍的数组分割可以使性能提高2倍，我们可以用将内环部分展开2倍或将外环的II减少2倍来实现。提升性能需要相应数量的阵列分区。在矩阵向量乘法中，这种关系相对简单，因为对内部循环中的每个变量只有一次访问权限。在其他代码中，关系可能更复杂。无论如何，设计者的目标应该是确保例化的FPGA资源得到有效利用。一般情况下，将性能提高2倍将使用大约两倍的资源，相反将性能降低2倍可以节约一半的资源。 让我们来研究一下循环展开和阵列分区对性能和面积的影响，比较根据每秒的矩阵向量乘法运算（吞吐量）和根据展开阵列分区因子的数量的性能高低，并绘制相同的区域趋势图（如显示LUT，FF，DSP模块，BRAM）。再思考这两种情况的总趋势是什么？你会选择哪种设计？为什么？ 4.6 Baseline实现 上一节中我们讨论了执行DFT的核心计算——矩阵向量乘法的一些优化方法。然而将矩阵向量乘法转移到功能完备的DFT进行硬件实现，还会出现其他问题。在本节中，我们将重点转移到DFT，并讨论如何优化以使其执行起来最有效。 处理大量复杂数字的能力是这一节我们需要着重考虑的点之一。如4.2节所述，因为S矩阵的元素是复数，所以实值信号的DFT几乎总是一个复数值信号。执行复数值信号的DFT以产生复数值结果也很常见。此外，我们需要处理分数或可能的浮点数据，而不是整数。这会增加实现的成本，尤其是需要执行浮点操作的时候。另外，浮点运算符（特别是加法运算符）比整数加法具有更大的延迟。这可以使得II = 1的循环更难以实现。第二个变化是我们希望能够将我们的设计容量扩展到一个大输入矢量的大小，比如N = 1024个输入样本。然而如果我们直接使用矩阵向量乘法，那么我们必须存储整个S矩阵。由于这个矩阵是输入大小的平方，因此这么大的一个输入矢量的存储实现起来比家里困难。本章我们将讨论解决这两个复杂问题的技巧。 正如使用HLS创建硬件实现时的典型实例一样，让我们从简单代码的实现开始。这里我们有一个可以保证它具有正确的功能baseline代码。通常，这些代码都以非常连续化的方式运行;它没有高度优化，因此可能无法达到所需的性能指标。但是，这是确保设计人员理解算法功能的必要步骤，并且可以作为未来优化的起点。图4.15显示了DFT的baseline实现。这使用双重嵌套for循环。内部循环将S矩阵的一行与输入信号相乘。该代码不是将S矩阵作为输入读取，而是基于当前循环索引，在内部循环的每次迭代中计算S中的元素。我们使用cos()和sin()函数将该相量转换为具有实部和虚部的笛卡尔坐标。该代码可将相量与适当采样的输入信号相乘并累加结果。经过该内环的N次迭代之后，每个S矩阵的列元素都被计算得出一个频域样本。外循环也迭代了N次，S矩阵的每一行都被迭代一次。最终，代码计算了N次矩阵W的表达式，但是cos()和sin()函数以及复数乘加计算进行了 n2n^{2}n2 次。 此代码使用函数调用来计算cos()和sin()值。Vivado HLS能够使用其内置的数学库来实现这样的数学计算。第3章介绍了用于实现三角函数（包括CORDIC）的几种可能的算法[22]。但是，要使这些函数生成精确的结果可能代价比较高。因为输入量不是任意的，取消这些函数调用也有几种方法。我们将在稍后更详细地讨论这些权衡方法。这个代码的顺序执行代码如图4.16所示。 #include //Required for cos and sin functions typedef double IN_TYPE; // Data type for the input signal typedef double TEMP_TYPE; // Data type for the temporary variables #define N 256 // DFT Size void dft(IN_TYPE sample_real[N], IN_TYPE sample_imag[N]) { int i, j; TEMP_TYPE w; TEMP_TYPE c, s; // Temporary arrays to hold the intermediate frequency domain results TEMP_TYPE temp_real[N]; TEMP_TYPE temp_imag[N]; // Calculate each frequency domain sample iteratively for (i = 0; i 图4.15：DFT的baseline code 如果你要使用你设计的CORDIC（如从第3章开始），那么此代码需要做什么修改？ 改变CORDIC核心的准确性会使DFT硬件资源使用情况发生变化吗？ 它会如何影响性能？ 请使用HLS实现DFT的基线代码，实现后查看报告，与乘法和加法相比，实现三元函数的相对成本是多少？ 对哪些操作尝试优化更有意义？通过流水线操作内循环可以实现什么性能？ 4.7 DFT优化 上一节的基线的DFT实现使用了相对较高的 double 数据类型。实现浮点运算尤其是双精度浮点运算通常代价很高并且需要很多流水线操作。我们可以从图4.16中看到这显着影响了循环的性能。通过流水线操作，这些高延迟操作的影响不那么重要，因为可以同时执行多个循环执行。此代码中的例外是用于累加结果的变量temp real []和temp imag []。这个累加是一种循环，并在流水线化内循环时限制了可实现的II。该运算符的依赖性如图4.17所示。 一种可能的解决方案是降低计算的精度。这种方法在实际应用时是有价值的，因为它减少了每个操作所需的资源，减少了存储值所需的内存，并且通常也减少了操作的延迟。例如，我们可以使用32位浮点型或16位半型来替代双精度型。许多信号处理系统完全避免了浮点数据类型，并使用定点数据类型3.5。对于常用的整数和定点精度，每个加法可以在一个循环中完成，从而使循环在II = 1处流水线化。 如果将所有数据类型从双精度型更改为浮点型，那么图4.15中的代码综合结果会发生什么变化？还是从一倍到一半？或到一个固定的点值？这是如何改变性能（间隔和延迟）和资源使用情况的？它是否会更改输出频率域采样值？ 用浮点累加实现II = 1的普适解决方案是用不同的顺序处理数据。看图4.17，我们看到由于j循环是内部循环，所以重复是存在的（用箭头表示）。如果内循环是i循环，那么在下一次迭代开始之前我们就不需要累加的结果。我们可以通过交换两个循环的顺序来实现这一点。这种优化方式通常被称为循环交换或流水线交织处理[40]。由于外循环i内部的额外代码，我们可能不是很容易地发现可以重新排列循环。由于S矩阵是对角对称的，因此i和j可以在w的计算中交换。 结果是我们现在可以在内部循环中实现1的II。但是我们需要为临时实值和临时图像数组设置额外的存储器，存储计算的中间值一直到再次需要这些数据。 重新排列图4.15中代码的循环，并显示您可以使用1的II来管理内部循环。 根据DFT中S矩阵的结构，我们可以应用其他优化方式来完全消除三角运算。回想一下，S矩阵的每个元素的复矢量是通过单位圆的固定旋转角度来计算的。S矩阵的行S[0][]对应于单位圆周的零旋转，行S[1][]对应于单次旋转，并且随后的行对应于单位圆周更大角度的旋转。我们可以发现，第二行S[1][]相对应的向量覆盖了来自其他行的所有向量，因为8个列向量每个绕单位圆旋转45°，一共则围绕单位圆旋转了一圈。我们可以通过研究图9.11来直观地确认这个现象。这样我们可以只存储第二行这一次旋转中的正弦和余弦值，然后索引到这个存储器中的值以计算相应行的必要值。这只需要2×N=O（N）个存储单元可以有效减少存储器的O（N）的大小。对于1024个点的DFT，存储器的存储需求将减少到1024×2个条目。假设有一个32位的固定值或浮点值，则只需要8KB大小的片上存储器。显然，与明确存储整个S矩阵相比，明显减少了存储容量。我们将矩阵S的这个一维存储表示为s′s^{'}s′ S′=S[1][.]=[1ss2…sn−1] S^{'}=S[1][.]=\\begin{bmatrix} 1 & s &s^{2} &\\ldots &s^{n-1}\\\\ \\end{bmatrix} S′=S[1][.]=[1​s​s2​…​sn−1​] 导出一维数组 为了进一步提高性能，我们可以应用一种与矩阵向量乘法非常相似的技术。之前我们发现了提高矩阵向量乘法的性能需要对M[][]数组进行分区。但是如果用s′s^{'}s′ 表示S矩阵则意味着不再有一种有效的方法来划分s′s^{'}s′ 以增加我们在每个时钟上读取的数据量。S的每一个奇数行和列都包括s′s^{'}s′ 的每个元素。因此，我们无法像对S一样对s′s^{'}s′ 的值进行分区。这样增加我们从存储s′s^{'}s′ 的内存中读取数据端口的数量的唯一方法是复制存储。幸运的是，不像与必须读取和写入的内存，复制只读的数组的存储是相对容易的。事实上，Vivado HLS将只对在初始化且从未例化的只读存储器（ROM）自动执行此优化。这种功能的一个优点是我们可以简单地将sin（）和cos（）调用移动到数组初始化中。在大多数情况下，如果此代码位于函数的开头并仅初始化阵列，则Vivado HLS能够完全优化三角函数计算并自动计算ROM的内容。 设计一个利用 为了有效地优化设计，我们必须考虑代码的每个部分。往往是最薄弱的环节决定了设计的整体性能，这意味着，如果设计有一个瓶颈，将显著影响设计的性能。当前版本的DFT可以对输入和输出数据进行就地操作，即它存储结果相同的数组作为输入数据，输入数组 sample_real 和 sample_imag 都是有效的存储器端口，也就是说，你可以把这些参数的数组存储在相同的存储位置。这样，在任意给定的周期，我们只能获取其中一个阵列的一个数据，这可能会在函数中并行的乘法和加法运算方面产生瓶颈。这就是我们为什么必须将所有的输出结果存储在一个临时数组的原因，然后将所有这些结果复制到函数结尾处的“sample”数组中。如果我们没有执行就地操作，则不需要这样做。 修改DFT函数接口，使输入和输出存储在单独的数组中。这会如何影响你的可以执行优化？它如何改变性能？ 区域结果如何？ 4.8 结语 在本章中，我们探究了离散傅里叶变换（DFT）的硬件实现和优化方法。DFT是数字信号处理的基本操作，需要采样时域的信号并将其转换到频域。在本章的开头，我们描述了DFT的数学背景。这对于理解下一章（FFT）中所做的优化很重要。本章的其余部分集中介绍了指定和优化DFT以在FPGA上进行高效的实现。 由于DFT的核心是执行矩阵向量乘法，所以我们最初花费了一些时间来描述在执行矩阵向量乘法的简化代码上的指令级优化。这些指令级优化由HLS工具完成。我们用这个机会来阐明HLS工具执行指令优化的过程，希望如上的优化过程能让你直观地了解到工具优化的结果。 本章后节，我们为DFT提供了正确的功能实现方案，讨论了一些可以改善性能的优化，具体来说就是将系数阵列划分为不同存储器以提高吞吐量。阵列的分区优化通常是构建最高性能体系结构的关键方法。 Copyright © xupsh.github.io 2018 all right reserved，powered by Gitbook 该文件修订时间： 2018-07-10 15:20:35 "},"05-Fast-Fourier-Transform.html":{"url":"05-Fast-Fourier-Transform.html","title":"第五章","keywords":"","body":"第五章 Copyright © xupsh.github.io 2018 all right reserved，powered by Gitbook 该文件修订时间： 2018-07-10 15:20:35 "},"06-Sparse-Matrix-Vector-Multiplication.html":{"url":"06-Sparse-Matrix-Vector-Multiplication.html","title":"第六章","keywords":"","body":"第六章 稀疏矩阵向量乘法 稀疏矩阵向量乘（SpMV）把一个稀疏矩阵与一个向量相乘。稀疏矩阵是指矩阵中大部分元素为0的矩阵。这里的向量本身也可是稀疏的，但通常情况下是密集的。作为一种通用的运算，在科学应用、经济模型、数据挖掘、信息检索中广泛应用。例如，在利用迭代法求解稀疏线性方程组和特征值的问题。同时，也被应用于网页搜索排名和计算机视觉（图像重构等）。 本章节主会引入几个与HLS相关的新概念，进一步深入之前关于优化的讨论。本章的目标之一是引入一种更复杂的数据结构。我们用压缩行存储（CRS）来保存稀疏矩阵。另一个目标是演示如何进行性能测试。我们编写了简单的激励用来检验设计是否正确。这在硬件设计中十分重要，Vivado® HLS工具采用HLS C编写激励，并能轻松的对工具生成的RTL代码进行多方面的验证。这是基于HLS设计比基于RTL设计的巨大优势之一。章节中也会讲解如何采用Vivado® HLS工具进行C/RTL联合仿真。不同SpMV设计会带来性能上差异，因为执行时间和稀疏矩阵是密切相关的，所以我们必须通过输入数据来确定任务执行之间的间隔以及任务延迟。 6.1 背景 图6.1显示了一个4x4的矩阵M表示的2种方式。其中图6.1-a采用通用的二维方式16个元素来表示矩阵，每个元素存储在自己对应的位置上。图6.1-b采用CRS的方式表示相同的矩阵。CRS作为一种数据结构，由3个数组组成。值(values)数组保存矩阵中非零元素的值。列索引(columnIndex)数组和行指针（rowPtr）数组对非零元素的位置信息进行编码。列索引存储每一列的元素，行指针包含每一行第一个元素的值。CRS结构避免存储矩阵中的0值，确实在数值数组中确实没有存储0。但是在这个例子中，虽然数值数组不保存0，但是列索引数组和行指针数组作为标记信息，表示了矩阵的形态。CRS广泛用于大型的矩阵但是仅仅有少量的非零元素（少于10%或者更低），这样可以简化这类矩阵的存储以及相关的运算。 但是，CRS对矩阵的稀疏性没有要求，可以适用于任何矩阵。作为一种针对矩阵的通用方法，但不见得是最高效的。CRS结构也不见得是表示稀疏矩阵最高效的方式，其他稀疏矩阵表示方法也在被使用。 更准确的讲，CRS作为一种数据结构由3个数组构成：值(values)、列索引(colIndex)、行索引（rowPtr）。值数组和列索引表示稀疏矩阵M中的每一个非零元素，这些数组表示矩阵M采用行的方式，从左到右，从上到下。矩阵中的数据保存在值数组中，列索引数组保存数据在数组中水平方向的位置，如果 values[k] 表示 MijM_{ij}Mij​ 其中collndex[k]=jcollndex[k]= jcollndex[k]=j。数组rowPtr用n+1n+1n+1的长度来表示n行矩阵。rowPtr[k]表示在行k之前，矩阵中所有元素的数目，其中rowPtr[0]=0rowPtr[0]=0 rowPtr[0]=0且最后一个元素rowPtr[k]总是表示当前矩阵k行之前所有非零元素的个数Mij M_{ij}Mij​ ,其中rowPtr[i]≤k≤rowPtr[i+1]rowPtr[i] \\leq k \\leq rowPtr[i+1]rowPtr[i]≤k≤rowPtr[i+1]。如果行k包含任何非0元素，那么rowPtr[k]将包含当前行的第一个元素。注意，如果当前行没有非0元素，那么rowPtr数组中的值将会重复出现。 ​ 从图6.1 a）中，我们可以行优先的方式遍历矩阵，从而确定值（values）数组在CRS中的形式。只要发现一个非0元素，它的值会被保存在下一个索引 iii 中，同时，它的列号columnIndex[i]会被保存在列数组中。另外，在我们访问一个新行的时候，我们保存下一个值的索引 iii 在rowPtr数组中。所以，rowPtr数组的第一个元素总是0。从图6.1 b)中，我们可以把矩阵转换为二位数组表示的方式。第一步是根据rowPtr数组，确定每一行中非0 元素的个数。对行 ii i 而言，该行中元素的数目为rowPtr[i]−rowPtr[i+1]rowPtr[i]-rowPtr[i+1]rowPtr[i]−rowPtr[i+1]的差值。所以当前行的值可以从values数组values[rowPtr[i]]开始，通过递归得到。在我们的示例矩阵中，因为前rowPtr数组前2个元素是0和2，所以我们知道第一行有2个非0元素，即value[0]和value[1] 。第一个非0元素在values数组中,value[0]是3。该值所对应的列号为1，因为columnIndex[0]=0columnIndex[0]=0columnIndex[0]=0。以此类推，矩阵中第二行元素的个数为k∈[2,4)k\\in[2,4)k∈[2,4),第三行的元素个数为k∈[4,7)k \\in [4,7)k∈[4,7)。最后，共有9个非0元素在矩阵中，所以rowPtr最后一个值是9。 #include \"spmv.h\" void spmv(int rowPtr[NUM_ROWS+1], int columnIndex[NNZ], DTYPE values[NNZ], DTYPE y[SIZE], DTYPE x[SIZE]) { L1: for (int i = 0; i 图6.2： 主体代码演示了系数矩阵向量乘（SpMV）y=M.xy=M.xy=M.x的计算。通过rowPtr、columnIndex和value保存矩阵M采用CRS的方式。第一个for循环通过迭代访问每一行，第二个for循环访问每一列，实现矩阵M中非0元素和向量中对应的元素相乘并保存值在向量y中。 给定一个二维数组表示一个矩阵，通过C代码实现矩阵CRS格式。编写对应的C代码实现将矩阵从CRS格式转化为二维数组的形式。 结果表明，通过采用CRS的方式，我们能高效的实现稀疏矩阵乘法，不需要将矩阵转化为二维形式。实际上， 对于大型的矩阵仅仅只有一小部分非0元素，稀疏矩阵向量乘法会比第四章中讨论的密集矩阵向量乘高效很多。因为我们直接找到非0元素，并执行非0元素对应的运算。 6.2 基本实现 图6.2 提供了基本代码对系数矩阵乘法的实现。函数spmv函数有5个参数，分别是rowPtr、columnIndex和values对应矩阵M的CRS格式，这和图6.1中描述的数据结构等价。参数 yyy 用于保存输出的结果，参数x表示输入的被乘向量xxx。变量NUM_ROWS表示矩阵M中行号。变量NNZ表示矩阵中非0元素的个数。最后，变量SIZE表示数组x和数组y中元素的个数。 外层for循环标签为L1，对矩阵的行进行遍历。将矩阵当前的行与向量x相乘，得到输出的结果yyy。内层循环标签为L2，实现对矩阵M中每列元素的遍历。L2循环迭代计算rowPtr[i+1]−rowPtr[i]rowPtr[i+1]-rowPtr[i]rowPtr[i+1]−rowPtr[i]计算每一行非0元素的个数。每次循环计算，能从value数组中读取矩阵M的非0元素然后对应的从x数组中取得被乘向量x的值，对应相乘。cloumnIndex[k]中的值保存了对应的列号k。 #ifndef __SPMV_H__ #define __SPMV_H__ const static int SIZE = 4; // SIZE of square matrix const static int NNZ = 9; //Number of non-zero elements const static int NUM_ROWS = 4;// SIZE; typedef float DTYPE; void spmv(int rowPtr[NUM_ROWS+1], int columnIndex[NNZ], DTYPE values[NNZ], DTYPE y[SIZE], DTYPE x[SIZE]); #endif // __MATRIXMUL_H__ not defined ​ 图6.3： spmv函数和激励的头文件 6.3 测试平台 图6.4 展示了一个针对spmv函数测试平台。测试平台通过定义matrixvector函数，直接实现矩阵向量乘法，它不考虑稀矩阵是稀疏矩阵和矩阵是否采用CRS方式表示。我们比较matrixvector函数输出和spmv函数的输出。 在通常的测试平台中，需要实现的函数都会有个“golden\"参考，作为用户期望综合的结果。测试平台会比较golden用例的输出和通过Vivado® HLS综合的代码执行结果。最好的实践方式是，测试平台既可以用于golden用例，也可用于被综合的代码。这样就保证了两者实现的正确性。 测试平台在主函数main中执行。这里我们通过设置fail变量初始化为0，当spmv函数的输出成结果与matrixvector函数输出结果不相同是时，变量置1。定义与矩阵M相关的变量、被乘向量xxx 和输出结果yyy。对于矩阵M，即有普通模式，也有CSR模式（保存为values、columnIndex、rowPtr）。矩阵M 的value如图6.1中所示，输出向量yyy有两种，其中y_sw数组保存matrixvector函数输出的结果，y数组保存spmv函数输出的结果。 在定义好所有的输入变量和输出变量之后，分别调用spmv函数和matrixvector函数并输入合适的数据。 接下来的for循环用于比较y_sw和y中的每一个对应的结果。如果其中一个不相同，则将fail 标志置1。最后，程序会打印测试的结果并返回fail变量。 #include \"spmv.h\" #include void matrixvector(DTYPE A[SIZE][SIZE], DTYPE *y, DTYPE *x) { for (int i = 0; i 图6.4 ： 一个简单spmv函数的简单测试平台。测试平台生成了一个用例，并且计算矩阵的向量乘法通过稀疏矩阵乘法（spmv）和非系数矩阵乘法(matrixvector)。 这个测试平台相对简单并且可能无法充分验证所有的输入都能正常输出。最主要的原因是，它仅仅只用了一个矩阵作为例子，相反，一个好的激励会测试许多矩阵。通常，会通过随机的方式产生输入的测试用例，并且重点测试边界用例。在这个例子中，我们不仅要保证值正确计算，同时保证通过加速器正确的被执行了，而且编译时间相关的parameter改变会在实现不同加速单元值折中。最关键的是，在相同的parameter上，我们能通过随机产生很多输入数据来进行测试。编译时间相关的参数每次发生变化，都需要我们重新编译代码。 创建一个复杂的激励来，通过随机数方式生成许多组测试数据。稀疏矩阵编译时间参数应该是可以修改的（例如，SIZE，NNZ等）。创建一个HLS综合脚本，在编译时间参数合理范围改变时，能执行代码很多次。 6.4 指定循环的属性 如果直接将上述代码进行综合，我们可以得到函数运行的时钟周期及资源占用率。但是，我们不能得到模块执行所需的时钟周期、任务执行的延迟和任务执行之间的间隔。因为这些都取依赖于输入数据，由spmv函数外部因素决定。最主要的因素是，内层循环执行的次数是由矩阵M中非0元素个数决定的。非0元素的个数在代码中是由常量NNZ决定的，虽然可以调用函数计算不同大小的矩阵，但是实际迭代次数是和输入数据相关的。另外，性能也会因为非0元素的分布、综合优化的约束产生不同。更复杂的是，迭代的次数由输入决定，许多可能的输入并没有被遍历。所以，对于工具而言，不通过复杂的分析和额外的信息，工具是不能知道spmv函数执行需要多少时钟周期。Vivado® HLS工具也不能进行上述的分析。 spmv函数能正常工作的前提条件是什么？证明给定的前提条件，矩阵中每个非0元素实是不是在对应一次内层循的执行？ 有几种方式能帮助工具进行性能的分析，其中一种方式就是想Vivado® HLS提供循环边界的额外信息。这可以通过使用loop_tripcount directive实现，它能让设计者指定最小、最大和平均迭代次数针对特定的循环。通过提供这些值， Vivado® HLS 能提供时钟周期级别的评估。 ​ 使用loop_tripcount directive 用变量指定循环的最小，最大和平均迭代次数，这样Vivado® HLS 工具能对当前设计时钟周期数目进行估计。这些不影响最后综合的结果，只会影响综合报告。 对spmv函数使用loop_tripcount directive，语法格式 # pragma HLS loop_tripcount min=X, max=Y, avg=Z 其中X，Y，Z正的常量。哪个循环需要使用directive?当改变参数（min、max和avg）以后，综合报告有什么不同？这对时钟周期有影响吗？这对资源占用有影响吗？ loop_tripcount 引导能帮助设计者对函数的性能有个原始的估计。这样能比较相同的函数通过使用不同的directives或者对代码本身重构。但是，这不能确定min、max和avg参数。这也很难确定边界条件min和max的值。如果有测试平台，就有一种更准确的方式用于计算spmv函数执行的时钟周期数，那就是C/RTL协同仿真。 6.5 C/RTL 协同仿真 C/RTL协同仿真能自动化测试Vivado® HLS工具生成的RTL代码，只需要在综合的时候提供测试平台。每次执行综合以后的代码和提供的测试平台，记录输入和输出结果。输入的值按照时钟转换成输入向量。这里的输入向量用于针对生成的RTL代码进行仿真，同时记录输出向量。更新综合后的代码， 再次运行测试平台并保存输入和输出数据。测试平台如果返回值是0，则表示成功；若激励返回非0值，则表示失败。 C/RTL协同仿真在流程上，将VIvado® HLS 生成的RTL代码，通过C 测试平台，实现时钟周期级别的仿真。这样，就能准确对生成的RTL代码进行性能评估，即使性能与输入数据有关。被综合的函数运行周期最小值，最大值，平均值以及间隔在仿真完成以后都能准确的得到。 注意这些和时钟周期相关的参数是通过激励中测试数据得到的。所以，结果的质量和测试平台的质量息息相关。如果测试平台没有很好的对函数执行测试，那么结果将不准确。另外，输入测试向量都是基于理想的时序，不能反映模型实际工作时，外部接口对函数的影响。实际的性能可能会比仿真的要低，如果执行过程中阻塞在输入数据或对外部存储的访问上。不过，对于循环边界调试时变量的情况，设计者可以通过协同仿真的方式确定时钟周期个数。 C/RTL协同仿真能提供循环边界是变量的函数的延迟。它反馈函数运行时延迟的最小值、最大值和平均值以及函数运行间隔。这些延迟和测试平台输入的数据是强相关的。 当采用图6,4提供的测试平台时，函数运行的最小值、最大值和平均值以及函数间隔是多少个时钟周期？ 6.6 循环的优化与数组的分块 我们可以通过Vivado® HLS工具得到当前函数的性能和面积的评估结果，然后可以考虑如何对函数进行优化。流水线、循环展开、数组分块是第一类最常用的优化方法。最典型的方式是从最内层的循环，然后根据需要向外层循环进行。 在这个例子中， 对最内层的L2循环进行流水线化也许是我们最先和最容易想到的优化方式。这个连续迭代的循环在执行上流水以后，总体运行会加快。如果不采用流水，L2循环将按照串行执行。注意，L1循环此时还是按照串行的方式执行。 图6.5演示了spmv函数在L2循环采用流水方式时运行的步骤。每次L2的循环都被II=3II=3II=3流水化。流水线允许在外层循环执行一次迭代时，内层循环执行多次循环迭代。此时，内内层循环II受限于递归（recurrence ）操作。II=3II=3II=3是因为我们认为加法器有3个时钟周期的延迟。外部循环没有采用流水的方式，所以内层的循环必须在下外层L2循环开始执行前，计算完成并输出结果。 对最内层的L2 for循环进行流水化，通过在spmv函数中增加流水directive如图6.2所示。II(initiation interval)最后是多少？在你指定II的值以后，最终目标的II值是增大了还是减少了？ 观察执行步骤，我们可以发现有几个因素限制了循环执行性能。第一个因素，递归（recurrence ）操作限制了循环的 II。第二个因素，外层的循环没有采用流水的方式。一种高效计算稀疏矩阵向量乘法的方式，每个时钟周期把乘法器和加法器使用起来。当前的设计离这个目标还很远。 在章节4.3中，我们探究了几种设计优化技术，其中包括对不同的循环进行流水，循环展开，数组分割。掌握在这些技术之间进行权衡是一项挑战，因为它们之间经常相互依赖。我们通常联合使用这些技术，为了得到好的性能谨慎的选择其中一种而不选择另一种也许结果会更糟糕。例如，在我们使用循环展开是，设计者需要明白它对数据访问的影响。增加了对数据访问的操作但是设计性能又受限于数据访问时，优化毫无益处。同样，如果提供了冗余的存储端口，实际中使用率不高，这样对提高性能毫无帮助反而增加了资源的消耗。 想了一上述优化技术组合后复杂的形式，我们建议你尝试下面的练习： 对spmv设计进行综合，采用表6.1提供的10种directives，每种都有不同的流水，展开和分割针对不同的循环和数组。这些分割在不同的数组（values、columnIndex、x）上使用。你看到结果的趋势是如何的？增加了展开和分割，是有利于还是不利于面积？性能如何？为什么？ ​ 表6.1 稀疏矩阵向量乘法可优化的方式 L1 L2 case1 - - case2 - pipeline case3 pipeline - case4 unroll=2 - case5 - pipeline,unroll=2 case6 - pipeline,unroll=2,cyclic=2 case7 - pipeline,unroll=4 case8 - pipeline,unroll=4,cyclic=4 case9 - pipeline,unroll=8 case10 - pipeline,unroll=8,cyclic=8 case11 - pipeline,unroll=8,block=8 如果你完成了上述练习，你会发现盲目的使用优化directives，可能不会得到你期望的结果。通常在设计时， 在思考下考虑应用的特性，选择针对设计的特定优化方式。当然，这也需要一些直觉能力和一些专用工具投入使用。虽然，搞清楚像Vivado®HLS这样复杂工具中每一个细节是困难乃至不可能的，但是我们能基于关键的方面建立思考模型。 上面我们在用例3和4中考虑对外层循环L1进行流水化操作而不是对内层循环。这种变化针对一个任务，可以提高潜在的并行程度。为了完成优化，Vivado ®HLS工具必须展开代码中所有的内层循环L2 。如果循环能全部展开，这样能减少计算循环边界的时间，同时也能消除递归（recurrences）。但是代码中的内层循环Vivado HLS是无法完全展开的，因为循环边界不是常量。 例如在实现上面提到的例子3，在最外层的循环L1使用流水化directive。在不设定目标II时，II值是多少？资源占用率发生了什么变化？增加了II后资源占用率结果如何？这与之前采对L2循环进行流水化，结果有什么不同？这和最基本的设计（无 directives）相比有什么不同？当你对外层循环进行展开时，结果到底如何？（提示：检查综合后的日志信息） 另外一种增加并行化的方式是对内层循环进行局部循环展开，就像之前例子5到10。这种变化实现更多的并行化，通过在相同的循环迭代中，执行更多的操作。有些情况，Vivado HLS 工具在对内层循环进行流水化时，通过实现更多操作来提高性能。但是，这还是很难提高内层循环的II，由于内层循环的递归操作。但是，在II大于1的情况下， 许多操作可以共享同一个计算单元。 图6.6展示了一个局部展开的代码。在这段代码中，L2循环被分成2个循环，分别为L2_1和L2_2。最内层的循环L2_2执行的次数由参数S确定。内部循环包含了最原始的L2循环，其中循环边界是由最原始的L2循环确定的。代码中，L2_1循环包含了不确定次数的乘法和加法操作，运算次数由参数S确定，和一次递归完成累加y0+=yty0 += yty0+=yt。 注意图6.6中的代码和自动循环展开的代码是由一点点区别的。自动循环展开复制计算，但是保留每次计算先后顺序（除了当前的例子）。这就导致了计算顺序由内层循环决定，如图6.7左所示。对计算顺序进行调整后，操作上的依赖关系如图6.7 左边所示。在当前的代码中，最后累加求和是一个递归（recurrence ）。当使用浮点数据类型时，这种调整计算顺序的操作可能对程序产生改变，所以Vivado HLS对这种类型的代码不进行操作顺序自动调整。 这个设计可能会被综合、实现如图6.8所示的结果。在这个例子中，S=3S=3S=3与IIIIII最匹配，乘法器的延迟正好是3。所有的运算过程都是在一个乘法器和加法器上执行。比较这个例子与图6.5中的例子，我们可以发现一些缺点。最明显的是，内层循环的流水线长度很长，实现的时候需要多个更多的周期刷新流水线的输出，才能执行下一次外层L1循环。处理一行中非零元素和执行块S 相同。一行有个3个元素和一行有一个元素计算的时间是相同的。剩下的运算也需要在循环流水线中执行，即使他们的结果没有用。为了严格的比较两个设计的特性，我们需要了解设计对矩阵每行非零元素个数的预期。 #include \"spmv.h\" const static int S = 7; void spmv(int rowPtr[NUM_ROWS+1], int columnIndex[NNZ], DTYPE values[NNZ], DTYPE y[SIZE], DTYPE x[SIZE]) { L1: for (int i = 0; i ​ 图6.6 局部展开图6.2中smpv函数 如果矩阵每行非零元素很少，则采用第一种实现方式较优；如果矩阵中每行非零元素较多，则第二种实现方式更好。 需要注意，这里存在一个关于先有鸡还是先有蛋的问题。我们需要知道目标器件和时钟周期，这样才能确定流水线中加法器能不能满足时序要求。只有在我们知道流水线的级数之后（也许S=1时，Vivado HLS才能识别到加法递归），我们才能选择合适版本的参数S，来满足II=1II=1II=1。一旦我们确定了S，我们能通过C/RTL协同仿真来，通过一组测试数据，确定是不是达到了性能上的要求。因为循环边界是可变的，所以得到的性能参数是依赖于数据的，所以我们需要设定不同的S，来找到性能的最大值。改变器件的类型和工作频率会影响之前所有的设计！进款看来去高层次综合（HLS）对解决问题提供的帮助不多，相比于RTL开发新版本然后进行验证，它开发起来快（代码编写方便）。 图6.8可以实现时，S与加法器流水线等级相同。如果S设定较大，结果会怎样？如果S 设定较小，结果会怎样？如果目标II小于S会怎样？如果目标II大于S会怎样？ 6.7 小节 在本章节中，我们介绍了系数矩阵向量乘法（SpMV），这延续了之前对矩阵运算的研究。SpMV 显得很有乐趣，因为它采用了一种特别的数据结构。为了减少大量的存储，矩阵采用行压缩的方式存储，这样就要求我们以一种非直接的方式对矩阵进行访问。 这一章节首先我们了Vivado® HLS工具测试和仿真的能力。我们采用一个基于SpMV简单的激励文件，讲解HLS工作流程。另外，我们对Vivado® HLS工具中C/RTL协同仿真进行了讲解。这对我们得到设计准确性能结果是十分重要。矩阵越不稀疏，则更多的计算需要执行。在测试平台确定以后，协同仿真可以提供程序运行的精确仿真。这样就可以达到执行周期和性能结果。最后，我们讨论了采用循环优化和数组分块对代码进行优化。 Copyright © xupsh.github.io 2018 all right reserved，powered by Gitbook 该文件修订时间： 2018-07-10 15:20:35 "},"07-Matrix-Multiplication.html":{"url":"07-Matrix-Multiplication.html","title":"第七章","keywords":"","body":"第七章 Copyright © xupsh.github.io 2018 all right reserved，powered by Gitbook 该文件修订时间： 2018-07-10 15:20:35 "},"08-Prefix-Sum-and-Histogram.html":{"url":"08-Prefix-Sum-and-Histogram.html","title":"第八章","keywords":"","body":"第八章 前缀和与直方图 8.1 前缀和 ​前缀和是许多应用中经常使用的运算算子，例如在递推关系、压缩问题、字符串比较、多项式评估、直方图、基数排序和快速排序应用中[11] 。为了创建高效的FPGA设计，下面我们对前缀和运算进行重新设计。 ​前缀和本来是一序列数字的累加和。若给定一序列输入中inni{n_n}inn​,前缀和中第n项的值是输入前n项的累加和outnou{t_n}outn​，即outn=in0+in1+in2+⋯+inn−1+innou{t_n} = i{n_0} + i{n_1} + i{n_2} + \\cdots + i{n_{n - 1}} + i{n_n}outn​=in0​+in1​+in2​+⋯+inn−1​+inn​。以下展示的是前四个输出元素的计算过程。 out0=in0ou{t_0} = i{n_0}out0​=in0​ ​out1=in0+in1ou{t_1} = i{n_0} + i{n_1}out1​=in0​+in1​ ​out2=in0+in1+in2ou{t_2} = i{n_0} + i{n_1} + i{n_2}out2​=in0​+in1​+in2​ ​out3=in0+in1+in2+in3ou{t_3} = i{n_0} + i{n_1} + i{n_2} + i{n_3}out3​=in0​+in1​+in2​+in3​ ​⋯ \\cdots ⋯ ​当然，在实际应用中，我们不希望存储和重新计算以前所有输入的累加和，因此我们使用递推方程式表示： ​outn=outn−1+innou{t_n} = ou{t_{n - 1}} + i{n_n}outn​=outn−1​+inn​ ​递推方程的劣势是在计算outnou{t_n}outn​之前必须先计算出outn−1ou{t_{n-1}}outn−1​,这从根本上限制了计算时的并行性的扩展和吞吐量的提高。相反，计算前缀和的原始方程由于计算每个输出都可以独立计算，所以很明显可以并行执行，但是代价是进行一系列的冗余计算。使用C语言实现的递推方程如图8.1所示。理想情况下，我们期望代码中循环的II (Initiation interval)= 1，但即使对于这样简单的代码，也是具有挑战性的。在Vivado@HLS中进行综合这段代码运行结果如图8.1所示。 ​这段代码的编写方式是将每个输出数值都写入输出寄存器out[]中，然后在下一次迭代中再次从寄存器中读出上一次输出的数值。由于读取寄存器的延迟是1个时钟周期，因此从寄存器中读取的数据只有在下一个时钟周期才能被处理。结果是，这样的代码设计只能实现II (Initiation interval)=2 的循环设计。在这种情况下，有一种简单的改良此代码的方法：我们可以使用一个单独的局部变量来进行累加操作，而不是像以前一样从数组中读回前一次累加的数值。在CPU处理器代码设计中，避免使用额外的外部存储器来替代寄存器作为数据访问的方式更有优势，同样在HLS设计中这样的数据访问方式更重要，因为其他的处理操作很少能成为系统的性能瓶颈。该操作方式代码如图8.2所示。 #define SIZE 128 void prefixsum(int in[SIZE], int out[SIZE]) { out[0]=in[0]; for(int i = 1; i #define SIZE 128 void prefixsum(int in[SIZE], int out[SIZE]) { int A = in[0]; for(int i=0; i ​你可能会问，为什么编译器无法自动优化内存负载和存储以改进II的设计。事实证明，Vivado@hls能够优化加载和数组存储，但仅适用于单个基本块范围内的读取和写入。如果我们展开循环，你可能看到如图8.3所示。注意，我们也通过添加约束array_partition的方式来达到在接口处可以同时读取和写入多个数值。在这种情况下，Vivado@HLS能够消除循环体内大部分out[]数组的读操作，但我们仍然只能实现循环间隔II=2的设计。在这种情况下，循环中第一次加载读数仍然存在。但是我们可以通过修改代码使用局部变量来替代从out[]数组中读取数据。 ​理想情况下，当我们展开内部循环时，则在每个时钟中就可以执行更多的操作和减少函数运算的时间间隔。如果我们将展开因子设置2，则性能提升一倍。如果展开因子系数设置为4，则性能提升4倍，即循环在展开时，系统性能以线性方式变化。虽然大部分情况是这样，但是当我们展开内部嵌套循环时，设计中的某些方面是不会变化的。在大多数情况下，例如当循环的迭代间隔是执行很长时间时，展开内部循环对于整个函数性能的提升没有显著影响。但是，对着循环迭代次数的减少，展开循环会产生更大的影响。循环流水线设计中最大成分是流水线自身深度。由Vivado@HLS为流水线循环生成的组合逻辑要求在循环执行后刷新流水线。 #define SIZE 128 void prefixsum(int in[SIZE], int out[SIZE]) { #pragma HLS ARRAY PARTITION variable=out cyclic factor=4 dim=1 #pragma HLS ARRAY PARTITION variable=in cyclic factor=4 dim=1 int A = in[0]; for(int i=0; i 通过设置不同的展开因子来将对应的图8.2中前缀和代码中for循环展开，并结合数组分割来达到使循环ii = 1。前缀和函数延迟如何变化？资源利用率如何变化？你为什么认为是这样变化的？当循环完全展开时会发生什么？ ​图8.4中展示了图8.1和图8.2中的代码综合产生的硬件架构。在a)部分中，我们可以看到流程中的‘loop’包含存储out[]数组的输出存储部分，而在b)部分，流程中的循环部分仅包含一个存储累加值的寄存器和只写的输出存储器。简化重复并消除不必要的内存访问是优化HLS代码的常见做法。 ​本节的目标是表明即使代码中的小改动有时也会对硬件设计产生重大的影响。有些变化可能不一定直观，但可以通过开发工具的反馈来识别。 void histogram(int in[INPUT SIZE], int hist[VALUE SIZE]) { int val; for(int i = 0; i ​图8.6：计算直方图的原始代码。 for循环遍历输入数组并递增hist数组的相应元素。 8.2 直方图 ​直方图表示离散信号的概率分布。当给定一系列离散输入值时，直方图计算每个值在序列中出现的次数。当通过除以输入总数进行标准化处理时，直方图就变成序列的概率分布函数。直方图常应用于图像处理、信号处理、数据库处理以及许多其他领域。在许多情况下，将高精度的输入数据量化处理成更小的数量间隔是直方图中一种常见处理。在本节的内容中，我们将略过数据实际处理过程，而重点关注数据分块操作。 ​图8.5中是一个直方图应用的简单例子。该数据集由一系列[0,4]中整数表示。下面显示了相应的直方图，在直方图中显示了每个数据块区间的计数，其中每个数据块区间的高度对应每个单独值的在数据集中的个数。图8.6中显示了直方图函数的计算代码。 ​代码最后看起来与前一小节中的前缀和计算代码非常相似。不同之处在于，前缀和基本上只执行一次累加，而在直方图函数中我们为每个分块均计算一次累加。另一个区别是，在前缀和运算中，我们每次都加上一个新的输入值，而在直方图运算中，我们只加1。当使用pipeline指令对函数内部循环进行约束时，会遇到和图8.1中代码同样问题，由于内存的重复读写，系统只能实现II =2的循环。这是因为在每次迭代循环中我们均需要从hist[]数组中读取数据和写入数据。图8.7中显示了图8.6中代码的硬件体系结构。从图中可以看到针对hist[]数组进行了读取和写入操作。其中，val变量用作hist[]数组的索引，并且该索引变量读取和写入在同一个位置。 8.3 直方图优化和错误依赖 ​让我们更深入的观察上面的处理过程。在循环的第一次迭代中，我们读取位置x0处的hist数组值并将其写回到相同的位置x0处hist数组中。由于读操作需要一个时钟延迟，所以写入数组操作必须在下一个时钟周期发生。然后在下一次迭代循环中，我们读取另一个hist数组中另一个位置x1中数组。x0和x1都取决于输入值，并可以取任何值。因此我们考虑到综合成电路时最坏的情况，如果x0 = x1,则在前一个写入完成前，位置x1处的读取无法开始。因此，我们必须在读写之间进行切换。 ​事实证明，只要x0和x1是独立的，我们就必须在读写之间进行切换。如果它们实际上不是独立的呢？例如，我们可能知道数据源实际不会连续产生两个完全相同的数据。那我们现在该怎么做呢？如果我们可以将x0和x1是不同的地址额外信息提供给HLS工具，那么它就能够同时在位置x1处读取，而在位置x0处写入数据了。在Vivado@HLS中，可以通过设置dependence指令来完成。 ​修改后的代码如图8.8所示。上面我们明确表示该函数使用需要一些前提条件。在代码中，我们使用assert断言来完成对第二个前提条件的检查。在Vivado@HLS中，这个断言在仿真过程中被启用，以确保仿真测试过程中向量满足所需的前提条件。软件提供的dependence指令可以避免前提条件对综合电路的影响。也就是说，它向Vivado@HLS软件工具指示使用特定的方式读取和写入hist数组。在这种情况下，迭代循环之间读操作和写操作间距离是2。在这种情况下，距离为n将表明在地带次数i+n中的读操作仅依赖于地带次数i中的写操作。因此，断言in[i+1] != in[i]，但可能出现in[i +2] == in[i]，所以正确距离是2。 #include #include ”histogram.h” // Precondition: hist[] is initialized with zeros. // Precondition: for all x, in[x] != in[x+1] void histogram(int in[INPUT SIZE], int hist[VALUE SIZE]) { #pragma HLS DEPENDENCE variable=hist inter RAW distance=2 int val; int old = −1; for(int i = 0; i 图8.8：计算直方图的替代函数。 通过向Vivado @HLS添加指令约束输入，就可以在不显着更改代码的情况下实现II = 1的设计。 在图8.8中，我们向代码添加了一个前提条件，使用一个断言对其进行了检查，并且使用dependence指令指示工具对于前提条件的约束。如果你的测试文件不满足这个先决条件会发生什么？如果删除assert()会发生什么？Vivado@HLS是否仍检查前提条件？如果前提条件与dependence指令不一致，会发生什么？ ​不幸的是，如果我们不愿意接受附加的先决条件，那么dependence指令就不能真正帮助我们。同样清楚的是，因为我们可能需要使用存储在hist数组中的所有值，所以我们不能直接应用于前缀函数相同的优化。另一种方法是使用不同的技术实现hist数组，例如我们可以完全划分hist数组，从而使用触发器（FF）资源实现数组。由于在一个时钟周期内写入FF的数据在下一个时钟周期可立即使用，这解决了重复问题并且在涉及少量分块时这也是一个不错的解决方案。图8.9显示了这种设计的结构。然而，当需要大量分块时，这往往是一个糟糕的解决方案。通常的直方图是用成百上千个分块进行构建并且对于大数据集可能需要许多位精度来计算所有输入。这导致大量FF资源和大型多路复用器，其中多路复用器也需要逻辑资源。通常在块RAM（BRAM）中存储较大的直方图是一个更好的解决方案。 ​回到图8.6中的代码，我们看到，架构必须能够处理两种不同的情况。一种情况是输入包含连续的同一个分块中的值。在这种情况下，我们希望使用一个简单的寄存器以最小的延迟执行累加。第二种情况是当输入中不包含连续的同一个分块中的值，在这种情况下，我们需要读取，修改并将结果写回到内存，并且可以保证hist数组的读操作不会受到前一个写操作的影响。我们已经看到，这两种情况都可以单独实施，也许我们可以将他们组合成单一设计。图8.10中所示了完成此操作的代码。该代码使用一个本地变量old来存储上一次迭代分块的结果，同时使用另一个本地变量accu存储此次迭代分块的计数。每次迭代循环时，我们都会检查当前分块是否与上次迭代分块值相同。如果是这样，那么我们可以简单地增加accu。如果不是，那么我们需要将数值存储在hist数组中，然后在hist数组中使用当前值更替。无论哪种情况，我们都会使用当前的值更新old和accu值。该代码对应的体系结构如图8.11所示。 ​在这段代码中，我们仍然需要一个dependence指令，就像图8.8中那样，但是形式略有不同。在这种情况下，在同一个迭代循环中，读取和写入访问是在不同地址中进行的。这两个地址都依赖于输入数据，因此可以指向hist数组中的任何单独像素。因此，Vivado@HLS假定这两种访问都可以访问相同的位置，并以交替的周期顺序对数组进行读取和写入操作，则循环的II =2。但是，通过查看代码，我们可以很容易地看到hist[old]和hist[val]永远不会访问相同的位置，因为他们位于条件if(old = val )的else分支中。在一次迭代（内部依赖）内，写入操作（RAW）之后的读取操作永远不会发生，因此这是错误的依赖关系。在这种情况下，我们不使用dependence指令来通知工具关于函数的先决条件，而是关于代码本身的属性。 综合图8.6和图8.10中的代码。这两种情况下启动间隔（II）是多少？当你从图8.10中的代码中删除dependence指令时会发生什么？在这两种情况下，循环间隔怎么变化？资源使用情况如何？ 对于图8.10中的代码，你可能会问为什么像Vivado@HLS这样的工具无法确定性能。事实上，虽然在这样的一些简单情况下，更好的代码分析可以将if条件属性传播到每个分支，但我们必须接受存在一些代码段，其中内存访问的性能是不可判定的。在这种情况下最高的性能只能通过添加用户信息的静态进程来实现。最近的一些研究工作通过引入一些研究来寻求改进设计中的动态控制逻辑[60, 40,19]。 #include ”histogram.h” void histogram(int in[INPUT SIZE], int hist[VALUE SIZE]) { int acc = 0; int i, val; int old = in[0]; #pragma HLS DEPENDENCE variable=hist intra RAW false for(i = 0; i 图8.10：从for循环中删除写入依赖后的读取。 这需要一个if /else结构，看起来似乎会增加设计的不必要的复杂性。尽管数据路径更复杂，但它允许更有效的流水线操作。 ​图8.11展示的是图8.10中代码重构后的图形化描述。图中并非所有的操作都在这里显示，但实现功能的主要思想都显示出来。你可以看到两个单独的if和else区域（用虚线表示）。图中将Acc变量复制了两次目的是让图形更容易理解；在实际设计中只有一个寄存器用于该变量。该图显示了对应于计算的if子句和对应于数据读写的else子句的两个分离的数据路径。 8.4 提高直方图性能 ​通过一些努力，我们已经实现了II =1 的设计。以前我们已经看到通过部分展开内部循环方式可以进一步减少设计的执行时间。但是对于直方图函数是有点困难的，有几个原因如下。第一个原因是顺序循环执行，即下次循环执行必须在这次循环计算完成的前提下才能开始，除非我们能够以某种方式分解输入数据。第二个原因是在回路II = 1的情况下，电路需要在在个时钟周期内同时执行读取和写入hist数组，这样就需要占用FPGA中BRAM资源的两个端口。之前我们已经考虑过数组分区方法来增加存储数组内存端口的数量，但是由于访问顺序输入数据，所以没有特别好的方式来分割hist数组。 ​不过，并不是没有指望了。因为我们可以通过将直方图计算分解为两个阶段来达到更多的并行性。在第一阶段，我们将输入数据分成若干独立的分块。每个分块的直方图可以使用我们之前的直方图解决方案独立计算。第二阶段，将各个直方图组合起来生成完整数据集的直方图。这种分块（或映射）和合并（或还原）过程与MapReduce框架[20]采用的过程非常相似，并且是并行计算的常见模式。Map-reduce模式适用于包含交换和关联操作的循环，例如这种情况下的加法。完整方案如图8.12所示。 ​图8.13中式实现这种架构的代码。直方图函数实现了Map-reduce模式的’map’部分，并且会多次实例化。该代码与图8.10中的代码非常相似。主要的区别在于我们添加了额外的代码来初始化hist数组。Histogram_map函数输入数组是hist数组中一个分区数据。Histogram_reduce函数实现了模式中的“还原”部分。它将分区数据的直方图作为输入，并通过将每个直方图的计数相加，将它们组合成完整的直方图。在我们的图8.13的代码示例中，我们只有两个处理对象，因此将两个输入数组hist1和hist2合并。这可以很容易的扩展以处理更多的元素。 ​新的直方图函数将输入数据分成两个分区，分别存储在inputA和inputB数组中。它使用histogram_map函数计算每个分区的直方图，然后将其存储在hist1和hist2数组中。这两个数组被输入到histogram_reduce函数中。该函数将它们合并后并将结果存储在hist数组中，其中合并的hist数组是顶层直方图函数的最终输出。 修改图8.13中的代码包含支持可参数化改变PE个数的变量NUM_PE？提示：你需要根据数组分块数量NUM_PE以及循环将数组合并成一个数组。当你改变PE的数量时，吞吐量和任务间隔会发生什么变化？ ​我们在histogram函数中使用dataflow指令来达到任务级流水线设计。在这种情况下有三个处理过程：两个partial_histogram函数处理实例和两个histogram_reduce函数处理实例。在一个任务中，因为两个partial_histogram处理的数据相互独立，所以可以同时执行。Histogram_reduce函数处理过程必须在partial_histogram处理完成后才开始。因此，dataflow指令本质上是创建了一个两阶段的任务管道。第一阶段执行partial_histogram函数，而第二阶段执行histogram_reduce函数。与任何数据流设计一样，整个histogram函数的间隔取决于两个阶段的最大启动间隔。第一个阶段的两个partial_histogram函数时相同的，并且具有相同的间隔（IIhistogram_mapI{I_{histogram\\_map}}IIhistogram_map​）。Histogram_reduce函数酱油另一个间隔（IIhistogram_reduceI{I_{histogram\\_reduce}}IIhistogram_reduce​）。顶层histogram函数的启动间隔IIhistogramI{I_{histogram}}IIhistogram​是max(IIhistogram_mapI{I_{histogram\\_map}}IIhistogram_map​ ,IIhistogram_reduceI{I_{histogram\\_reduce}}IIhistogram_reduce​ ). #include ”histogram parallel.h” void histogram map(int in[INPUT SIZE/2], int hist[VALUE SIZE]) { #pragma HLS DEPENDENCE variable=hist intra RAW false for(int i = 0; i 图8.13：图示是使用任务级并行和流水线操作的直方图的另一种实现。直方图操作分为两个子任务，这两个子任务在两个histogram_map函数中执行。使用histogram_reduce函数将这些结果合并到最终的直方图结果中。顶层的histogram函数是将这三个函数连接在一起。 当你添加或更改pipeline指令时，会发生什么？比如，在histogram_reduce函数中为for循环添加pipeline指令是否有益？将pipeline指令移动到直方图映射函数中，也即将它拉到当前所在for循环的外部，那么结果是什么？ ​本节目标是学习直方图计算的优化算法，而这也是许多应用程序中另外一个小但重要的核心。关键是因为对于我们的程序，工具可以理解的东西通常是有限制的。在某些情况下，我们必须注意如何写代码，而在其他情况下，实际上我们必须提供给工具更多关于代码或代码执行环境的信息。特别的，内存访问形式的性能通常会严重影响HLS生成正确且高效的硬件。在Vivado@HLS中，可以使用dependence指令表示这些性能。有些时候这些优化或许与直觉相反，比如在8.10中添加的if/else结构。一些情况下优化或许要求一些创造性，就像分布式计算在图8.12和8.13的应用。 8.5 结论 ​本节我们学习了前缀和与直方图内核。尽管这些方法看起来不同，但他们都包含重复的内存访问。如果内存访问不是流水线的，这些重复访问就会限制吞吐量。这两种情况，我们可以通过重构代码来去除重复。前缀和会非常容易，因为它的访问模式就是确定的。直方图情况下，我们必须重新写代码以解决重复访问的问题，或者确保实践中不会发生重复。无论是这两种的哪种情况，我们都需要一种方法来向Vivado®HLS描述一些信息，关于环境或者工具自身无法确定的代码部分。这些信息会在dependece指令中被捕获。最后，我们研究了两种算法的并行化方法，以便他们可以在每个时钟周期处理大量数据样本。 Copyright © xupsh.github.io 2018 all right reserved，powered by Gitbook 该文件修订时间： 2018-07-10 15:20:35 "},"09-Video-Systems.html":{"url":"09-Video-Systems.html","title":"第九章","keywords":"","body":"第九章 视频系统 9.1 背景 ​视频处理是目前FPGA上常见的应用。其中一个选择FPGA处理视频应用的原因是目前的FPGA时钟处理频率可以很好地满足常见视频数据对处理速率的要求。例如，一般的高清视频格式，全高清视频格式（1080p@60HZ）需要的处理速率是1920（像素/行）x 1080（行/帧）x 60（帧/秒） = 124,416,000（像素/秒）。 ​当对数字视频流（1080p@60HZ）进行编码时(1080p视频帧实际传输时像素大小为2200x1125，其中行2200像素 = 行同步+行消隐前肩+有效像素（1920像素）+行消隐后肩，场1125 行=场同步+场消隐前肩+有效行（1080行）+ 场消隐后肩 ），其中消隐像素也会伴随有效像素以148.5MHz（1080P@60HZ）的频率在FPGA流水线电路中进行处理。为了达到更高的处理速率可以通过在每个时钟周期内处理多个采样数据的方式实现。数字视频是如何传输的详细内容介绍将在9.1.2小节中展开。另一个选择FPGA处理视频应用需求的原因主要是因为视频按扫描线顺序从左上角像素到右下角像素的顺序进行处理，如图9.1所示。这种可预测的视频数据处理顺序允许FPGA在无需消耗大量存储器件的条件下构建高效的数据存储架构，从而有效地处理视频数据。这些体系结构的详细信息将在第9.2.1小节中介绍。 ​视频处理应用是HLS一个非常好的目标应用领域。首先，视频处理通常是可以容忍处理延迟的。尽管一些应用可能会将整体延迟限制到一帧之内，但是许多视频处理应用中是可以容忍若干帧的处理延迟。因此，在HLS中使用接口和时钟约束方式实现的高效的流水线处理，可以不用考虑处理时延问题。其次，视频算法往往非常不统一，算法一般是基于算法专家的个人喜好或擅长的方式被开发的。一般情况下它们是被使用可以快速实现和仿真的高级语言开发的。虽然全高清视频处理算法在FPGA处理系统上可以以每秒60帧处理速度运行或者是在笔记本电脑上通过使用综合的C/C++代码以每秒一帧的处理速度运行是很常见的，但是RTL级仿真时仅能一个小时一帧的速度运行。最后，视频处理算法通常以适合HLS容易实现的嵌套循环编程风格编写。这意味着来自算法开发人员编写的许多视频算法的C / C ++原型代码均可以被综合成相应的FPGA电路。 9.1.1 视频像素表示 ​许多视频输入和输出系统都是围绕人类视觉系统感知光线的方式进行优化的。第一个原因就是眼球中的视锥细胞对红、绿和蓝光敏感。其他颜色都可以视为红、绿和蓝色的融合。因此，摄像机和显示器模仿人类视觉系统的功能，对红、绿、蓝光采集或者显示红、绿和蓝像素，并用红色、绿色和蓝色分量的组合来表示颜色空间。最常见的情况是每个像素使用24位数据位表示，其中红绿蓝每个分量各占8位数据位，其中颜色分量的数据位的位数也存在其他情况，例如高端系统中的每个像素颜色分量可以占10位位深或甚至12位位深。 ​第二原因是人类视觉系统对亮度比对颜色更敏感。因此，在一个视频处理系统内，通常会将RGB颜色空间转换到到YUV颜色空间，它将像素描述为亮度（Y）和色度（U和V）的分量组合，其中色度分量 U和V是独立于亮度分量Y的。例如常见视频格式YUV422，就是对于4个像素点，采样4个Y的值，两个U的值，两个V的值。这种格式应用于视频压缩时的采样叫色度子采样。另一种常见的视频格式YUV420表示采样4个像素值由4个Y值，一个U值和一个V值组成，进一步减少了表示图像所需像素数据。视频压缩通常在YUV色彩空间中进行。 ​第三个方面是由于眼睛中的眼杆和感光部分对绿光比对红光更加敏感，并且大脑主要从绿光中获取亮度信息。因此，图像传感器和显示器采用马赛克模式，比如采样2个绿色像素和1个红像素与1个蓝像素比例的Bayer模式。于是在相同数量焦平面采集单元或显示器显示单元条件下系统可以采集或显示更高分辨率的图像，从而降低图像采集传感器或显示器的制造成本。 视频系统多年来一直围绕人类视觉系统进行设计。最早的黑白相机对蓝绿光敏感，以匹配眼睛对该颜色范围内亮度的敏感度。然而，不幸的是它们对红光不太敏感，因此红色（如红妆）在相机上看起来不正常。当时针对这个问题的解决方案绝对是低技术含量的：拍照时演员穿着华丽的绿色和蓝色化的妆。 9.1.2 数字视频格式 ​除了表示个别的像素之外，数字视频格式必须以视频帧的形式对像素进行组织和编码。在很多情况下，通过同步或同步信号的方式来表示连续像素序列的视频帧开始和结束。在某些视频接口标准（如数字视频接口或DVI）中，同步信号使用单独的物理线路引出。在其他标准（如数字电视标准BTIR 601/656）中，同步信号的开始和结束由不会出现在视频信号中的特殊像素值表示。 ​相邻行像素之间（从左到右顺序扫描）由水平同步信号分隔开，且相邻行像素之间的水平同步信号由若干时钟周期的脉冲信号组成。另外，在水平同步信号和有效像素信号中间还有若干时钟周期的无效信号，这些信号称为行前肩和行后肩。同样，相邻帧信号之间（从上到下顺序扫描）由垂直同步脉冲分隔。每个视频帧之间有若干行有效的帧同步信号。注意，相邻帧之间的垂直同步信号仅在视频帧的开始出现。同样，帧视频信号中除了同步信号和视频有效信号外，还有无效视频行组成的场前肩和场后肩信号。另外，大多数数字视频格式包含表示有效视频像素起始的数据使能信号。因此，所有无效的视频像素一起组成水平消隐间隔和垂直消隐间隔。这些信号如图9.2所示。 数字视频信号均是对原来电视标准的模拟信号（美国的NTSC和许多欧洲国家的PAL）通过抽样、量化和编码后形成。由于用于模拟阴极射线管扫描的硬件具有有限的电平转换速率，所以水平和垂直同步间隔的时间要满足从硬件恢复扫描到下一行的开始。同步信号由若干个时钟周期的低电平组成。另外，由于电视无法有效地显示靠近同步信号的像素，因此引入前肩信号和后肩信号，这样就可以显示更多的图片像素。即使如此，由于许多电视机都是基于电子束扫描原理设计的，所以其中的图像数据有20％的边框处的像素是不可见。 ​如图9.2所示，典型1080P（60Hz）视频帧共包含2200 1125个数据采样像素点。在每秒60帧的情况下，这相当于每秒总共148.5百万的采样像素点。这比1080P（60Hz）帧中的有效视频像素的平均速率（1920 1080 * 60 =每秒124.4百万像素）高很多。现在的大多数FPGA都可以满足以这个时钟速率进行高效的处理，并且是在一个时钟周期进行一次采样的方式下运行的。对于更高分辨率的处理系统需求，如4K或2K的数字影院，或者每秒120帧甚至240帧的处理需求，就需要一个时钟周期采样更多像素点，通过增加数据处理的吞吐量方式来运行。注意，我们通常可以通过在HLS中展开循环的方式来生成此类结构（请参见1.4.2小节）。同样，当处理低分辨率和低帧率需求时，优选的方案是采用操作共享的方式，多个时钟周期去处理一次采样。这样的处理结构是通过指定循环的处理间隔方式实现。 #include ”video_common.h” unsigned char rescale(unsigned char val, unsigned char offset, unsigned char scale) { return ((val − offset) ∗ scale) >> 4; } rgb_pixel rescale_pixel(rgb_pixel p, unsigned char offset, unsigned char scale) { #pragma HLS pipeline p.R = rescale(p.R, offset, scale); p.G = rescale(p.G, offset, scale); p.B = rescale(p.B, offset, scale); return p; } void video_filter_rescale(rgb_pixel pixel_in[MAX_HEIGHT][MAX_WIDTH], rgb_pixel pixel_out[MAX_HEIGHT][MAX_WIDTH], unsigned char min, unsigned char max) { #pragma HLS interface ap_hs port = pixel_out #pragma HLS interface ap_hs port = pixel_in row_loop: for (int row = 0; row 图9.3 简单视频滤波器的实现代码 ​例如，在图9.3中代码展示了一个简单的视频处理应用程序，程序中执行每次循环的II = 1(Initiation interval),也就是一个时钟周期处理一次采样数据。代码中采用嵌套循环的方式是按照图9.1中所示的扫描线顺序处理图像中的像素。II = 3的设计方式可以通过共享计算组件的方式来减少资源使用量。通过设置内层循环展开因子为2和输入输出数组拆分因子为2就可以满足一个时钟处理两个像素。这种例子相对简单，因为每个组件和每个像素的处理是相对独立的。更复杂的功能可能不会因为资源共享而处理更方便，也可能无法同时处理多个像素。 void video_filter(rgb_pixel pixel_in[MAX_HEIGHT][MAX_WIDTH], rgb_pixel pixel_out[MAX_HEIGHT][MAX_WIDTH]) { #pragma HLS interface ap_memory port = pixel_out // The default #pragma HLS interface ap_memory port = pixel_in // The default 高速计算机视觉应用是需要满足每秒处理10000帧的200*180像素的视频帧的速度要求。这样的应用通常是使用一个高速图像传感器直接和FPGA直接连接，并且中间不需要有同步信号。在这种情况下，你会每个时钟周期内进行多少次采样处理呢？FPGA可以很好的完成处理么？答案是你可以使用HLS编写嵌套循环的结构来完成这样的设计。 9.1.3 视频处理系统架构 ​到目前为止，我们专注于构建视频处理应用部分的程序而不关心如何将其整合到一个大的系统程序中去。在很多情况下，如图9.1.2中示例代码，大部分像素处理发生在循环内，并且当循环运行时每个时钟周期仅处理一个像素。在本节中，我们将讨论讲视频处理部分程序集成到大的系统程序中的情况。 ​默认情况下，Vivado@HLS软件会将代码中的函数数组接口综合成硬件的存储器接口。其中，存储器写数据接口由地址总线、数据总线和写使能信号线组成。存储器每次读取和写入数据均有相应地址变化，并且数据读取和写入时间固定。如图9.4所示，将这种接口与片上存储资源Block RAM资源集成在一起使用很简单方便。但是即使在大容量的芯片，片上Block RAM资源也是很稀缺的，因此如果存储大容量的视频资源会很快消耗完片上Block RAM资源。 针对24位像素位深的1920x1080视频帧，芯片需要消耗多少BlockRAM资源才能完成存储存一帧视频帧？片上Block RAM资源最多又能存储多少帧呢？ void video_filter(pixel_t pixel_in[MAX_HEIGHT][MAX_WIDTH], pixel_t pixel_out[MAX_HEIGHT][MAX_WIDTH]) { #pragma HLS interface m_axi port = pixel_out #pragma HLS interface m_axi port = pixel_in ​通常，大部分视频系统更好的选择是将视频帧存储在外部存储器中，比方说DDR。在图9.5中展示了系统与外部存储器典型系统集成模式。在FPGA内部，外部存储器的控制器（MIG）集成了ARM AXI4标准化从接口与FPGA内的其他模块进行通信。FPGA内的其它模块使用AXI4主接口或者是通过专门的AXI4内部互联模块与外部存储器的AXI4从接口相连。AXI内部互联模块允许多个主设备模块访问多个从设备模块。该架构抽象了外部存储器的操作细节，允许在无需修改FPGA设计中其它模块的情况下，允许不同外部存储器模块和标准互换使用。 ​尽管大多数处理器都使用高速缓存，从而高性能处理数据。但通常情况下，如图9.5所示，基于FPGA实现的视频处理系统，无需片上高速缓存。在处理器系统中，高速缓存可以提供对先前访问的数据更低时延的访问，并通过始终读取或写入完整的高速缓存行来提高对外部存储器访问的带宽。一些处理器甚至还使用更复杂的数据处理机制，如预取和推测读取，以减少对外部存储器的访问时延和增加对外部存储器的访问带宽。对于大多数基于FPGA的视频处理系统，因为大多数视频算法访问外部存储器是可预测的，所以使用线性缓冲区和窗口缓冲区可以一次从外部缓冲区中读取多个数据。另外,当以猝发模式对外部存储器访问时，Vivado@HLS能够提前调度地址变换，避免读取数据时拖延计算。 void video_filter(pixel_t pixel_in[MAX_HEIGHT][MAX_WIDTH], pixel_t pixel_out[MAX_HEIGHT][MAX_WIDTH]) { #pragma HLS interface s_axi port = pixel_out #pragma HLS interface s_axi port = pixel_in void video_filter(pixel_t pixel_in[MAX_HEIGHT][MAX_WIDTH], pixel_t pixel_out[MAX_HEIGHT][MAX_WIDTH]) { #pragma HLS interface ap_hs port = pixel_out #pragma HLS interface ap_hs port = pixel_in void video_filter(hls::stream &pixel_in, hls::stream &pixel_out) { 图9.7: HLS中流接口的代码实现方式 如图9.6所示为另一种存储器体系架构。在这种架构中，算法处理模块通过外部直接存储器（DMA）与外部存储器连接，DMA完成与外部存储控制器（MIG）之间地址转换的细节操作。算法处理模块可以以AXI总线数据流（AXIS）的形式将数据传输给DMA控制器。DMA假设数据是算法处理模块生成的，并将数据写入外部存储器。在Vivado@HLS中，有多种编码方式可以将代码中的数组接口综合成AXIS流接口，如图9.7所示是其中一种。在这种情况下，C代码与前面看到的代码相同，但接口约束指令不同。另外一种代码实现方法是使用hls::stream<>方式显式建立总线流接口。无论那种情况都必须注意，DMA中生成数据的顺序要与C代码中访问数据的顺序相同。 ​AXIS数据流接口的一个优点是它允许在设计系统中，采用多个算法处理模块级联的方式，并且不需要在外部存储器中存储算法处理计算中间结果。在一些应用例子中，如图9.8所示，FGPA系统在没有外部存储器的情况下，将从输入接口（如HDMI）上接收到的像素数据处理后直接将它们发送到输出接口。这样的设计通常要求算法处理模块的吞吐量必须达到需求，以满足外部接口严格实时约束的要求。当一些复杂的算法构建时，系统难以保证其数据吞吐量需求，因此系统如果至少能提供一帧缓冲区，就可以为算法构建提供更大的灵活性。当输入和输出像素速率不同或者可能不相关时（例如接收任意输入视频格式并输出不同任意视频格式的系统），帧缓冲可以起到简化构建系统的作用。 void video_filter(pixel_t pixel_in[MAX_HEIGHT][MAX_WIDTH], pixel_t pixel_out[MAX_HEIGH][MAX_HEIGHT]) { #pragma HLS interface ap_hs port = pixel_out #pragma HLS interface ap_hs port = pixel_in 9.2 实现 ​当一个系统实际处理视频数据时，一般从视频处理算法实现角度来进行系统分解集成。在本章的剩余部分，我们将假设输入数据是按照流的方式送入系统，并且按照扫描线的顺序进行处理的。采用HLS开发，我们不关注代码RTL级具体实现方式，只关注HLS设计能满足所需要的性能指标要求即可。 9.2.1 行缓冲和帧缓冲 ​在视频处理算法中，通常计算一个输出像素的值时需要输入像素及其周围的像素的值做参考，我们把储存计算所需要的输入像素值的区域叫窗口。从概念上讲，按照窗口大小去Z型扫描图片，然后根据扫描到的像素值计算出输出结果就可以。如图9.9所示示例代码中，示例代码是针对视频帧进行二维滤波。示例代码中在计算每一个输出像素结果前需要从输入视频帧中读取相应的窗口像素数据（存储在数组中）。 在图9.9中，代码中包含的int wi =row + i – 1;int wj = col +j -1;, 解释这些表达式为什么包含”-1”这一项。提示：如果滤波器核换成7×7，而不是3×3，”-1”这个数字项会改变么？ ​注意，在此代码中，每计算一个输出像素值，必须多次读入像素并填充到窗口缓冲区中。如果每个时钟周期只能执行一次读操作，示例代码的执行性能会受限于读入像素速率大小。因此示例代码基本上是图1.8中所示一维滤波器的二维版本。另外，因为输入像素不是以正常扫描线顺序读取的，所以接口约束也只有有限的几个可选。（本主题将在9.1.3小节中更详细讨论）。 ​仔细观察相邻的窗口缓冲区中缓冲的数据，你会发现缓冲的数据高度重叠，这意味着相邻窗口缓冲区之间数据更高的依存性。这也意味来自输入图像的像素可以被本地缓存或者高速缓存存储，以备数据被多次访问使用。通过重构代码来每次只读取输入像素一次并存储在本地缓冲区中，这样可以使系统性能得到更好的表现。在视频系统中，由于本地缓冲区存储窗口周围多行视频像素，所以本地缓冲区也称为线性缓冲区。线性缓冲区通常使用Block RAM(BRAM)资源实现，而窗口缓冲区则使用触发器（FF）资源实现。图9.10所示是使用线性缓冲区重构的代码。注意，对于N×N图像滤波器，只需要N-1行存储在线性缓冲区中即可。 rgb_pixel filter(rgb_pixel window[3][3]) { const char h[3][3] = {{1, 2, 1}, {2, 4, 2}, {1, 2, 1}}; int r = 0, b = 0, g = 0; i_loop: for (int i = 0; i = MAX_HEIGHT || wj = MAX_WIDTH) { window[i][j].R = 0; window[i][j].G = 0; window[i][j].B = 0; } else window[i][j] = pixel_in[wi][wj]; } } if (row == 0 || col == 0 || row == (MAX_HEIGHT − 1) || col == (MAX_WIDTH − 1)) { pixel_out[row][col].R = 0; pixel_out[row][col].G = 0; pixel_out[row][col].B = 0; } else pixel_out[row][col] = filter(window); } } } 图9.9: 没有使用线性缓冲区的2D滤波代码 ​如图9.10所示代码，是使用线性缓冲区和窗口缓冲区方式实现的，其中代码实现过程如图9.11所示。代码每次执行一次循环时，窗口会移动一次，使用来自于1个输入像素和两个来自于行缓冲区缓存的像素来填充窗口缓冲区。另外，输入的新像素被移入线性缓冲区，准备被下一行的窗口运算过程所使用。请注意，由于为了每个时钟周期处理一个像素并输出结果，所以系统必须在每个时钟周期内完成对窗口缓冲区数据的读取和写入。另外，当展开”i”循环后，对于窗口缓冲区数组而言，每个数组索引都是一个常量。在这种情况下，Vivado@HLS将转换数组中的每个元素成一个标量变量（一个成为标量化的过程）。窗口数组中的元素随后使用触发器(FF)编译实现。同样，线性缓冲区的每一行数据都会被访问两次（被读取一次和写入一次）。示例代码中明确约束行缓冲区中每一行数组元素被分割成到一块单独存储区中。根据MAX WIDTH的可能取值情况，最后决定使用一个或者多个Block RAM实现。注意，每个Block RAM可在每个时钟周期支持两次独立访问。 线性缓冲区是应用于模块式计算的重用缓冲区的一种特殊例子。如图9.9中所示，重用缓冲区和线性缓冲区的高级综合是目前一个热点研究领域。参考[8, 31]。 Vivado@HLS包含hls::linebuffer<>和hls::window buffer<>类，它们可以简化窗口缓冲区和行缓冲区的管理。 对于3×3的图像滤波器核，则存储每个像素占用4字节的1920×1080图像的一行数据需要使用多少个FPGA片上Block RAM? 9.2.2 因果滤波器 ​图9.10中实现的滤波器是每个时钟周期读取一个输入像素，计算出一个输出像素。该滤波器实现原理与图9.9中所示不完全相同。输出结果是从先前读取像素的窗口缓冲区中数据计算出来的。窗口缓冲区中取数顺序是“向上和向左”。因此，输出图像相对于输入图像是“向下和向右”移动的。这种情况类似于信号处理中的因果滤波器和非因果滤波器的原理。大多数信号处理理论的重点是因果滤波器。因为只有因果滤波器对于时间采样信号（例如，其中x[n]=x(n∗T)x[n] = x(n*T)x[n]=x(n∗T)和​y[n]=y(n∗T)y[n] = y(n*T)y[n]=y(n∗T)）才有实用价值。 在因果滤波器 void video_2dfilter_linebuffer(rgb_pixel pixel_in[MAX_HEIGHT][MAX_WIDTH], rgb_pixel pixel_out[MAX_HEIGHT][MAX_WIDTH]) { #pragma HLS interface ap_hs port=pixel_out #pragma HLS interface ap_hs port=pixel_in rgb_pixel window[3][3]; rgb_pixel line_buffer[2][MAX WIDTH]; #pragma HLS array_partition variable=line_buffer complete dim=1 row_loop: for (int row = 0; row 图 9.10: 使用线性缓冲区实现2D滤波器的代码 通过卷积的定义证明前面原理： y=x⊗h:y[n]=∑k=−∞∞x[k]∗h[n−k]y = x \\otimes h:y[n] = \\sum\\limits_{k = - \\infty }^\\infty {x[k]*h[n - k]} y=x⊗h:y[n]=k=−∞∑∞​x[k]∗h[n−k] ​就本书而言，大多数变量不是时间采样信号和单输入单输出系统。对于设计时间采样信号的系统，在使用HLS开发过程中可以进行时序约束处理。只要系统能达到所需的任务延迟，那么就认为系统设计是正确的。 ​在大多数视频处理算法中，在上文代码中所引入的空间位移不是预期的，是需要被消除的。虽然有很多种修改代码的方法来解决这个问题，但是一种常见的方式是扩展迭代域。这种技术是通过增加少量的循环边界，以便第一次循环迭代就读取第一个输入像素，但是第一个输出像素直到等到后面的迭代空间才写出。修改后的版本滤波器代码如图9.12所示。代码原理如图9.14所示，和图9.10中原始缓冲区中代码相同。使用HLS编译后，可以看出数据依赖性以完全相同的方式得到满足，并且待综合的代码是硬件可实现的。 9.2.3 边界条件 ​在大多数情况下，计算缓冲区窗口只是输入图像的一个区域。然而，在输入图像的边界区域，滤波器进行计算的范围将超过输入图像的边界。根据不同应用的要求，会有很多不同的方法来解决图像边界处的计算问题。也许最简便的方法来解决边界问题就是忽略边界，这样输出的图像就会比输入的图像长宽各少滤波器核大小。但是在输出图像大小固定的应用中，如数字电视，这种方法就行不通了。 void video_2dfilter_linebuffer_extended( rgb_pixel pixel_in[MAX_HEIGHT][MAX_WIDTH], rgb_pixel pixel_out[MAX_HEIGHT][MAX_WIDTH]) { #pragma HLS interface ap_hs port=pixel_out #pragma HLS interface ap_hs port=pixel_in rgb_pixel window[3][3]; rgb_pixel line_buffer[2][MAX_WIDTH]; #pragma HLS array_partition variable=line_buffer complete dim=1 row_loop: for(int row = 0; row = 1 && col >= 1) { int outrow = row−1; int outcol = col−1; if(outrow == 0 || outcol == 0 || outrow == (MAX_HEIGHT−1) || outcol == (MAX_WIDTH−1)) { pixel_out[outrow][outcol].R = 0; pixel_out[outrow][outcol].G = 0; pixel_out[outrow][outcol].B = 0; } else { pixel_out[outrow][outcol] = filter(window); } } } } } ​图 9.12: 使用线性缓冲区并且循环迭代范围扩展为1时实现2D的滤波器代码 另外，当处理大量大小略微不同的图片时，需要一系列大小的滤波器核来进行处理，这种情况就复杂了。图9.10中的代码展示，输出图像通过在边界处填充已知值的像素（一般填充黑色）来达到与输入图像大小相同。或者通过其他方式来合成缺失的值。 缺少的输入值可以用常量来填充； 可以从输入图像的边界像素处填充缺少的输入值； 缺失的输入值可以在输入图片内部像素中进行重构。 当然，也存在更复杂和更计算密集的方案。图9.16中展示了一种处理边界条件的方案。此方案是通过计算每个像素在窗口缓冲区中的偏移地址方法。这种方案的一个明显的缺点就是每次从窗口缓冲区中读取的地址都是变化的地址。因此，在计算滤波之前，这个变量会导致多路复用。对于N×N的抽头滤波器，针对N个输入将会消耗大约N×N个多路复用器。对于滤波器而言，多路复用器占滤波器资源消耗的大部分。另一种处理数据写入窗口缓冲区时的边界条件是以规则模式移动窗口缓冲区。在这种情况下，只消耗N个多路复用器，而不是N*N个，从而是资源消耗量降低很多。 修改图9.16中的代码，从窗口缓冲区中读取数据使用常量地址。你节省了多少硬件资源？ 9.3 结论 ​视频处理是一种常见的非常适合使用HLS实现的FPGA应用。大多数视频处理算法有一个共同特点是数据局部性，即可以在使用少量的外部存储器访问的情况下，能够实现流式传输和本地缓存的应用。 void video 2dfilter linebuffer extended constant( rgb pixel pixel in[MAX HEIGHT][MAX WIDTH], rgb pixel pixel out[MAX HEIGHT][MAX WIDTH]) { #pragma HLS interface ap hs port=pixel out #pragma HLS interface ap hs port=pixel in rgb pixel window[3][3]; rgb pixel line buffer[2][MAX WIDTH]; #pragma HLS array partition variable=line buffer complete dim=1 row loop: for(int row = 0; row = 1 && col >= 1) { int outrow = row−1; int outcol = col−1; rgb pixel window2[3][3]; for (int i = 0; i = MAX HEIGHT − outrow + 1) wi = MAX HEIGHT − outrow; else wi = i; if (j = MAX WIDTH − outcol + 1) wj = MAX WIDTH − outcol; else wj = j; window2[i][j] = window[wi][wj]; } } pixel out[outrow][outcol] = filter(window2); } } } } 图9.16: 使用线性缓冲区核常量边界来实现处理边界条件的代码，这种方法处理消耗硬件资源成本很大 Copyright © xupsh.github.io 2018 all right reserved，powered by Gitbook 该文件修订时间： 2018-07-10 15:20:35 "},"10-Sorting-Algorithms.html":{"url":"10-Sorting-Algorithms.html","title":"第十章","keywords":"","body":"第十章 排序算法 10.1 简介 排序是许多系统中最常见的一个通用算法。它的核心算法是在处理大量排序数据时，用二叉树检索法进行高效处理，其时间复杂度仅为O(logN)O(logN)O(logN)。比如，数序序列 A=1,4,17,23,31,45,74,76A = {1, 4, 17, 23, 31, 45, 74, 76}A=1,4,17,23,31,45,74,76 从这个序列中判断是否存在一个数，不需要将它与所有8个元素进行比较，仅仅需要从排序序列中间元素选取并检查需要判断的数字是否大于或小于元素。如果检索元素45，第一步，可以从比较A(4)＝31来开始，从45到31我们可以消除A(0...4)只考虑A(5...7)，即 A=  1,4,17,23,31  ,45,74,76A = {~~1, 4, 17, 23, 31~~, 45, 74, 76}A=  1,4,17,23,31  ,45,74,76 下一步，如果与A(6)＝74比较，可以得到45＜74，可以消除除A(5)以外的所有情况，此时 A=  1,4,17,23,31  ,45,  74,76  A = {~~1, 4, 17, 23, 31~~, 45, ~~74, 76~~}A=  1,4,17,23,31  ,45,  74,76   最终确认A(5)确实包含在序列中。 在上面的例子中，序列A可以代表各种不同的概念。A可以代表一个数学集合，可以搜索元素是否在集合内。在集合中，A也可以表示数据中的一部分，通常称为关键字，用于索引其余信息。关键字可以是一个人的名字，基于关键字的搜索，可以获取该人的其余数据信息，比如他们的出生日期等等。在有些场合下，关键字还可能是更抽象的对象，比如一些数据或密钥的加密散列。在这种情况下，数据存储顺序可能是随机的，但只要获得正确的密码散列，仍然可以搜索它。不管何种情况，排序和搜索所需的基本操作类似，都要需要比较两个不同的值，在这一章中将忽略这些问题。 在通用处理器系统中，有各种各样的排序算法应用，参考[36]。它们在空间复杂度和时间复杂度方面有所不同，但绝大数都需要O(NlogN)O(NlogN)O(NlogN)次比较才能对NNN个元素进行排序。对一个排序序列使用二叉树插入1个新元素时，搜索O(logN)O(logN)O(logN)次即能找到新值的正确位置；当需要插入NNN个元素时，这个过程需要重复NNN次。 在实际应用场景下，插入元素的成本可能非常大，这取决于排序的数据结构 。在通用处理器系统中，有各种各样的因素影响综合性能，比如处理大数据集或多核之间并行化计算时的局部存储问题。 HLS中也有类似的考虑，通常以增加资源开销为代价，来降低计算处理的时间。在很多实际案例中，要取得最佳设计往往要从算法和实现技术方式两个方面来综合考虑。算法和实现技术的权衡目前是一个新兴的研究领域，参考[45,54,49]。 性能外的特性也影响排序算法的选择。例如： 稳定： 如果输入数据有两个字段具有相同的键值，它们以相同的顺序输出，那么排序是稳定的。例如，对一组记录进行排序，使用年龄作为排序主键，包含人名和年龄。在输入数据中，两人都是25岁，John排在Jane前面。一个稳定的排序需要确保John和Jane的位置跟输入数据保持一致。 在线：算法允许数据在接收时进行排序。在数据排序时不可以访问，或者必须从外部存储器顺序读取等情况，在线是非常有必要的措施。 原位： 一个包含NNN个元素的数组可以使用NNN个元素存储空间进行排序，也有一些算法在排序过程中需要额外的存储。 适应：对于已经排序的数据来说是有效的。如果数据已经排序，一些算法可能会运行得更快，即只需要O(N)O(N)O(N)的时间复杂度。 10.2 插入排序 插入排序是一种基本的排序算法，其核心思想是将一个新的元素插入到一个有序数组中，并继续保持有序。每步将一个待排序的记录，按其关键码值的大小插入前面已经排序的文件中适当位置上，直到全部插入完为止。 例如有一个长度为NNN的无序数组，进行N−1N-1N−1次的插入即能完成排序；第一次，数组第1个数认为是有序的数组，将数组第二个元素插入仅有1个有序的数组中；第二次，数组前两个元素组成有序的数组，将数组第三个元素插入由两个元素构成的有序数组中......第N−1N-1N−1次，数组前N-1个元素组成有序的数组，将数组的第N个元素插入由N-1个元素构成的有序数组中，则完成了整个插入排序 。 例如对输入数组A进行排序，先考虑数组第1个数A[0]A[0]A[0] 视为元素个数为1的有序序列；下一步考虑数组的第二个元素A[1]A[1]A[1] 插入这个有序序列中；然后依次把数组A中的每个元素A[i]A[i]A[i] 插入到这个有序序列中，因此，需要一个外部循环，扫描数组A的每一个元素。在每一次插入过程中，假设这是要将A[i]A[i]A[i] 插入到前面的有序序列中，需要将A[i]A[i]A[i] 和A[0...i−1]A[0...i-1]A[0...i−1] 进行比较，确定要插入的合适位置，这就需要一个内部循环。图10.1 展示一个数组插入排序的单步视图。第一趟第1个元素值3是有序的，因为任何只带有一个元素的数组都是按顺序排列的。第二趟插入数组元素值2，与第一个元素值3比较后，被放置到有序数组中的第一个元素，将之前有序数组中的元素值3移到右边。第三趟插入数组的第三个元素A[2]=5A[2]= 5A[2]=5，由于其已经位于正确的位置，因此无需做任何移动操作。第四趟把数组元素4插入到有序数组中元素5前面即可。最后一趟插入数组元素值1时，元素1需要插入到有序数组中的第一个元素位置，前面的有序数组元素全部右移一个位置。 插入排序是一种稳定、在线、原位、自适应的排序算法。插入排序通常用在处理小批量数组。例如，复杂算法产生的大量数据可以分解为若干个组小批量的数组，然后利用插入排序处理这些小批量的数组，最终结果通过组合排序数组形成。 10.2.1 插入排序的基本实现 #include \"insertion_sort.h\" void insertion_sort(DTYPE A[SIZE]) { L1: for(int i = 1; i 0 && A[j−1] > item ) { #pragma HLS pipeline II=1 A[j] = A[j−1]; j−−; } A[j] = item; } } 图10.2 : 插入排序的参考代码。外部循环for用来遍历数组元素，内部循环while用来遍历已经排序的序列，将当前元素移动到对应位置。 图10.2是插入排序的C参考代码。外部循环标记为L1，由于单个元素A[0]A[0]A[0]已经排序，这里仅需要从元素A[1]A[1]A[1] 迭代到元素A[SIZE−1]A[SIZE-1]A[SIZE−1]，其中SIZESIZESIZE 表示数组元素的长度。LI的每次循环首先拷贝当前要插入有序序列中的元素A[i]A[i]A[i]，然后再执行内部L2循环寻找该值索引的合适位置。内部循环的判断条件是还没有循环到数组末尾(即条件为j>0j>0j>0)，并且数组元素是大于即将要插入的元素(即条件A[j−1]>itemA[j-1]>itemA[j−1]>item)。只要该判断条件满足，排序子数组的元素右移(操作A[j]=A[j−1]A[j]=A[j-1]A[j]=A[j−1]​)；当判断条件不满足时，即已经查询到要插入元素的坐标位置；此时退出循环，找到索引的正确位置直接插入元素。当第​iii次迭代完成后，从​A[0]A[0]A[0]到​A[i]A[i]A[i]的元素按排序顺序排列。 图10.2中的插入排序代码是一个简单的实现，没有做任何优化。这里可以使用Vivado HLS不同的优化指令 ，如pipeline, unroll 和array_paration等进行优化。最简单的优化策略即是使用pipeline指令，使得内部循环L2支持流水功能。对于插入排序算法，内部循环访问不同的数组元素时，没有数据相关性，因此设置期望的流水线启动间隔为1（即II=1）。生成的加速器平均需要 N2/4N^2/4N2/4次数据比较，由于每个时钟周期都需要比较一次，因此流水线的处理延迟大概需要 N2/4N^2/4N2/4个时钟周期, 参考[58]。实际上，外部循环的顺序执行的计算延迟稍高。为了获取更好的性能，可以尝试将pipeline指定应用到外部循环L或者函数本身，或者还可以使用部分循环展开组合。插入排序的一些优化选项可以参考表10.1。 表10.1：图10.2中插入排序的C代码实现可以尝试的优化选项 指令（Directives) 启动间隔（II） 周期（period) 逻辑资源Slices 1 L2: pipeline II=1 ? ? ? 2 L2: pipeline II=1 ? ? ? L2: unroll factor=2 array partition variable=A cyclic factor=2 3 L1: pipeline II=1 ? ? ? 4 L1: pipeline II=1 ? ? ? L1: unroll factor=2 array partition variable=A complete 5 function pipeline II=1 ? ? ? array partition variable=A complete 建议探索一下表10.1中的优化选项，分别综合这些优化设计并确定启动间隔(II)、时钟周期和所需要的逻辑资源，分析综合报告，获取哪些优化选项在改进延迟和吞吐量方面效果最明显。如果合并这些优化选型到插入排序算法设计里面会发生什么? 图10.2所示的插入排序代码与前面几章的其他嵌套循环程序比较类似，但是有一些方面确实很难优化。优化选项1尝试的流水线启动间隔也无法达到1，虽然数据通路上并没有重要的相关性，但是在控制通路上循环是否能够执行的判断影响了其流水线性能。在这种情况下，必须读取A[i−1]A[i-1]A[i−1]来确定循环是否能够执行，而该循环检查并不能在读取数据A的第一级流水线完成。这是典型的递归例子，其包含了HLS生成的循环控制逻辑。如果碰到类似的递归逻辑，Vivado HLS报告中会指出循环退出条件不能在第一个启动间隔的时钟周期中去调度；当然也有可能会发生退出或者保持当前控制逻辑的状态。一种解决方案是增加一条读取A[i−1]A[i-1]A[i−1]的操作，才能保证循环退出检查在1个启动间隔周期内调度，其代码如图10.3所示。 #include \"insertion_sort.h\" void insertion_sort(DTYPE A[SIZE]) { L1: for(i = 1; i 0 && t > item) { #pragma HLS pipeline II=1 A[j] = t; t = A[j−2]; j−−; } A[j] = item; } } 图10.3 ： 根据表10.1中的优化选项1重构插入排序 表中的优化选项2是以factor因数为2展开内部循环，即在每一个时钟周期内完成两个移位操作，可能会降低插入排序的延迟。由于每次存储访问不能分配到不同的存储区域，因此即使添加数组分区指令优化，Vivado HLS也不能达到启动间隔为1的循环。 在Vivado HLS中，数组分区array_partition优化指令是用来实现多组独立的存储块区域。例如优化指令（array_partition variable=A cyclic factor=4)表示划分数组A中为4个独立的子存储块，通常这个指令使得每个时钟周期内存储访问速度是未优化前的4倍，但是其限制是一个时钟周期内的每次存储访问必须对应其中的一块子存储块。数组元素A[i]可以存放在任意一个分区，而数组元素A[4*i+2]仅可以访问第3个子模块；需要额外的交叉逻辑来解决同一个周期内同时访问A[i]、A[i+1]、A[i+6]和A[i+7]。在编译时只能保证静态偏移量下的访问可以抵达不同的存储块，但是实际的存储块直到运行时才能确定。当然在访问不同存储块区域时，还可以使用缓冲逻辑保证那些不能在一个周期内抵达的访问。要是访问同一存储块区域，缓冲逻辑可以延迟几个周期直到有所有访问完成。多端口的架构设计通过一个或两个物理端口获取数据副本，保证在每个时钟周期中有一定数量的访问可以完成，参考参考[62,1,37]。 表中的优化选项3也未能实现显著的改进，主要原因是内部循环L2没有静态可计算的环路，Vivado HLS无法重构外部循环L1的流水线。这里主要关注插入算法在指令优化上的设计空间，好的替代方案还需要进队代码重构。要设计出最佳的代码重构不仅需要理解算法，还需要理解HLS的综合的体系结构，参考参考[28,48]。接下来的小节会主要对插入排序的代码进行重构，其代码结构与图10.2中的有很大差异。 设计一个最佳基于HLS的算法加速需要考虑下面几个方面。首先，编写高效的高层综合语言需要工程师是必须理解硬件设计，比如循环展开和存储划分等一些基本思路。其次，工程师需要对应用程序和硬件实现都有足够的理解，才能正确评估任何吞吐量问题。第三，也是最重要的，为了达到最佳的设计结果，即高性能和资源的低开销，通常需要重构代码才能创建一个高效的硬件结构。这些与软件设计有很大的差异。 10.2.2 并行化插入排序 为了提高插入排序的性能，优化目标是每个时钟周期插入一个新元素。当最后一个元素插入到排序列表中是，可能会需要改变数组中的所有元素。对于图10.2中的代码，意味着内部循环L2实际上顺序扫描比较了数组中的所有元素。要想在每个时钟周期中插入一个新元素，首先需要足够的硬件操作资源，才可以对数组中的每个元素进行比较。为了保证外部循环的流水线，优化内部循环的变量边界为常量边界，才可以使得内部循环体展开并集成到外部循环体中，参考代码如图10.4所示。 #include \"insertion_sort_parallel.h\" #include \"assert.h\" void insertion_sort_parallel(DTYPE A[SIZE], DTYPE B[SIZE]) { #pragma HLS array_partition variable=B complete L1: for(int i = 0; i = 0; j−−) { DTYPE t; if(j > i) { t = B[j]; } else if(j > 0 && B[j−1] > item) { t = B[j−1]; } else { t = item; if (j > 0) item = B[j−1]; } B[j] = t; } } } 图10.4：重构表10.1中优化选型3的插入排序代码 重构图10.2中的内部循环体的实现代码，把退出条件优化为if条件，放在新的内部循环体L2中；增加其他分支判断条件，扩大内部循环的次数；增加的分支判断条件在原始循环时不执行任何操作，也不会被执行；数组的赋值在循环体L2内部执行，而不是在L2循环体外部执行。内部循环展开时，jjj 都成为常量，数组B的每次读写都将在常量索引下执行。另一方面，itemitemitem变量是分配给内部循环的一份元素拷贝；在编译期间Vivado HLS会创建一个独立的寄存器用来实现电路上的多路复用。 将单个变量转换为多个副本是编译器里常用的内部转换优化机制，这种中间表示形式即是静态单一赋值（SSA）。要合并来自代码中不同点的值，SSA中间表示形式包括φ函数都是由希腊字母φ表示。这些φ函数在Vivado HLS产生的电路中生成多路复用器，如果您仔细查看，你可能会发现工具中相关的资源报告。 图10.4中的并行插入排序本质上生成了多组内部循环体，这个内部循环体的结构主要是由几个多路复用器、一个决定谁最小的比较器和1个存储数组元素的寄存器等组成。当然，每个阶段还可能包括缓冲寄存器，以确保生成的电路逻辑在一个有效的时钟频率。若把内部循环体L2看为排序单元，那么插入排序函数即是由一个一维数组的排序单元和一些在输入输出接口层的额外逻辑组成，在这种情况下， 外部迭代体仅需要SIZESIZESIZE个时钟周期就可以处理完。这个排序单元的主要特性是每个排序单元只与相邻的排序单元通信，而不是所有的单元。像这样的设计被称为脉动阵列，是一种常见的并行算法优化的技术。在很多情况下，只要在不同的循环之间的通信是有限的，当展开内部循环的优化，包括排序和脉动阵列的实现，都可以称为隐式脉动阵列。 10.2.3 显式脉动阵列插入排序 脉动阵列已经有了很好的研究，许多并行算法都采用了脉动阵列的技术，特别是使用线性排序单元阵列来实现插入排序，参考参考[59,9,45,5]。脉动阵列本身的核心概念就是让数据在运算单元的阵列中进行流水，减少访存的次数，并且使得结构更加规整，布线更加统一，提高频率。 这里描述一种显式的数据流编码风格，通过dataflow优化指令就可以实现脉动阵列的直观方法。 图10.5展示了插入排序的脉动阵列的实现方式。每个单元都是相同的，每个单元的输入端口ininin用来接收当前寄存器中的值，较小的值发送到输出端口outoutout, 而较大的值存放在本地寄存器locallocallocal中, 其实每个单元的功能也就是out=min(in,local)out=min(in, local)out=min(in,local)。第iii号单元的输出结果传递给线性阵列的下一个（即第i+1i+1i+1号）单元的输入，当新的输入到来时，会与存储在阵列中的本数组进行比较，直到找到正确的位置。如果新的输入大于阵列中的所有值，排序后的值将向右移动一个单元阵列；如果新的输入小于阵列中的所有值，此值会在阵列中传输，最终会被存放在最右边的阵列单元中。当所有的数据都处理完时，最小的元素存放在第N−1N-1N−1个阵列单元，直接从输出读出即可。 一个插入单元的核心代码如图10.6所示。输入和输出变量都声明为HLS的数据流类型。DTYPE是一个类型参数，允许对不同类型进行操作。本地变量存放阵列中的某一个元素，添加了static关键字是为了在多个函数调用中保存它的值。这里需要注意的是使用相同的函数，复制单元功能NNN次；每个单元必须有一个单独的单元静态变量，一个静态变量不能跨NNN个函数共享。 void cell0(hls::stream & in, hls::stream & out) { static DTYPE local = 0; DTYPE in copy = in.read(); if(in copy > local) { out.write(local); local = in.copy; } else { out.write(in copy); } } 图10.6：一个插入单元cell0对应的Vivado HLS C代码，其他单元格除了需要具体不同的函数名（比如cell1、cell2等）之外，其他的功能代码都时相同的。代码与图10.5中架构图所展示的功能相同，输入和输出变量采用了HLS的数据流接口，此接口提供了一种抽象层次更高跟方便的方法去生成和仿真FIFO。 图10.7展示了8个元素进行排序的代码，实现的主要功能即是将8个插入单元连接在一起。若需要扩展更多的元素，只需要复制更多的单元函数即可。HLS定义并实例化了单元之间的数据流变量类型，并以合适的方式连接每个单元的输入和输出接口。 void insertion_cell_sort(hls::stream &in, hls::stream &out) { #pragma HLS DATAFLOW hls::stream out0(”out0 stream”); hls::stream out1(”out1 stream”); hls::stream out2(”out2 stream”); hls::stream out3(”out3 stream”); hls::stream out4(”out4 stream”); hls::stream out5(”out5 stream”); hls::stream out6(”out6 stream”); // Function calls; cell0(in, out0); cell1(out0, out1); cell2(out1, out2); cell3(out2, out3); cell4(out3, out4); cell5(out4, out5); cell6(out5, out6); cell7(out6, out); } 图10.7：插入单元对8个元素进行排序，函数的输入是HLS的数据流接口，输出是通过变量out按顺序的输出元素，输出顺序从最小的元素开始，以最大的元素结束。 上面insertion_cell_sort函数是从最小值开始输出数据，后面的输出越来越大的元素。如果要首先输出最大的元素，后面的输出越来越小，需要做哪些改进，才可能反转这个输出顺序？ 为了对整个元素进行排序，需要多次调用insertion_cell_sort 子函数。每一个插入单元排序的调用都提供了一个数据元素进行排序；第一次调用时，这些数据元素将存放在哪里呢？这个问题的解决方法是把输入数据在初始化成局部变量0，这个在所有的单元函数中完成的。 将静态变量local初始化为0是对数据类型的假设。这种假设的成立条件是什么?换句话说，范围是多少才能被正确处理输入数据的值?如果输入数据在insertion_cell_sort函数这个范围之外?有没有更好的方法去初始化局部变量? 在调用了插入单元排序函数8次后，所有的数据都存放在每个单元格函数的8个局部变量中。 要得到第一个排序元素，需要调用insertion_cell_sort函数多少次?对于所有元素数据的排序，需要调用多少次？如果把数组拆成N个单元，又需要多少次调用insertion_cell_sort函数才能完成整个排序？ 指令dataflow的作用是实现了8个插入单元函数组成的任务流水线结构。在顶层函数的每个执行过程中都流水地处理一个新的输入示例，流水线的每个阶段都去调用单元函数。当调用单元函数8次时，即只能对序列排序8个值；在单元函数之间不包含递归，因此在资源足够的情况下可以任意扩展和调用单元函数。 整个数组的插入排序需要多少个周期?所有排序的数据都是从插入单元函数中的参数输出的吗？如果删除dataflow优化指令，循环计数将如何变化？如何改进资源利用率？ 图10.8所示的是testbench的参考代码，testbench生成要排序的随机数据存放在input数组中，多次调用insertion_cell_sort函数进行排序，处理结果存放在cell_output数据中。接下来，使用同样的输入数据，插入排序处理过程采用图10.2所示的insertion_sort函数。最后，testbench比较这两种不同实现方式的结果，如果两钟不同实现方式的排序结构相同，则testbench通过。 #include \"insertion_cell_sort.h\" #include #include const static int DEBUG=1; const static int MAX_NUMBER=1000; int main () { int fail = 0; DTYPE input[SIZE]; DTYPE cell_output[SIZE] = {0}; hls::stream in, out; //generate random data to sort if(DEBUG) std::cout 图10.8：insertion_cell_sort函数的测试平台 在testbench中，常量SIZESIZESIZE的值表示要排序元素的数量，在本节的运行示例中即为8。常量DEBUG是用来提供testbench中的一些输出详细说明；设置成非0表示打开debug信息，设置成0表示关闭debug信息。输入数组Input中的数据是由rand函数随机产生的；如果需要更新产生的数据，可以调用带参数信息的srand函数。 值得注意的是，testbench中一共调用了SIZE∗2SIZE*2SIZE∗2次insertion_cell_sort函数。前面SIZE次调用都会向insertion_cell_sort函数中输入一个元素，但不会产生有效的结果输出；后面SIZE次的调用提供虚拟无效的输入数据，并产生一个已经排序的元素，从最小的元素开始输出。 在排序操作开始进行时，图10.6中的代码是在不同的状态下的本地局部变量，这意味着只能对一个数组进行排序。在大多数实际场景中，不仅需要对多个数组进行排序，还希望在不存在气泡的情况下，对每个数组进行反向处理。推荐大家改进代码和testbench，实现对多个数组的排序。 10.3 归并排序 归并操作是 John von Neumann在1945年发明的一种稳定的分治算法，参考36。 归并排序算法的基本思想是将两个有序序列合并成一个较大的有序序列，可以在O(N)O(N)O(N)时间内完成。从概念上讲,将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序 ，组成最终有序序列。 分治操作是归并排序中最核心的算法，不需要算术或者数据移动，只需要考虑每个元素的输入数组是否一个排序的子数组；所有的操作都是需要将两个已经有序的子数组合并成一个大的有序数组 ，其排序的过程如图10.9所示。 将两个排序数组组合成一个较大的排序数组的过程通常称为two-finger算法。图10.10展示了两个已经排序的输入数组in1和in2合并到一个大的输出数组out中。two-finger操作初始化时指向每个数组第一个元素（数值in1中的元素3和数组in2中的元素1），在算法执行的过程中，两个指针会指向数组中的不同元素。 图10.10的第一步是初始化状态，输入的两个数组各有四个元素，输出数组是空的。第二步，比较两个数组中的第一个元素，并且把最小的元素写入输出数组中（即比较3和1中小元素1并排序到数组out中）；此时数组in2的指针指向下一个元素。第三步，继续比较两个数组中当前指针所指向元素的大小，并把小的元素排序到输出数组中（即比较3和2中的小元素2并排序到数组out中）。继续类似的操作，直到其中一个数组元素移空；最后只需要拷贝未处理完的数组中剩下的元素到输出数组out中。 归并排序算法是递归函数调用的典型示例 。大多数的高层综合语言不支持递归，或者以有边界的方式支持递归。这里我们关注归并排序算法的非递归实现方式，代码看起来与通常CPU架构下的完全不同，但是算法的核心思想是完全相同的。 10.3.1 归并排序的基本操作 图10.11展示了非递归方式实现的归并排序的基本代码，处理数组排序大概需要NlogNN log NNlogN 次比较，并且需要额外德 临时存储空间。代码里首先考虑数组中的每个元素作为一个排序子数组，外部循环的每次迭代都将排序子数组合并成较大的排序子数组。第一次迭代，对最大SIZESIZESIZE为2的子数组进行排序；第二次迭代，对最大SIZESIZESIZE为4的子数组进行排序；然后是8，以此类推。需要注意的是，这里的输入数组得瑟长度并不是2的幂次方，也可能有一些子数组小于最大尺寸。 #include \"merge_sort.h\" #include \"assert.h\" // subarray1 is in[i1..i2-1], subarray2 is in[i2..i3-1], result is in out[i1..i3-1] void merge(DTYPE in[SIZE], int i1, int i2, int i3, DTYPE out[SIZE]) { int f1 = i1, f2 = i2; // Foreach element that needs to be sorted... for(int index = i1; index = SIZE) i2 = SIZE; if(i3 >= SIZE) i3 = SIZE; merge(A, i1, i2, i3, temp); } // Copy temp[] back to A[] for next iteration copy: for(int i = 0; i 图10.11：非递归方式的归并排序实现。merge_sort函数每一步都将两个已经有序的子数组合并成一个大的有序数组 ，直到整个数组有序 归并排序算法的主入口函数为merge_sort，函数的数组为A，需要内部存储存放数组temp；参数SIZE决定两个数组的大小，参数DTYPE决定数据的排序类型。merge_sort函数主要有两个嵌套的for循环构成，外部循环体主要跟踪每个排序子数组中的元素数量；初始化时将每个元素作为单独的子数组，因此width宽度初始化为1。每次循环都会生成较大的排序子数组，这些新的子数组绝大多数情况下都是两倍的元素。但宽度大于或者等于参数SIZE的值时，循环终止，此时所有的元素都在一个有序数组中。 内部循环体merge_arrays的主要功能时归并两个有序数组 ，这些有序数组最多有width个元素，从索引i1和i2开始。然后调用merge函数将有序子数组合并并复制到内部存储temp数组中。这里需要处理循环末尾的边界情况，若参数SIZE不是2的幂次方，子数组可能包含小于宽度的元素。在完成子数组的归并到temp数组后，需要把当前temp数组中的元素按顺序存放在数组A中，以便开展下一轮的循环迭代。 通过不断调整SIZE的值，获取那些值比较合适？当调用merge函数是，i1、i2和i3之间的可能关系有哪些？如果限定参数SIZE，HLS产生的电路又有什么影响？ merge函数对数组in中的两个子数组采用了two-finger算法。数组in作为函数的输入数组，数组out作为函数的输出数组；而且还需要输入变量i1、i2和i3，来描述需要合并的两个子数组的边界范围。一个子数组从第i1坐标索引开始，到第i2个坐标索引之前截止；还有一个子数组从第i2个坐标索引开始，到第i3个坐标索引截止；合并后输出子数组将存储在数组out的坐标索引i1到i3之间。 merge函数包含一个遍历数组排序输出的循环；每一个循环迭代都将一个元素放在输出数组out中的正确排序的位置。函数中的变量f1和f2对应每个子数组的坐标索引。if条件里面的主要功能即是选择in[f1]和in[f2]中相对小的元素，并拷贝到输出数组out下一个排序的位置中。而if条件里面还需要处理几种特殊的情况；一种情况是f1等于 i2，此时in[f1]已经超过子数组的边界，需要在in[f2]里面选择最小的元素；同样地。如果f2等于i3，此时in[f2]已经超过子数组的边界，需要在in[f1]里面选择最小的元素。 在处理过程中数组in会发生什么变化？在外部循环的每次迭代之后数组in的元素排序会是什么？当merge_sort函数返回时，数组in的元素排序会是什么？ 综合后的性能报告可能无法确定归并排序的延迟和间隔，为什么会出现这种情况？如何评估loop tripcount指令值，哪一个才是合适的最小值、最大值和平均值？ 图10.11中的代码并没有使用Vivado HLS的一些特定优化指令。对多层嵌套for循环的优化，通常先从内部循环优化开始，然后再进行外部循环的优化。常用的循环优化指令有流水线指令pipeline和展开指令unroll。 使用pipeline指令设置不同的优化参数，还可以使用unroll指令展开for循环，哪一种方式提供了最好性能？性能和资源利用率之间的最佳权衡又是什么？代码方面的设计缺陷阻碍了更高的性能？这些方面都是算法设计考虑的因素，不能仅关注代码实现层面。 pipeline和unroll往往会受到资源上面的限制，因此需要考虑数组输入输出的端口数量。图10.11中的数组都是一维的，此时设计者还需要仔细考虑数组的访问模式，以确保性能优化与资源限制匹配。 建议使用array_partition、pipeline和unroll指令来优化循环，探索出最佳的策略。只考虑性能方面，最佳的设计是什么？在考虑资源利用率和性能之间的权衡后，最佳的设计是什么？ 最佳设计往往只有通过重构代码才能实现。虽然Vivado HLS提供了许多指令来启动一个常规的公共代码优化，但是为每一个优化提供一个指令的做法是不切实际的。在下一节中，将描述一种方法重构归并排序的代码，以增加排序的吞吐量。 10.3.2 重构归并排序 图10.11实现的内部循环merge函数要取得1个时钟周期的循环启动间隔是非常有挑战的。一方面数组in有四次读操作，且有两个不同的读操作基地址。HLS综合工具需要分析出其中有些读取操作是冗余的，但是FPGA的片上BRAM资源只能支持每个时钟周期的两个访问，再加上这些读操作在不同的基本块中，编译器更难消除冗余负载。 通过重构代码来消除冗余读取，编译器只需要更少的优化来实现1个时钟周期的循环启动间隔，重构后的代码如图10.12所示。另外一方面，在变量f1和f2有递归关系，这些变量在if条件内部递增，并且确定了下一次循环时数组in中的需要比较元素的位置信息。这种动态浮动的比较方式也会影响时钟频率和循环的启动间隔。 #include \"merge_sort.h\" #include \"assert.h\" // subarray1 is in[ii..i2-1]; subarray2 is in[i2..i3-1] // sorted merge is stored in out[i1..i3-1] void merge(DTYPE in[SIZE], int i1, int i2, int i3, DTYPE out[SIZE]) { int f1 = i1, f2 = i2; // Foreach element that needs to be sorted... for(int index = i1; index 图10.12：重构merge函数的代码实现：在Vivado HLS中循环的启动间隔可以达到1 图10.13描述了重构代码的行为结构，虽然内部循环实现了1个时钟周期的启动间隔，但是在内部循环结束时，在下一个阶段的流水线执行之前，中间的缓冲数据必须先清空。一旦循环的次数增加，中间的气泡问题还是影响流水线性能的关键因素。由于循环静态分析的局限性，影响性能的代码部分很难可视化，而且内部循环的次数是有变量参数决定的。 常见的方法是将多层循环嵌套优化成一个单一循环，减少流水线中循环退出时的刷新次数，Vivado HLS工具也支持了多层循环嵌套的自动优化。然而，图10.11中的代码实现并不是一个完美的循环嵌套，需要重构merge函数以支持循环嵌套的完美合并，重构后的代码如图10.14所示。其最大的变化就是merge_arrays函数循环次数也是确定的，使得编译器更好地理解实现。 #include \"merge_sort.h\" #include \"assert.h\" void merge_sort(DTYPE A[SIZE]) { DTYPE temp[SIZE]; stage: for (int width = 1; width = SIZE) i2 = SIZE; if(i3 >= SIZE) i3 = SIZE; merge_arrays: for (int i = 0; i = SIZE) i2 = SIZE; if(i3 >= SIZE) i3 = SIZE; f2 = i2; } } copy: for(int i = 0; i 图10.14：重构merge函数的代码实现：在Vivado HLS中循环的启动间隔可以达到1，而且流水线的气泡很少 评估图10.14中代码的性能，即使内部循环已经实现了1个时钟周期的启动间隔，该设计是否有效合理地利用了硬件加速？有没有进一步改进merge_sort函数延迟的方法，使得整个延迟在大约在NlogN个时钟周期？ 前面重点介绍了如何优化merge_sort函数，在不大幅增加资源利用率的情况下，降低计算处理的延迟，提高了加速器的计算效率。提高加速器并行计算能力的方法主要是进一步降低延迟或者提高吞吐量。前面介绍的内部循环的展开优化和数组分区优化可以在每一个时钟周期内同时执行更多的任务。还有一种提高并行计算能力的方法是寻找粗粒度的任务级流水线。这里可以把归并排序的内部迭代体merge_arrarys创建多份硬件资源，以达到粗粒度的任务级流水。如图10.15所示，通过展开连续的内部循环体merge_arrays，可以同时处理不同的数据集，以提高整个加速器的计算性能。 图10.16是加入任务级流水和数据流优化后的代码实现。虽然有很多方面都与原始代码类似，但是有几个重要的区别。第一个区别是merge_arrays 函数的循环都提取到一个函数中，方便了顶层函数的代码重构；第二个区别是merge_sort_parallel函数的输入和输出分别在一个独立的数组中，通过Vivado HLS的dataflow指令就能够构建一个数据流水线的体系结构；第三，temp数组用在merge_arrays函数之间的乒乓操作数据流中，减少中间缓存的不必要的拷贝信息；同时重构为一个二维数组，使得通道数的表示参数化。 #include \"merge_sort_parallel.h\" #include \"assert.h\" void merge_arrays(DTYPE in[SIZE], int width, DTYPE out[SIZE]) { int f1 = 0; int f2 = width; int i2 = width; int i3 = 2*width; if(i2 >= SIZE) i2 = SIZE; if(i3 >= SIZE) i3 = SIZE; merge_arrays: for (int i = 0; i = SIZE) i2 = SIZE; if(i3 >= SIZE) i3 = SIZE; f2 = i2; } } } void merge_sort_parallel(DTYPE A[SIZE], DTYPE B[SIZE]) { #pragma HLS dataflow DTYPE temp[STAGES-1][SIZE]; #pragma HLS array_partition variable=temp complete dim=1 int width = 1; merge_arrays(A, width, temp[0]); width *= 2; for (int stage = 1; stage 图10.16：重构归并排序的代码实现：利用了Vivado HLS的dataflow和pipeline的指令优化 merge_sort_parallel函数里面包含多个阶段的merge_arrays函数调用；第一次调用时从输入端读取数据，并把处理完的结果写入temp数组中；在循环执行过程中，多次调用merge_arrays，并写入temp数组的其他分区；最后一个调用时写入排序后的结果到数组B中。在资源足够的情况下，参数SIZE和STAGES可以支持更大的吞吐。 评估图10.16中重构后的代码性能,分析其实现的延迟和启动间隔，大概需要多大的片上存储？ 10.4 总结 本章介绍了一些基本的排序算法。插入排序操作平均需要N2/4N^2/4N2/4次数据比较，极端下需要N2N^2N2次比较，但是仅需要少量的存储资源；展示了插入排序中的几种提升性能的不同方式；由于流水线的气泡问题，N个比较器大约需要N个时钟周期的间隔才能完成插入排序。归并排序的比较次数相对插入排序较少，大约仅需要NlogNN log NNlogN 次比较，但是需要额外的片上存储开销存储中间缓存。一种高效的设计方案是通过重构优化代码，取得在1个比较器的情况下，归并排序大概仅需NlogNN log NNlogN 个时钟周期即可完成。另外一种高效的设计方案是采用任务级流水线，每一个时钟周期有logN log NlogN 个比较，N个时钟周期的间隔才能完成归并排序。与插入排序相比，同样的计算处理周期，归并排序需要较少的比较器，但是带来的代价是额外的存储资源开销。归并排序如果需要更多的片上存储，其整体的延迟也会变大。 在实际系统中，基于FPGA的排序设计方案都必须解决资源和时间性能之间的权衡问题。还有一种使用不同折中方案的排序算法叫基数排序，与本章的排序算法不太一样，其更关注数据的有效范围作为元素之间的比较项。基数排序的一部分实现在下一章的Huffman编码会有更详细的介绍。 排序算法的并行结构通常被描述为排序网络，排序网络有时可以是脉动阵列或者流水线。通过研究这些现有的并行结构来获得HLS的设计灵感，然后通过C代码来实现它。在Vivado HLS中，可以使用任意一种方法来描述这些循环流水线、数据流水线或者两者的组合。 Copyright © xupsh.github.io 2018 all right reserved，powered by Gitbook 该文件修订时间： 2018-07-10 15:20:35 "},"11-Huffman-Encoding.html":{"url":"11-Huffman-Encoding.html","title":"第十一章","keywords":"","body":"第十一章 Copyright © xupsh.github.io 2018 all right reserved，powered by Gitbook 该文件修订时间： 2018-07-10 15:20:35 "},"GLOSSARY.html":{"url":"GLOSSARY.html","title":"词汇表汇总","keywords":"","body":"词汇表 数组分离 把一个逻辑数组分离到不同的内存中储存 比特流 用于编程FPGA功能的配置数据 BRAM 一个可编程的RAM模块，嵌入在FPGA上以完成数据储存和交流 C/RTL同步模拟 用C测试平台的测试矢量来完成HLS产生的RTL设计这个过程 压缩行储存 也就是CRS，是一个表示稀疏矩阵的方法。它能够有效的表示一个很大但有很多无效数字的矩阵。 数据率 任务处理输入数据的频率。通常以比特每秒的单位表示，取决于输入数据的大小。 离散傅立叶变换 DFT，以一个离散信号为输入，把它转换成频率域的信号的过程。 EDA 电子设计自动化工具，是一些帮助完成硬件设计的软件工具。 快速傅里叶变换 FFT，优化版本的离散傅立叶变换，需要更少量的操作。 触发器 触发器（FF）是可以储存信息的电路。我们通常默认它可以储存1比特的信息，是组成数字电路的最基本的模块之一。 有限脉冲响应 FIR，一个常见的数字信号处理任务，将一个输入信号和既定系数决定的信号做卷积。FIR通常用硬件实现比较有效。 FPGA 现场可编程门阵列，是一种出厂后仍可以被用户自定义集成电路。 HLS 高层次综合，是一种将算法描述转换成RTL的硬件设计语言，它可以详细规定电路每个周期的行为。 I/O模块 一个I/O模块可以提供FPGA与系统中其他部分连接的接口。I/O模块可以与内存（包括片上内存和不在片上的DRAM），微处理器（通过AXI或其他协议），传感器，校准器等部分交流。 IP核 一个RTL层级的部件，具有完善的接口来接入整个设计。通常出于知识产权（Intellectual Property）目的向其他公司隐藏，由此得名。 逻辑综合 把一个glsrtl设计转换成设备层的连线表的过程。 循环交叉 一种改变循环里操作的顺序的代码转变。这种转变通常是解决递归的有效方式。 循环流水 允许一个循环的多个步骤同时运行，享有同样的功能单位。 查找表 查找表（LUT）是一种地址信号作为输入，相对应位置的存储数值作为输出的内存形式。它是现代FPGA的一个重要组成部分。 连线表 设计的中间连接部分，由设计层的主要部件和他们之间的连接方式组成。在FPGA设计中“主要部件”包括查找表，触发器，和BRAM。 部分循环展开 循环的主体被复制成多次执行的过程。通常被用于处理系统（PS）以减少循环的占用（overhead），也会有利于向量化。 放置与路由 把设备层主要部件的连线表转换成一个具体装置配置的过程。 处理 数据流结构中的一个独立部分。 处理部件 设计中的一个可以简单的处理同步执行的部件，在HLS中通常出现在数据流结构的描述中。 递归（recurrence） 一种代码结构，产出的电路中带有反馈循环，这种结构会限制电路的产力。 ROM 只读内存（Read-Only Memory）是一种被初始化到一定数值的内存，它只能被读取无法被写入数据。在很多情况下用ROM储存是一种非常好的优化因为他们存储的数据不会变。 路由通道 路由通道提供FPGA内各部件灵活的连接方式。 RTL 寄存器转移级（Register Transfer Level），是一种硬件描述，它用各个寄存器之间的逻辑操作来搭建一个同步数字电路。它也是现代数字设计的一个常见设计入口。 slice 一些查找表，触发器和mux的集合，具体配置在FPGA资源配置报告中有详述。 分类单元 一个简单的组件，是分类算法的系统的一部分。通常分类单元可以执行两个对象的比较和交换。 稳定分类 一种分类算法，如果它能保证排序前2个相等数的前后位置顺序和排序后它们两个的前后位置顺序相同，那么它就是稳定分类。 静态单赋值 静态单赋值是编译器中的一种中介码，每个变量在这里只被赋值一次。这种形式让优化变得更简单。 交换盒 交换盒连接各个路由通道，为可编程逻辑和I/O模块之间数据的流通提供了一个灵活的路由结构。 脉动阵列 一个协同完成复杂算法的处理部件阵列。脉动列阵的设计方向通常是让每个处理部件封装一些本地信息，并且只和他们的本地邻居进行交流。这样简单的增大阵列的尺寸就可以增加处理的项目的尺寸。 任务 行为，或说高层次综合计算的基本的原子级单位。高层次综合中与之对应的是函数调用。 任务流水 用流水的形式在一个加速器上同时执行多个任务。 任务间隔 一个任务开始和下一个任务开始之间的间隔。 任务延迟 一个任务开始和它结束之间的间隔。 Copyright © xupsh.github.io 2018 all right reserved，powered by Gitbook 该文件修订时间： 2018-07-10 15:20:35 "},"BIBLIOGRAPHY.html":{"url":"BIBLIOGRAPHY.html","title":"参考文献","keywords":"","body":"参考文献 1 Ameer M.S. Abdelhadi and Guy G.F. Lemieux. Modular multi-ported SRAM-based memories. In Proceedings of the International Symposium on Field Programmable Gate Arrays (FPGA), pages 35{44. ACM, 2014. ISBN 978-1-4503-2671-1. doi: 10.1145/2554688.2554773. URL http://doi.acm.org/10.1145/2554688.2554773. 2 SystemC. Accellera, 2.3.2 edition, October 2017. URL http://www.accellera.org/ downloads/standards/systemc. 3 Hassan M. Ahmed, Jean-Marc Delosme, and Martin Morf. Highly concurrent computing structures for matrix arithmetic and signal processing. IEEE Computer, 15(1):65{82, 1982.s 4 Raymond J. Andraka. Building a high performance bit-serial processor in an FPGA. In Proceedings of Design SuperCon, volume 96, pages 1{5, 1996. 5 Oriol Arcas-Abella et al. An empirical evaluation of high-level synthesis languages and tools for database acceleration. In Proceedings of the International Field Programmable Logic and Applications Conference (FPL), pages 1{8. IEEE, 2014. 6 AMBA AXI and ACE Protocol Speci\fcation. ARM Limited, v1.0 edition, 2013. URL http:// infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.ihi0022e/index.html. ARM IHI 0022E. 7 Bryce E. Bayer. Color imaging array, July 1976. US 3971065. 8 Samuel Bayliss and George A. Constantinides. Optimizing SDRAM bandwidth for cus- tom FPGA loop accelerators. In Proceedings of the International Symposium on Field Pro- grammable Gate Arrays (FPGA), pages 195{204. ACM, February 2012. 9 Marcus Bednara et al. Tradeo\u000b analysis and architecture design of a hybrid hardware/soft- ware sorter. In Proceedings of the International Conference on Application-speci\fc Systems, Architectures and Processors (ASAP), pages 299{308. IEEE, 2000. 10 Vaughn Betz and Jonathan Rose. VPR: A new packing, placement and routing tool for FPGA research. In Proceedings of the International Field Programmable Logic and Applications Conference (FPL), pages 213{222. Springer, 1997. 11 Guy E. Blelloch. Pre\fx sums and their applications. Technical Report CMU-CS-90-190, School of Computer Science, Carnegie Mellon University, November 1990. 12 Stephen Brown and Jonathan Rose. FPGA and CPLD architectures: A tutorial. IEEE Design and Test of Computers, 13(2):42{57, 1996. 13 Andrew Canis, Jongsok Choi, Mark Aldham, Victor Zhang, Ahmed Kammoona, Jason H Anderson, Stephen Brown, and Tomasz Czajkowski. LegUp: high-level synthesis for FPGA- based processor/accelerator systems. In Proceedings of the International Symposium on Field Programmable Gate Arrays (FPGA), pages 33{36. ACM, 2011. 14 Jianwen Chen, Jason Cong, Ming Yan, and Yi Zou. FPGA-accelerated 3D reconstruction using compressive sensing. In Proceedings of the International Symposium on Field Programmable Gate Arrays (FPGA), pages 163{166. ACM, 2012. 15 Jason Cong, Bin Liu, Stephen Neuendor\u000ber, Juanjo Noguera, Kees Vissers, and Zhiru Zhang. High-level synthesis for fpgas: From prototyping to deployment. IEEE Transactions on Computer-aided Design of Integrated Circuits and Systems (TCAD), 30(4):473{491, 2011. 16 James W. Cooley and John W. Tukey. An algorithm for the machine calculation of complex fourier series. Mathematics of Computation, 19(90):297{301, 1965. ISSN 00255718. URL http://www.jstor.org/stable/2003354. 17 Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Cli\u000bord Stein. Introduction to Algorithms, Third Edition. MIT Press, 3rd edition, 2009. ISBN 0262033844, 9780262033848. 18 Philippe Coussy and Adam Morawiec. High-level synthesis, volume 1. Springer, 2010. 19 Steve Dai, Ritchie Zhao, Gai Liu, Shreesha Srinath, Udit Gupta, Christopher Batten, and Zhiru Zhang. Dynamic hazard resolution for pipelining irregular loops in high-level synthesis. In Proceedings of the International Symposium on Field Programmable Gate Arrays (FPGA), pages 189{194, 2017. ISBN 978-1-4503-4354-1. doi: 10.1145/3020078.3021754. URL http: //doi.acm.org/10.1145/3020078.3021754. 20 Je\u000brey Dean and Sanjay Ghemawat. MapReduce: Simpli\fed data processing on large clusters. Communications of the ACM, 51(1):107{113, January 2008. ISSN 0001-0782. doi: 10.1145/ 1327452.1327492. URL http://doi.acm.org/10.1145/1327452.1327492. 21 Alvin M. Despain. Fourier transform computers using CORDIC iterations. IEEE Transactions on Computers, 100(10):993{1001, 1974. 22 J. Detrey and F. de Dinechin. Floating-point trigonometric functions for FPGAs. In Proceed- ings of the International Field Programmable Logic and Applications Conference (FPL), pages 29{34, August 2007. doi: 10.1109/FPL.2007.4380621. 23 L Peter Deutsch. DEFLATE compressed data format speci\fcation version 1.3. 1996. 24 Jean Duprat and Jean-Michel Muller. The CORDIC algorithm: new results for fast VLSI implementation. IEEE Transactions on Computers, 42(2):168{178, 1993. 25 Brian P. Flannery, William H. Press, Saul A. Teukolsky, and William Vetterling. Numerical recipes in C. Press Syndicate of the University of Cambridge, New York, 1992. 26 Daniel D. Gajski, Nikil D. Dutt, Allen C.H. Wu, and Steve Y.L. Lin. High-Level Synthesis: Introduction to Chip and System Design. Springer Science & Business Media, 2012. 27 W Morven Gentleman and Gordon Sande. Fast fourier transforms: for fun and pro\ft. In Proceedings of the November 7-10, 1966, fall joint computer conference, pages 563{578. ACM, 1966. 28 Nivia George, HyoukJoong Lee, David Novo, Tiark Rompf, Kevin J. Brown, Arvind K. Su- jeeth, Martin Odersky, Kunle Olukotun, and Paolo Ienne. Hardware system synthesis from domain-speci\fc languages. In Proceedings of the International Field Programmable Logic and Applications Conference (FPL), pages 1{8. IEEE, 2014. 29 Sumit Gupta, Rajesh Gupta, Nikil Dutt, and Alexandru Nicolau. SPARK: A Parallelizing Approach to the High-level Synthesis of Digital Circuits. Kluwer, 2004. ISBN 1-4020-7837-4. 30 Scott Hauck and Andre DeHon. Recon\fgurable computing: the theory and practice of FPGA- based computation, volume 1. Morgan Kaufmann, 2010. 31 James Hegarty, Ross Daly, Zachary DeVito, Jonathan Ragan-Kelley, Mark Horowitz, and Pat Hanrahan. Rigel: Flexible multi-rate image processing hardware. ACM Trans. Graph., 35(4):85:1{85:11, July 2016. ISSN 0730-0301. doi: 10.1145/2897824.2925892. URL http: //doi.acm.org/10.1145/2897824.2925892. 32 M. Heideman, D. Johnson, and C. Burrus. Gauss and the history of the fast fourier transform. ASSP Magazine, IEEE, 1(4):14{21, October 1984. ISSN 0740-7467. doi: 10.1109/MASSP. 1984.1162257. 33 David A. Hu\u000bman. A method for the construction of minimum-redundancy codes. Proceedings of the IRE, 40(9):1098{1101, 1952. 34 Ryan Kastner, Anup Hosangadi, and Farzan Fallah. Arithmetic optimization techniques for hardware and software design. Cambridge University Press, 2010. 35 David Knapp. Behavioral Synthesis: Digital System Design using the Synopsys Behavioral Compiler. Prentice-Hall, 1996. ISBN 0-13-569252-0. 36 Donald Ervin Knuth. The art of computer programming: sorting and searching, volume 3. Pearson Education, 1998. 37 Charles Eric Laforest, Zimo Li, Tristan O'rourke, Ming G. Liu, and J. Gregory Ste\u000ban. Composing multi-ported memories on FPGAs. ACM Transactions on Recon\fgurable Tech- nology and Systems (TRETS), 7(3):16:1{16:23, September 2014. ISSN 1936-7406. doi: 10.1145/2629629. URL http://doi.acm.org/10.1145/2629629. 38 Glen G. Langdon Jr, Joan L. Mitchell, William B. Pennebaker, and Jorma J. Rissanen. Arith- metic coding encoder and decoder system, February 27 1990. US Patent 4,905,297. 39 Dajung Lee, Janarbek Matai, Brad Weals, and Ryan Kastner. High throughput channel tracking for JTRS wireless channel emulation. In Proceedings of the International Field Pro- grammable Logic and Applications Conference (FPL). IEEE, 2014. 40 Edward A. Lee and David G. Messerschmitt. Pipeline interleaved programmable DSPs: Ar- chitecture. IEEE Transactions on Acoustics, Speech, and Signal Processing (TASSP), 35(9): 1320{1333, September 1987. 41 Edward A. Lee and Pravin Varaiya. Structure and Interpretation of Signals and Systems, Second Edition. 2011. ISBN 0578077191. URL LeeVaraiya.org. 42 Edward Ashford Lee. Plato and the Nerd: The Creative Partnership of Humans and Technol- ogy. MIT Press, 2017. ISBN 978-0262036481. 43 C. Leiserson, F. Rose, and J. Saxe. Optimizing synchronous circuitry by retiming. In Third Caltech Conference On VLSI, 1993. 44 G. Liu, M. Tan, S. Dai, R. Zhao, and Z. Zhang. Architecture and synthesis for area-e\u000ecient pipelining of irregular loop nests. IEEE Transactions on Computer-aided Design of Integrated Circuits and Systems (TCAD), 36(11):1817{1830, November 2017. ISSN 0278-0070. doi: 10.1109/TCAD.2017.2664067. 45 Rui Marcelino et al. Sorting units for FPGA-based embedded systems. In Distributed Embedded Systems: Design, Middleware and Resources, pages 11{22. Springer, 2008. 46 Janarbek Matai, Pingfan Meng, Lingjuan Wu, Brad T Weals, and Ryan Kastner. Designing a hardware in the loop wireless digital channel emulator for software de\fned radio. In Proceedings of the International Conference on Field-Programmable Technology (FPT). IEEE, 2012. 47 Janarbek Matai, Joo-Young Kim, and Ryan Kastner. Energy e\u000ecient canonical hu\u000bman encoding. In Proceedings of the International Conference on Application-speci\fc Systems, Architectures and Processors (ASAP). IEEE, 2014. 48 Janarbek Matai, Dustin Richmond, Dajung Lee, and Ryan Kastner. Enabling FPGAs for the masses. arXiv preprint arXiv:1408.5870, 2014. 49 Janarbek Matai, Dustin Richmond, Dajung Lee, Zac Blair, Qiongzhi Wu, Amin Abazari, and Ryan Kastner. Resolve: Generation of high-performance sorting architectures from high-level synthesis. In Proceedings of the International Symposium on Field Programmable Gate Arrays (FPGA), pages 195{204. ACM, 2016. ISBN 978-1-4503-3856-1. doi: 10.1145/2847263.2847268. URL http://doi.acm.org/10.1145/2847263.2847268. 50 Carver Mead and Lynn Conway. Introduction to VLSI systems, volume 1080. Addison-Wesley Reading, MA, 1980. 51 Giovanni De Micheli. Synthesis and optimization of digital circuits. McGraw-Hill Higher Education, 1994. 52 Shahnam Mirzaei, Anup Hosangadi, and Ryan Kastner. FPGA implementation of high speed \fr \flters using add and shift method. In Computer Design, 2006. ICCD 2006. International Conference on, pages 308{313. IEEE, 2007. 53 MISRA. Guidelines for the Use of the C Language in Critical Systems. March 2013. ISBN 978-1-906400-10-1. URL https://www.misra.org.uk. 54 Rene Mueller et al. Sorting networks on FPGAs. The VLDB Journal|The International Journal on Very Large Data Bases, 21(1):1{23, 2012. 55 Jorge Ortiz et al. A streaming high-throughput linear sorter system with contention bu\u000bering. International Journal of Recon\fgurable Computing, 2011. 56 Marios C. Papaefthymiou. Understanding retiming through maximum average-weight cycles. In SPAA '91: Proceedings of the third annual ACM symposium on Parallel algorithms and architectures, pages 338{348, 1991. 57 William B. Pennebaker. JPEG: Still image data compression standard. Springer, 1992. 58 Robert Sedgewick. Algorithms in C. Addison-Wesley, 2001. ISBN 978-0201756081. 59 Bhaskar Sherigar and Valmiki K. Ramanujan. Hu\u000bman decoder used for decoding both ad- vanced audio coding (AAC) and MP3 audio, June 29 2004. US Patent App. 10/880,695. 60 F. Winterstein, S. Bayliss, and G. A. Constantinides. High-level synthesis of dynamic data structures: A case study using Vivado HLS. In Proceedings of the International Symposium on Field Programmable Gate Arrays (FPGA), pages 362{365, December 2013. doi: 10.1109/ FPT.2013.6718388. 61 Ian H. Witten, Radford M. Neal, and John G. Cleary. Arithmetic coding for data compression. Communications of the ACM, 30(6):520{540, 1987. 62 UltraScale Architecture Con\fgurable Logic Block (UG574). Xilinx, v1.5 edition, February 2017. URL https://www.xilinx.com/support/documentation/user_guides/ ug574-ultrascale-clb.pdf. 63 Vivado Design Suite User Guide: High-Level Synthesis (UG902). Xilinx, v2017.1 edition, April 2017. URL https://www.xilinx.com/support/documentation/sw_manuals/xilinx2017_ 1/ug902-vivado-high-level-synthesis.pdf. 64 UltraScale Architecture Con\fguration (UG570). Xilinx, v1.7 edition, March 2017. URL https://www.xilinx.com/support/documentation/user_guides/ ug570-ultrascale-configuration.pdf. Copyright © xupsh.github.io 2018 all right reserved，powered by Gitbook 该文件修订时间： 2018-07-10 15:20:35 "},"RULES.html":{"url":"RULES.html","title":"排版约定","keywords":"","body":"排版约定 引用公式 使用示例: Inline math: ∫−∞∞g(x)dx\\int_{-\\infty}^\\infty g(x) dx∫−∞∞​g(x)dx Block math: ∫−∞∞g(x)dx(4.1) \\int_{-\\infty}^\\infty g(x) dx \\quad (4.1) ∫−∞∞​g(x)dx(4.1) 引用代码 只要将代码用```包住，代码块就会被识别为代码 ```c #include \"huffman.h\" // Postcondition: out[x].frequency > 0 void filter( /* input */ Symbol in[INPUT_SYMBOL_SIZE], /* output */ Symbol out[INPUT_SYMBOL_SIZE], /* output */ int *n) { #pragma HLS INLINE off ap_uint j = 0; for(int i = 0; i #include \"huffman.h\" // Postcondition: out[x].frequency > 0 void filter( /* input */ Symbol in[INPUT_SYMBOL_SIZE], /* output */ Symbol out[INPUT_SYMBOL_SIZE], /* output */ int *n) { #pragma HLS INLINE off ap_uint j = 0; for(int i = 0; i 引用图片 在行文中使用下述格式引用图片，将图片下方的备注写在[]之间 ![Figure 5.1: Part a) is a data flow graph for a 2 point DFT/FFT. Part b) shows the same compu-tation, but viewed as a butterfly structure. This is a common representation for the computation of an FFT in the digital signal processing domain.](images/2pointFFT.jpg) 文字加框 原书中蓝色的框 {% hint style='info' %} Important info: this note needs to be highlighted {% endhint %} Important info: this note needs to be highlighted 原书中黑色的框 {% hint style='tip' %} Important tip: this note needs to be highlighted {% endhint %} Important tip: this note needs to be highlighted 其它 请酌情使用 {% hint style='danger' %} Important danger: this note needs to be highlighted {% endhint %} Important danger: this note needs to be highlighted {% hint style='working' %} Important working: this note needs to be highlighted {% endhint %} Important working: this note needs to be highlighted 引用参考文献 在行文中使用下述格式引用参考文献即可 [[45](./BIBLIOGRAPHY.md#45), [55](./BIBLIOGRAPHY.md#55)] [45, 55] Copyright © xupsh.github.io 2018 all right reserved，powered by Gitbook 该文件修订时间： 2018-07-10 15:20:35 "}}